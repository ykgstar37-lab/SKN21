{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227316ea",
   "metadata": {},
   "source": [
    "# RAG(Retrieval Augmented Generation)\n",
    "- [RAG](https://python.langchain.com/v0.1/docs/modules/data_connection/)은 *Retrieval Augmented Generation*의 약자로, **검색 기반 생성 기법**을 의미한다. 이 기법은 LLM이 특정 문서에 기반하여 보다 정확하고 신뢰할 수 있는 답변을 생성할 수 있도록 돕는다.     \n",
    "- 사용자의 질문에 대해 자체적으로 구축한 데이터베이스(DB)나 외부 데이터베이스에서 질문과 관련된 문서를 검색하고, 이를 질문과 함께 LLM에 전달한다.\n",
    "- LLM은 같이 전달된 문서를 바탕으로 질문에 대한 답변을 생성한다. \n",
    "- 이를 통해 LLM이 학습하지 않은 내용도 다룰 수 있으며, 잘못된 정보를 생성하는 환각 현상(*hallucination*)을 줄일 수 있다.\n",
    "\n",
    "## RAG와 파인튜닝(Fine Tuning) 비교\n",
    "\n",
    "### 파인튜닝(Fine Tuning)\n",
    "\n",
    "- **정의**: 사전 학습(pre-trained)된 LLM에 특정 도메인의 데이터를 추가로 학습시켜 해당 도메인에 특화된 맞춤형 모델로 만드는 방식이다.\n",
    "- **장점**\n",
    "  - 특정 도메인에 최적화되어 높은 정확도와 성능을 낼 수 있다.\n",
    "- **단점**\n",
    "  - 모델 재학습에 많은 시간과 자원이 필요하다.\n",
    "  - 새로운 정보가 반영되지 않으며, 이를 위해서는 다시 학습해야 한다.\n",
    "\n",
    "### RAG\n",
    "\n",
    "- **정의**: 모델을 다시 학습시키지 않고, 외부 지식 기반에서 정보를 검색하여 실시간으로 답변에 활용하는 방식이다.\n",
    "- **장점**\n",
    "  - 최신 정보를 쉽게 반영할 수 있다.\n",
    "  - 모델을 수정하지 않아도 되므로 효율적이다.\n",
    "- **단점**\n",
    "  - 검색된 문서의 품질에 따라 답변의 정확성이 달라질 수 있다.\n",
    "  - 검색 시스템 구축이 필요하다.\n",
    "\n",
    "## 정리\n",
    "\n",
    "| 항목       | 파인튜닝 | RAG |\n",
    "| -------- | ---- | --- |\n",
    "| 도메인 최적화  | 가능   | 제한적 |\n",
    "| 최신 정보 반영 | 불가능  | 가능  |\n",
    "| 구현 난이도   | 높음   | 보통  |\n",
    "| 유연성      | 낮음   | 높음  |\n",
    "\n",
    "- LLM은 학습 당시의 데이터만을 기반으로 작동하므로 최신 정보나 기업 내부 자료와 같은 특정한 지식 기반에 접근할 수 없다.\n",
    "- 파인튜닝은 시간과 비용이 많이 들고 유지보수가 어렵다.\n",
    "-\t반면, RAG는 기존 LLM을 변경하지 않고도 외부 문서를 통해 그 한계를 보완할 수 있다.\n",
    "- RAG는 특히 빠르게 변화하는 정보를 다루는 분야(예: 기술 지원, 뉴스, 법률 등)에서 유용하게 활용된다. 반면, 정적인 정보에 대해 높은 정확도가 필요한 경우에는 파인튜닝이 효과적이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017ca94-32e0-4460-8937-90a8d92ca07b",
   "metadata": {},
   "source": [
    "## RAG 작동 단계\n",
    "- 크게 \"**정보 저장(인덱싱)**\", \"**검색**, **생성**\"의 단계로 나눌 수 있다.\n",
    "  \n",
    "### 1. 정보 저장(인덱싱)\n",
    "RAG는 사전에 정보를 가공하여 **벡터 데이터베이스**(Vector 저장소)에 저장해 두고, 나중에 검색할 수 있도록 준비한다. 이 단계는 다음과 같은 과정으로 이루어진다.\n",
    "\n",
    "1. **Load (불러오기)**\n",
    "   - 답변시 참조할 사전 정보를 가진 데이터들을 불러온다.\n",
    "2. **Split/Chunking (문서 분할)**\n",
    "   - 긴 텍스트를 일정한 길이의 작은 덩어리(*chunk*)로 나눈다.\n",
    "   - 이렇게 해야 검색과 생성의 정확도를 높일 수 있다.\n",
    "3. **Embedding (임베딩)**\n",
    "   - 각 텍스트 조각을 **임베딩 벡터**로 변환한다.\n",
    "   - 임베딩 벡터는 그 문서의 의미를 벡터화 한 것으로 질문과 유사한 문서를 찾을 때 인덱스로 사용된다.\n",
    "4. **Store (저장)**\n",
    "   - 임베딩된 벡터를 **벡터 데이터베이스**(벡터 저장소)에 저장한다.\n",
    "   - 벡터 데이터베이스는 유사한 질문이나 문장을 빠르게 찾을 수 있도록 특화된 데이터 저장소이다.\n",
    "   \n",
    "![rag](figures/rag1.png)\n",
    "\n",
    "### 2. 검색, 생성\n",
    "\n",
    "사용자가 질문을 하면 다음과 같은 절차로 답변이 생성된다.\n",
    "1. **Retrieve (검색)**\n",
    "   - 사용자의 질문을 임베딩한 후, 이 질문 벡터와 유사한 context 벡터를 벡터 데이터베이스에서 검색하여 찾는다.\n",
    "2. **Query (질의 생성)**\n",
    "   - 벡터 데이터베이스에서 검색된 문서 조각과 사용자의 질문을 함께 **프롬프트**(prompt)로 구성하여 LLM에 전달한다.\n",
    "3. **Generation (응답 생성)**\n",
    "   - LLM은 받은 프롬프트에 대한 응답을 생성한다.\n",
    "   \n",
    "- **RAG 흐름**\n",
    "  \n",
    "![Retrieve and Generation](figures/rag2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6fd91-e3de-4f9d-9c8a-9c21de7a768c",
   "metadata": {},
   "source": [
    "# Document Loader\n",
    "- LLM에게 질의할 때 같이 제공할 Data들을 저장하기 위해 먼저 읽어들인다.(Load)\n",
    "- 데이터 Resouce는 다양하다.\n",
    "    - 데이터를 로드(load)하는 방식은 저장된 위치와 형식에 따라 다양하다. \n",
    "      - 로컬 컴퓨터(Local Computer)에 저장된 문서\n",
    "        - 예: CSV, Excel, JSON, TXT 파일 등\n",
    "      - 데이터베이스(Database)에 저장된 데이터셋\n",
    "      - 인터넷에 존재하는 데이터\n",
    "        - 예: 웹에 공개된 API, 웹 페이지에 있는 데이터, 클라우드 스토리지에 저장된 파일 등\n",
    "\n",
    "![rag_load](figures/rag_load.png)\n",
    "\n",
    "- 다양한 문서 형식(format)에 맞춰 읽어오는 다양한 **document loader** 들을 Langchain에서 지원한다.\n",
    "    - 다양한 Resource들로 부터 데이터를 읽기 위해서는 다양한 라이브러리를 이용해 서로 다른 방법으로 읽어야 한다.\n",
    "    - Langchain은 데이터를 읽는 다양한 방식의 코드를 하나의 interface로 사용 할 수 있도록 지원한다.\n",
    "        - https://python.langchain.com/docs/how_to/#document-loaders\n",
    "    - 다양한 3rd party library(ppt, github 등등 다양한 3rd party lib도 있음. )들과 연동해 다양한 Resource로 부터 데이터를 Loading 할 수 있다.\n",
    "        - https://python.langchain.com/docs/integrations/document_loaders/\n",
    "- **모든 document loader는 기본적으로 동일한 interface(사용법)로 호출할 수있다.**\n",
    "- **반환타입**\n",
    "    - **list[Document]**\n",
    "    - Load 한 문서는 Document객체에 정보들을 넣는다. 여러 문서를 읽을 수 있기 대문에 list에 묶어서 반환한다.\n",
    "        - **Document 속성**\n",
    "            - page_content: 문서의 내용\n",
    "            - metadata(option): 문서에 대한 메타데이터(정보)를 dict 형태로 저장한다. \n",
    "            - id(option): 문서의 고유 id\n",
    "     \n",
    "- **주의**\n",
    "    - Langchain을 이용해 RAG를 구현할 때 **꼭 Langchain의 DocumentLoader를 사용해야 하는 것은 아니다.**\n",
    "    - DocumentLoader는 데이터를 읽어오는 것을 도와주는 라이브러리일 뿐이다. 다른 라이브러리를 이용해서 읽어 들여도 상관없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f25589-24a2-4f1f-9e8c-41e0594b6ce1",
   "metadata": {},
   "source": [
    "## 주요 Document Loader\n",
    "\n",
    "### Text file\n",
    "- TextLoader 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40998e95-a607-45d5-a3f6-2bb598b1aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "path = \"data/olympic.txt\"\n",
    "\n",
    "# 객체 생성 - 읽어들일 자원(파일)의 위치\n",
    "loader = TextLoader(path, encoding='utf-8')\n",
    "\n",
    "# Load - 읽어 오기\n",
    "docs = loader.load() # 메소드 호출시 읽는다.   \n",
    "#docs= loader.lazy_load() : 읽은 문서를 사용(조회) 할 때 그때 읽는다.\n",
    "\n",
    "print(type(docs), len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6b9f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/olympic.txt'}, page_content='올림픽\\n올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다. 대부분의 인기있는 종목들이나 일상에서 쉽게 접하고 즐길 수 있는 생활스포츠 종목들이 올림픽이라는 한 대회에서 동시에 열리고, 전 세계 대부분의 국가 출신의 선수들이 참여하는 만큼 전 세계 스포츠 팬들이 가장 많이 시청하는 이벤트이다. 2008 베이징 올림픽의 모든 종목 누적 시청자 수만 47억 명에 달하며, 이는 인류 역사상 가장 많은 수의 인구가 시청한 이벤트였다.\\n또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다.\\n올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다.\\n올림픽은 거의 모든 국가가 참여할 정도로 규모가 커졌다. 하계 올림픽은 33개의 종목과 약 400개의 세부종목에서 13,000명이 넘는 선수들이 겨루고 그중 각 종목별 1, 2, 3위는 각각 금/은/동을 수여받는다. 전 세계 언론에서 각각 4년마다 열리는 올림픽 경기를 중계하기 때문에 이름 없는 선수가 개인적, 국가적, 세계적으로 명성을 얻을 수 있는 기회가 된다. 이와 더불어 올림픽 경기는 개최지와 개최국에게도 전 세계에 그 이름을 널리 알리는 좋은 기회가 된다.\\n\\n고대올림픽\\n고대의 올림픽 경기(올림피아 경기)는 고대 그리스의 여러 도시 국가의 대표선수들이 모여 벌인 일련의 시합이었으며, 육상 경기가 주 종목이지만 격투기와 전차 경기도 열렸다. 그리고 패배하면 죽기도 하였다. 고대 올림픽의 유래는 수수께끼로 남아있다. 잘 알려진 신화로는 헤라클레스와 그의 아버지인 제우스가 올림픽의 창시자였다는 것이다. 전설에 따르면 이 경기를 최초로 \\'올림픽\\'이라고 부르고, 4년마다 대회를 개최하는 관례를 만든 사람이 헤라클레스라고 한다. 어떤 전설에서는 헤라클레스가 이른바 헤라클레스의 12업을 달성한 뒤에 제우스를 기리고자 올림픽 경기장을 지었다고 한다. 경기장이 완성되자 헤라클레스는 일직선으로 200 걸음을 걸었으며, 이 거리를 \"스타디온\"이라 불렀는데, 후에 이것이 길이 단위인 \\'스타디온\\'(그리스어: στάδιον → 라틴어: 영어: stadium)이 되었다. 또 다른 설로는 \\'올림픽 휴전\\'(그리스어: ἐκεχειρία 에케케이리아[*])이라는 고대 그리스의 관념이 최초의 올림피아 경기와 관련이 있다고 한다. \\'올림픽 휴전\\'이란 어느 도시 국가라도 올림피아 경기 기간 중에 다른 나라를 침범하면 그에 대한 응징을 받을 수 있다는 뜻으로, \"올림픽 기간에는 전쟁하지 말 것\"으로 요약할 수 있다.\\n고대 올림피아 경기가 처음 열린 시점은 보통 기원전 776년으로 인정되고 있는데, 이 연대는 그리스 올림피아에서 발견된 비문에 근거를 둔 것이다. 이 비문의 내용은 달리기 경주 승자 목록이며 기원전 776년부터 4년 이후 올림피아 경기 마다의 기록이 남겨져 있다. 고대 올림픽의 종목으로는 육상, 5종 경기(원반던지기, 창던지기, 달리기, 레슬링, 멀리뛰기), 복싱, 레슬링, 승마 경기가 있었다. 전설에 따르면 엘리스의 코로이보스가 최초로 올림피아 경기에서 우승한 사람이라고 한다.\\n고대 올림피아 경기는 근본적으로 종교적인 중요성을 띄고 있었는데, 스포츠 경기를 할 때는 제우스(올림피아의 제우스 신전에는 페이디아스가 만든 제우스 상이 있음)와 펠롭스를 기리기 위하여 제물 봉헌 의식을 치렀다. 펠롭스는 올림피아의 전설상의 임금이었던 피사티스의 오이노마오스 왕과 전차 경주를 겨룬 영웅으로 유명한 인물이다. 올림피아 경기의 승자는 시와 조각상으로 칭송받았다. 올림피아 경기는 4년마다 열렸으며, 이 기간을 \\'올림피아드\\'(Olympiad)라고 했는데, 그리스인들은 이를 시간 단위로 이용하였다. 올림피아 경기는 고대 그리스에서 정기적으로 열렸던 범그리스 대회의 순환 대회 가운데 하나였다.\\n올림피아 경기는 기원전 6세기~기원전 5세기에 절정에 이르렀으나, 그 후 로마가 패권을 잡은 뒤 그리스에 영향력을 행사하면서 서서히 쇠퇴하게 된다. 고대 올림픽이 공식적으로 끝난 해는 확실히 알 수 없으나, 대부분 테오도시우스 1세 황제가 모든 이단 숭배 및 예배를 금지했던 393년을 고대 올림픽의 마지막이라고 추정한다. 다른 설에 따르면 테오도시우스의 후계자인 테오도시우스 2세가 모든 그리스 신전을 파괴하라고 명령한 426년이라고도 한다. 이렇게 올림픽이 사라진 이후로 이보다 한참 뒤인 19세기에 이르러서야 비로소 다시 올림픽 경기가 열리게 된다.\\n\\n\\n근대올림픽\\n고대 올림피아 경기를 제대로 구현한 최초의 시도는 혁명 시대의 프랑스에서 1796년부터 1798년까지 3년동안 실시했던 프랑스 국내 올림픽인 \\'공화국 올림픽\\'(L\\'Olympiade de la République)이었다. 이 대회의 종목 중에는 고대 그리스 올림피아 경기 때 행한 일부 종목도 있었다. 특히 1798년 공화국 올림픽 대회는 미터법을 최초로 스포츠에 도입시킨 대회이기도 하다. 이후 52년뒤인 1850년에는 잉글랜드 슈롭셔주의 웬록에서 올림픽급의 대회가 열리기 시작하였다. 이 대회는 1859년에 아테네에서 열렸을 때 웬록 올림픽으로 명칭이 변경되었으며 지금도 열리고 있다. 브룩스 박사는 1859년에 아테네에서 열린 올림픽 경기의 내용을 이후 경기에 채택하였다. 1866년 런던의 수정궁에서는 윌리엄 페니 브룩스가 영국의 국가 올림픽 대회를 만들었다.\\n1821년 그리스에서는 오스만 제국의 지배에 반기를 들고 독립 전쟁이 일어나면서, 이때부터 올림픽 부활에 대한 관심이 생겨났다. 시인이자 신문 편집자였던 파나요티스 수초스(Παναγιώτης Σούτσος)는 1833년에 출간한 자신의 시 \\'망자(亡者)의 대화\\'에서 최초로 올림픽 부활에 대한 제안을 내놓았다. 그리스의 부유한 박애주의자였던 에방겔리스 자파스(Ευαγγέλης Ζάππας)는 1859년에 아테네 시 광장에서 열린 \"올림픽 경기(일명 자파스 올림픽)\"를 후원하였다. 이 경기에는 그리스와 오스만 제국 출신의 선수들이 참가하였다. 에방겔리스 자파스는 이후에도 올림픽 경기를 개최할 수 있도록 고대의 경기장이었던 파나티네코 경기장을 복원하는 데도 돈을 썼다. 파나티네코 경기장에서 1870년과 1875년에 자파스 올림픽을 개최했으며, 현대 올림픽인 2004년 하계 올림픽 때는 양궁 경기장으로도 쓰였다.\\n역사학자였던 쿠베르탱은 프로이센-프랑스 전쟁(1870–1871)에서 프랑스의 패배 원인을 분석하면서 군사들이 체계적인 체력 훈련을 받지 않았기 때문에 전쟁에서 패배했다고 말한 인물이다. 1890년 웬록 올림픽에 참석한 쿠베르탱은 그 이후부터 올림픽을 대규모로 부활시킬 수 있으리라 생각했다. 쿠베르탱은 웬록 올림픽과 자파스 올림픽을 토대로 하여 올림픽 경기를 국제적으로 시행하기 위해 나라별로 올림픽을 번갈아가며 개최하는 방식을 생각해냈다. 그는 이 방안을 새로 설립된 국제 올림픽 위원회(IOC)의 첫 올림픽 의회 기간 중에 언급했다. 총회는 파리의 소르본 대학교에서 1894년 6월 16일부터 6월 23일까지 7일간 지속되었으며, 총회 마지막날, 2년 후인 1896년에 아테네에서 국제적 규모의 올림픽 대회를 열기로 결정되었다. IOC는 올림픽을 조직하는 데에 모든 책임을 졌으며, 초대 위원장으로는 그리스의 작가였던 디미트리오스 비켈라스(Δημήτριος Βικέλας)가 선출되었다.\\n\\n하계올림픽\\n1859년 자파스 올림픽에 참가한 선수의 수는 250명을 넘지 못했다. 에방겔리스 자파스는 \"지난 자파스 올림픽을 포함, 1896년에 개최될 2번째 올림픽을 위해 파나티네코 경기장을 보수해야 한다.\"라는 충고를 하지만, 그리스 정부는 그의 말을 듣지 않았고 결국 1896년 아테네 올림픽 준비를 위해 파나티네코 경기장은 두 번이나 정비해야 했다. 1회 대회 정식종목으로는 9종목이 있었는데 육상, 사이클, 펜싱, 체조, 사격, 수영, 테니스, 역도, 레슬링이 있었으며, 조정도 정식종목이었으나 매우 나쁜 날씨로 인해 조정 경기는 취소되었다. 펜싱 경기는 역사적 건물인 자피온(에반젤리스 자파스의 이름을 딴 것이다)에서 열렸다. 그리스의 관리들과 국민들은 올림픽 경기 개최에 열광적이었다. 많은 선수들이 이에 동감하면서 앞으로도 올림픽 대회를 아테네에서 영구히 개최해야 한다고 요구하기까지 하였다. 그러나 국제올림픽위원회(IOC)는 근대 올림픽은 순환 개최로 열리는 세계적인 행사가 되어야 한다고 생각했다. 결국 2회 올림픽은 프랑스 파리에서 열기로 결정되었다.\\n1896년 올림픽 대회의 성공을 이어서 개최된 두 번째 올림픽인 1900년 올림픽에서는 올림픽의 존폐여부를 위협받는 지경에 이르게 되었다. 1900년에 파리와 1904년에 세인트루이스에서 열린 올림픽은 하필이면 엑스포와 시간과 장소가 겹치는 바람에 빛을 바래게 된다. 1904년 대회를 예로 들면 650명의 선수단이 참가했지만 그중 580명은 미국국적을 가진 사람이었다. 1900년과 1904년의 두 올림픽 대회는 역대 올림픽중에 최저점을 기록한다. 올림픽은 1906년 올림픽이 아테네에서 개최되었을 때 다시 일어서게 된다. 또 다른 성공적인 올림픽은 그리스 올림픽 협회가 조직했으며 세 차례나 올림픽을 치른 경기장에서 개최되었다. 이 경기는 비공식 올림픽이긴 했지만 세계적으로 상당한 참가자들을 불러 모았으며 대중들에게 큰 재미를 갖다주었다. 이 때를 시작으로 올림픽의 인기와 번영이 시작되었다.\\n\\n동계올림픽\\n동계 올림픽은 눈과 얼음을 이용하는 스포츠들을 모아 이루어졌으며 하계 올림픽 때 실행하기 불가능한 종목들로 구성되어 있다. 피겨스케이팅, 아이스하키는 각각 1908년과 1920년에 하계올림픽 종목으로 들어가 있었다. IOC는 다른 동계 스포츠로 구성된 새로운 대회를 만들고 싶어 했고, 로잔에서 열린 1921년 올림픽 의회에서 겨울판 올림픽을 열기로 합의했다. 1회 동계올림픽은 1924년, 프랑스의 샤모니에서 11일간 진행되었고, 16개 종목의 경기가 치러졌다. IOC는 동계 올림픽이 4년 주기로 하계 올림픽과 같은 년도에 열리도록 했다. 이 전통은 프랑스의 알베르빌에서 열린 1992년 올림픽 때까지 지속되었으나, 노르웨이의 릴레함메르에서 열린 1994년 올림픽부터 동계 올림픽은 하계 올림픽이 끝난지 2년후에 개최하였다.\\n\\n패럴림픽\\n패럴림픽(Paralympic)은 신체·감각 장애가 있는운동 선수가 참가하는 국제 스포츠 대회로, 장애인 올림픽으로 불린다. 1948년에 루드비히 구트만 경(Sir Ludwig Guttman)은 제2차 세계대전에 참전한 군인들의 사회 복귀를 위한 일환으로 1948년 런던 올림픽과 동시에 몇몇 병원들을 연합해서 여러 경기를 펼쳤다. 구트만의 세계 휠체어, 신체부자유자대회(World Wheelchair and Amputee Games)로 알려진 이 대회는 매년 열리는 스포츠대회가 되었다. 12년이 넘도록 구트만과 다른 사람들은 스포츠를 상처를 치료하는 방법 중 하나로써 계속 대회 개최에 노력을 기울였다. 로마에서 열린 1960년 하계 올림픽때 구트만은 400명의 선수들을 \"Parallel Olympics\"에 참가시켰으며 이것이 곧 1회 패럴림픽으로 알려지게 되었다. 그 때부터 패럴림픽은 하계 올림픽이 열린 년도에 열리게 되었다. 서울에서 열린 1988년 하계 올림픽부터는 하계 올림픽을 개최한 도시는 패럴림픽도 같이 개최하기로 한다.\\n\\n오늘날의 올림픽\\n1896년 대회때는 14개국에서 241명의 선수단이 참가했지만 2008년 하계 올림픽때는 204개국에서 10,500명의 선수가 참가하는 등 세계적인 대회로 변모했다. 동계 올림픽의 규모는 하계 올림픽 규모보다 작다. 예를 들면 2006 토리노 동계 대회때는 80개국에서 2,508명의 선수가 참가했으며 82개 세부종목이 있었고, 2008 베이징 하계 대회때는 204개국, 11,508명의 선수, 302개의 세부종목이 있었다. 올림픽이 진행되는 동안 선수와 임직원들은 올림픽 선수촌에서 지낸다. 올림픽 선수촌에는 선수들을 위한 개인실이 있으며 카페테리아, 헬스 클리닉, 종교적인 시설 등 최상의 편의를 위한 시설들이 있다.\\n올림픽에 참가하는 나라는 UN에 등록된 국가의 수 193개보다 많다. 다른 국제조직이 개최하는 대회들은 정치적 주권국으로 참가를 제한하는 반면, IOC는 그에 상관없이 올림픽에 모든 공동체들이 참가할 수 있도록 한다. 이는 연합체나 공동체에서 국가올림픽위원회(NOC)를 만드는 것을 허용한다는 의미이다. 예를 들면 푸에르토리코, 버뮤다, 홍콩과 같은 곳도 올림픽에서 다른 나라와 스포츠 경쟁을 합법적으로 할 수 있다.\\n\\n국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파트너를 맺기 • 선수, 직원, 심판, 모든 사람과 기관이 올림픽 헌장을 지키는 것을 말한다. 국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다. 올림픽 활동은 크게 세 가지로 구성된다.\\n- 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다. 예를 들어서 국제 축구 연맹(FIFA)는 축구를 주관하며, 국제 배구 연맹(FIVB)은 배구를 주관하는 기구이다. 올림픽에는 현재 35개의 국제경기연맹이 있고 각 종목을 대표한다. (이 중에는 올림픽 종목은 아니지만 IOC의 승인을 받은 연맹도 있다.)\\n- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다.\\n- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원회는 올림픽이 끝나면 해산되며 최종보고서를 IOC에 제출한다.\\n올림픽의 공식언어는 프랑스어와 영어와 개최국의 공용어이다. 모든 선언(예를 들어서 개막식 때 각국 소개를 할 때)들은 세 언어가 모두 나오거나 영어나 프랑스어 중에서 한 언어로만 말하기도 한다. 개최국의 공용어가 영어나 프랑스어가 아닐 때는 당연히 그 나라의 공용어도 함께 나온다.\\n\\n국제 올림픽 위원회(이하 IOC로 지칭)는 몇몇 위원들이 한 행위에 대해서 비판을 받고 있다. 그 예로 IOC 위원장이었던 에이버리 브런디지와 후안 안토니오 사마란치가 대표적인 사람이다. 브런디지는 20년 넘게 IOC 위원장직을 맡았고 임기 중에 올림픽을 정치적으로 휘말려들지 않게 하기 위해 보호했다. 그러나 그는 남아프리카 공화국 대표단에게 아파르트헤이트와 관련된 이슈를 건드리고 반유대정책을 함으로써 비난을 받았다. 사마란치 위원장 시기 때는 족벌 정치와 부패로 비난받았다. 사마란치가 스페인에서 프랑코 정권에 협력했다는 것도 비판의 이유가 되었다.\\n1998년에 몇몇 IOC위원들이 2002년 솔트레이크 시티 동계 올림픽 유치 과정에서 미국에게 미국을 올림픽 개최지로 뽑아달라는 뇌물청탁을 받았다는 것이 폭로되었다. 이에 IOC는 사퇴한 IOC위원 4명과 강제 퇴출된 6명에 대한 조사를 했다. 이 스캔들은 이후에 개최지 선정에서 이와 같은 불미스러운 일이 일어나지 않게 하기 위해서 IOC가 개혁에 착수하도록 하는 긍정적인 역할을 하기도 했다.\\nBBC 다큐멘터리인 \\'파노라마\\'에서는 \\'매수된 올림픽\\'이란 주제로 2004년 8월에 방송을 내보내기도 했다. 이때 이 프로그램에서는 2012년 하계 올림픽의 개최지 선정과 관련된 뇌물에 대해서 조사했다. 이 다큐멘터리에서는 특정 후보 도시가 IOC 위원들에게 뇌물수수하는 것이 가능했다고 주장했으며, 특히 파리 시장이었던 베르트랑 들라노에(Bertrand Delanoë)는 영국의 총리인 토니 블레어와 런던올림픽유치위원회가 입후보 규정을 위반했다고 비난했다. 그는 당시 프랑스 대통령이었던 자크 시라크를 목격자로 내세웠지만 시라크 대통령은 이 분쟁에 휘말려드는 것을 주의했으며 인터뷰를 삼갔다. 결국 베르트랑 들라노에의 주장에 대한 조사는 체계적으로 이루어지지는 않았다. 2006년 동계 올림픽을 유치했던 토리노도 이 논쟁에서 빠져나갈 수 없었다. 이번에는 스위스 국적의 IOC위원 마크 호들러(Marc Hodler)가 이 논쟁의 중심이 되었는데, 이 위원은 스위스 시온의 경쟁 도시였던 토리노가 IOC위원들에게 뇌물수수를 했다고 말했고, 이 발언으로 광범위한 조사가 이루어졌다. 이 언행이 많은 IOC위원들이 시온에 대해 언짢게 생각하게 되고 토리노가 개최지로 선정되도록 도와주는 역할을 했을 가능성도 제기되고 있다.\\n\\n올림픽 경기 종목\\n올림픽 경기 종목은 총 33개부문 52개 종목에서 약 400개의 경기로 이루어져있다. 예를 들어서 하계 올림픽 부문인 레슬링은 자유형과 그레코로만형의 두 종목으로 나뉜다. 여기에서 10경기는 남자부, 4경기는 여자부로 열리며 분류기준은 체중이다. 하계 올림픽은 26개, 동계 올림픽은 7개 부문으로 이루어져있다. 하계 올림픽에서는 육상, 수영, 펜싱, 체조가 1회 대회때부터 한번도 빠짐없이 정식종목이었으며, 동계 올림픽에서는 크로스컨트리, 피겨 스케이팅, 아이스 하키, 노르딕 복합, 스키 점프, 스피드 스케이팅이 1924년 동계 올림픽부터 빠짐없이 정식종목이었다. 배드민턴, 농구, 배구와 같은 정식종목들은 처음에는 시범종목이었으며 그 후에 정식종목으로 승인 되었다. 야구처럼 예전에는 정식종목 이었지만 지금은 정식 종목에서 빠진 종목도 있다.\\n\\n각 올림픽 종목들은 IOC로부터 승인을 받은 국제경기연맹의 관리를 받는다. 35개의 연맹이 IOC에서 승인을 받았으며, 승인을 받았지만 현재 정식종목이 아닌 종목을 감독하는 연맹도 있다. IOC의 승인을 받았지만 올림픽 종목이 아닌 스포츠들은 올림픽 종목으로 고려되지는 않으나, 올림픽이 끝난 후 처음으로 열리는 IOC총회 때마다 정식종목이 되도록 신청을 할 수는 있다. IOC 총회 때 정식종목 선정은 총회에 참석중인 IOC위원들의 투표를 통해 이루어지며, 재적 위원 수의 과반수 이상 찬성표를 얻어야 정식종목으로 인정을 받는다. IOC의 승인을 받은 스포츠이나 찬성표를 받지 못해 정식종목이 되지 못한 스포츠로는 체스와 서핑과 같은 것이 있다.\\n\\n2004년 10월과 11월에 IOC는 \\'올림픽 프로그램 위원회\\'(Olympic Programme Commission)를 설립했다. 여기서는 올림픽 종목과 올림픽 종목이 아닌 스포츠를 모두 재검토하는 일을 한다. 이 위원회의 목표는 올림픽 종목에 더 체계적으로 다가가는 것이다. 위원회에서는 우선적으로 올림픽 종목으로 포함되기 위해서는 7개의 기준을 충족시켜야 한다고 말한다. 이 7개의 기준은 역사, 전통, 보편성, 인기도와 잠재성, 선수의 건강, 연맹의 스포츠를 관리할만한 능력, 스포츠를 여는 데에 필요한 비용이다. 예를 들면 2012년 하계 올림픽의 정식종목 후보에 7개 조건을 포함한 비(非)올림픽 스포츠가 올랐고 그 내용은, 골프, 가라테, 럭비, 인라인 스케이팅, 스쿼시였다. 이 스포츠들은 IOC 상임이사회에서 재검토되어 2005년 7월에 열린 싱가포르 총회에서 최종 결정하기로 했다. 결국 5개 중 2개(가라테와 스쿼시) 가 최종 후보로 올라왔으나 가라테와 스쿼시 둘 다 2/3의 미만의 찬성표로 정식종목이 되지는 못한다. 그 후 2016년 올림픽 정식종목에는 7개의 스포츠가 정식종목 신청을 했는데, 내용은 가라테, 골프, 스쿼시, 야구, 소프트볼, 7인제 럭비, 인라인 스케이팅이었다. 2009년 8월 13일, 신청된 7개의 스포츠 중 단 2개만 최종후보로 선정되었는데, 이는 7인제 럭비와 골프였다. 같은해인 2009년 10월에 열린 IOC 총회에서 골프와 럭비는 과반수 이상의 득표를 얻어서 2016년 하계 올림픽과 2020년 하계 올림픽의 정식종목으로 채택되었다.\\n2002년에 열린 제114차 IOC 총회에서는 하계 올림픽 종목은 최대 28부문 301개 경기에 10,500명이 참가하는 것으로 제한하기로 결정했다.그 후 3년 뒤인 제117차 IOC 총회에서는 정식종목이었던 야구와 소프트볼을 정식 종목에서 제외시킨다. 이 결과에 대한 이견이 없었으므로 2012년 올림픽 때는 26개부문에서 경기가 열린다. 2016년과 2020년 올림픽 때는 럭비와 골프가 추가되어 다시 28개부문에서 경기가 열린다.\\n프로 NHL선수들은 1998년부터 아이스 하키종목에 출전할 수 있게 되었다. (나가노 올림픽 결승전 러시아 vs 체코).\\n영국 명문 공립 학교의 이념은 쿠베르탱에게 큰 영향을 끼쳤다. 영국 공립 학교는 스포츠를 교육의 중요한 부분이라 생각해서 \\'건전한 신체에 건전한 정신을\\'이라는 의미를 가진 라틴어 mens sana in corpore sano를 표어로 삼았다. 이 이념에 의하면 신사들은 특정한 분야에서만 우수해서는 안되고 모든 분야에서 고르게 잘해야 하고, 공정한 결과에는 승복해야 하며, 연습이나 훈련은 속이는 것과 마찬가지로 여겼다. 전문적으로 스포츠를 연습한 사람은 취미로 연습한 사람에 비해 공평하지 않다고 생각한 것이다.\\n\\n현대 올림픽에서는 프로 선수의 참가 불허가 많은 분쟁을 가져왔다. 1912년 하계 올림픽의 근대 5종 경기와 10종 경기에서 우승한 짐 소프는 올림픽에 나가기 전에 준프로야구선수로 활동했다는 게 나중에 밝혀져 메달이 박탈되었다. 소프는 후에 동정적 여론의 힘을 업고 1983년에 메달을 돌려받게 된다. 1936년 동계 올림픽 때 스위스와 오스트리아 스키선수들은 돈을 벌기 위해 스포츠를 했는데 이러한 행동이 아마추어 정신에 위배된다고 결정되어 그들은 스키종목에 참가할 수 없었다.\\n20세기에 이르러서 계급구조가 붕괴되면서 이른바 귀족적인 신사라는 아마추어 선수에 대한 정의는 시대에 뒤처지는 말이 되게 된다. 일부 국가들은 \\'정식 아마추어 선수\\'를 \\'키워서\\' 순수한 아마추어 정신을 벗어나고 있었고, 자신이 내는 비용으로 연습하는 선수들의 불리함에 대한 목소리가 나오기 시작했다. 하지만 IOC는 아마추어 정신에 관한 입장을 고수했다. 1970년대 초에는 아마추어 정신이 올림픽헌장에서 폐지되어야 한다는 말이 나오기 시작했다. 결국 프로선수들의 출전은 국제경기연맹(IF)에서 결정짓도록 되었다. 2008년 기준으로 아마추어 선수만 출전하고 있는 올림픽 종목은 복싱이 유일하며 남자 축구에서는 나이가 23세 이상인 선수를 3명까지만 선발할 수 있다. 이는 아마추어 정신을 지키기 위한 일환으로 볼 수 있다.\\n\\n논란\\n올림픽에서 첫 번째 보이콧은 1956년 하계 올림픽에서 시작되었다. 네덜란드, 스페인, 스위스는 소련의 헝가리 침공에 항의해 참가를 거부했다. 캄보디아, 이집트, 이라크, 레바논은 제2차 중동 전쟁 때문에 보이콧했다. 1972년과 1976년 올림픽에는 많은 아프리카의 국가들이 남아프리카 공화국과 로디지아에서 일어나는 인종 차별정권에 대한 항의의 표시로 올림픽 참가를 거부했다. 이 보이콧에는 뉴질랜드도 관계가 되어있는데, 뉴질랜드 럭비 국가 대표팀이 당시 아파르트헤이트정책을 쓰던 남아프리카 공화국과 경기를 했음에도 불구하고 뉴질랜드의 올림픽 참가가 허용되었기 때문이었다. 국제 올림픽 위원회는 이 두 보이콧에 대해 심각하게 고민했으나 후자의 뉴질랜드의 경우는 럭비가 올림픽 종목이 아니라는 이유를 내세워 뉴질랜드의 올림픽 참가 금지 요청을 거부했다. 당시 아프리카에 속해 있던 20개국과 가이아나, 이라크는 경기를 끝낸 선수들이 있었지만 탄자니아가 이끄는 올림픽 보이콧에 가세했다. 중화민국(타이완)도 1976년 몬트리올 올림픽 참가를 보이콧했는데, 그 이유는 중화인민공화국(중국)이 몬트리올 올림픽 조직위원회에게 타이완을 \\'중화민국\\'의 이름으로 참가하지 못하도록 압박을 가했기 때문이다. 타이완은 이것에 반발해서 중화민국의 국기와 중화민국의 국가를 계속 쓸 것이라고 밝혔다. 타이완은 1984년까지 올림픽에 참가하지 않았으며 그 후 참가할 때는 중화 타이베이 올림픽기와 특별한 찬가를 사용한다. 1980년과 1984년 올림픽 때는 냉전의 당사국들이 각각 반대진영에서 개최된 올림픽에 불참했다. 1980년에 열린 모스크바 올림픽 때는 소련의 아프가니스탄 침공에 대한 항의의 표시로 미국을 비롯한 65개국이 불참해서 1956년 이후 가장 적은 국가의 수인 81개국만 참가하는 대회가 되었다. 1984년에 열린 L.A 올림픽때는 루마니아와 유고슬라비아를 제외한 소련과 동구권의 14개 국가가 자국 선수들의 안전을 보장받지 못한다는 이유로 올림픽에 불참했다. 소련의 한 관계자는 그들이 올림픽 보이콧을 한 것에 대해 다음과 같은 발언을 통해 지지했다.\\n\"미국에서 광적인 애국심과 반소련 세력이 점점 늘어나고 있다.\"\\n동구권에서 보이콧을 한 국가들은 올림픽을 대신할 대회로 프렌드십 게임을 7월과 8월에 했다.\\n2008년에는 티베트와 다르푸르에 관한 중국의 인권문제를 두고 그에 대한 항의 표시로 중국산 물품의 불매운동과 2008 올림픽 불참에 대한 요구가 컸으나 보이콧을 한 나라는 없었다. 2008년 8월, 조지아 정부는 러시아가 2008년 남오세티야 전쟁에 참전한 것과 관련하여 러시아의 소치에서 열릴 2014년 동계 올림픽을 보이콧하자고 요청했다. 이에 대해 국제 올림픽 위원회는 \"앞으로 개최될 때까지 6년이나 남았는데 시작하기도 전에 섣불리 이른 판단을 하는 것은 옳지 않다.\"라고 말했다.\\n\\n쿠베르탱이 말했던 원래 이념과는 반대로 올림픽이 정치 혹은 체제 선전의 장으로 이용되는 경우가 있었다. 1936년 하계 올림픽을 개최할 때 당시의 나치독일은 나치는 자비롭고 평화를 위한다는 것을 설명하고 싶어했다. 또 이 올림픽에서 아리안족의 우월함을 보여줄 생각이었으나 이는 흑인이었던 제시 오언스가 금메달을 4개나 따내면서 실현되지는 못했다. 소련은 헬싱키에서 열린 1952년 하계 올림픽 때 처음으로 참가했다. 그 전에는 소련이 조직한 스파르타키아다라는 대회에 1928년부터 참가했었다. 다른 공산주의 국가들은 1920년대와 1930년대의 전쟁 기간 사이에 노동자 올림픽(Socialist Workers\\' Sport International)을 조직했는데, 이는 올림픽을 자본가와 귀족들의 대회로 여기고 그에 대한 대안으로 고안된 대회였다. 그 이후 소련은 1956년 하계 올림픽부터 1988년 하계 올림픽까지 엄청난 스포츠강국의 면모를 보여주며 올림픽에서의 명성을 드높였다.\\n선수 개인이 자신의 정치적 성향에 대해 표현하기도 했다. 멕시코 시티에서 열린 1968년 하계 올림픽의 육상부문 200m 경기에서 각각 1위와 3위를 한 미국의 토미 스미스와 존 카를로스는 시상식 때 블랙 파워 설루트(Black Power salute , 흑인 차별 반대 행위)를 선보였으며 2위를 한 피터 노먼도 상황을 깨닫고 스미스와 카를로스의 행위를 지지한다는 뜻에서 급하게 인권을 위한 올림픽 프로젝트(OPHR) 배지를 달았다. 이 사건에 대해서 IOC 위원장이었던 에이버리 브런디지는 미국 올림픽 위원회에 이 두 선수를 미국으로 돌려보내거나 미국 육상팀 전부를 돌려보내는 둘 중 하나의 선택을 하게 했고, 미국 올림픽 위원회는 두 선수를 미국으로 돌려 보낸다.\\n현재 이란 정부는 이스라엘과의 어떤 경기 경쟁이든 피하고 있다. 2008년 하계 올림픽 때 이란의 수영 선수는 이스라엘 수영 선수와 같이 경기한다는 이유로 경기를 포기했으며, 2004년 하계 올림픽에서도 이란의 유도 선수는 이스라엘 선수와 경기한다는 일정이 잡혔을 때 경기를 포기했다. 이 선수는 공식적으로는 시합전에 계체량을 재서 체중이 초과되어 실격 되었으나 이란정부로부터 125,000달러나 되는 돈을 받았다고 한다.\\n\\n20세기 초반, 많은 운동 선수들은 기록향상을 위해 약물을 복용하기 시작했다. 예를 들어 1904년 하계 올림픽 마라톤에서 우승한 미국 선수 토머스 J. 힉스는 코치에게서 스트리크닌과 브랜디를 받았다. 올림픽에서 약물을 과다 복용으로 사망한 사례도 한 번 있었다. 1960년 로마 대회 때 사이클 개인도로 경기 중에 덴마크 선수인 크누드 에네마르크 옌센이 자전거에서 떨어져서 사망했다. 검시관들의 조사에 의하면 그의 죽음의 원인은 암페타민 과다 복용이라고 했다. 이에 1960년대 중반부터 각 경기 연맹은 약물 복용을 금지하기 시작했으며 1967년에는 IOC도 약물 복용 금지에 동참했다.\\n올림픽에서 약물 복용 양성 반응이 나와서 메달을 박탈당한 첫 번째 사례로는 1968년 하계 올림픽의 근대 5종 경기에 출전해 동메달을 딴 한스 군나르 리렌바르가 있다. 그는 경기 후 도핑검사 결과 알코올을 복용한 것으로 확인되어 메달을 박탈당했다. 도핑 양성 반응으로 메달을 박탈당한 것으로 가장 유명한 사람은 1988년 하계 올림픽 육상 100m 경기에서 금메달을 땄으나 도핑 검사 결과 스타노졸롤을 복용한 것으로 확인돼 금메달을 박탈당한 캐나다 선수인 벤 존슨이 있다. 이에 따라 금메달은 2위를 했던 칼 루이스가 대신 받았다.\\n1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.\\n쿠베르탱의 생각과는 달리, 올림픽이 세계에 완벽한 평화를 가져다주지는 못했다. 실제로 제1차 세계대전으로 인해 독일 베를린에서 열리기로 했던 제6회 1916년 하계 올림픽이 취소되었고, 제2차 세계대전 때는 일본 도쿄에서 열리기로 했던 제12회 1940년 하계 올림픽, 삿포로에서 열리기로 했던 1940년 동계 올림픽, 영국 런던에서 열리기로 했던 제13회 1944년 하계 올림픽, 이탈리아 코르티나담페초에서 열릴 예정인 1944년 동계 올림픽이 취소되었다. 베이징에서 열린 2008년 하계 올림픽 개막식날 조지아와 러시아 간의 2008년 남오세티아 전쟁이 일어나기도 했다. 부시 대통령과 푸틴 대통령이 이 올림픽을 보러 왔으며 중국 주석인 후진타오가 주최한 오찬에 참석해서 이 현안에 대해 논의하기도 했다. 조지아 대표인 니노 살루크바체와 러시아 대표인 나탈리야 파데리나가 여자 10m 공기권총 경기에서 각각 동메달과 은메달을 땄을 때 이 일은 베이징 올림픽의 유명한 사건 중 하나로 남게 되었다. 살루크바체와 파데리나는 시상식이 끝난 뒤 서로 포옹을 하며 국적에 상관없이 기쁨을 나누었다.\\n테러도 올림픽에서 공포의 대상이었다. 뮌헨 참사로 알려진 1972년에 서독 바이에른의 뮌헨에서 열린 하계 올림픽때의 사건은 테러리스트인 검은 9월단이 일으킨 사건으로서 이스라엘 선수 11명을 인질로 붙잡았다가 전원이 사망한 사건이다. 당시 미숙한 진압으로 인해 인질 9명(선수 1명과 코치 1명은 인질로 잡기 이전에 살해), 테러범 5명, 독일 경찰관 1명이 사망했으며 이 진압 작전 이전에는 인질들은 단 한 명도 죽지 않았다. 애틀란타에서 열린 1996년 하계 올림픽 때는 센테니얼 올림픽 공원(Centennial Olympic Park)에서 폭발 사건이 일어나 2명이 죽고 111명이 다치는 사건이 발생했다. 이 사건의 주모자 에릭 로버트 루돌프는 종신형을 선고받았다. 참고로 마라톤 역시 전쟁에서 유래한 것이다.\\n\\n개최지 선정\\n올림픽 개최지는 해당 올림픽 개최 7년 전에 IOC 위원들의 투표로 결정된다. 개최지 선정에는 약 2년이 걸린다. 유치를 희망하는 도시는 우선 자국의 올림픽 위원회에 신청을 해야 한다. 만약 한 국가에서 두 도시 이상이 유치를 희망한다면, 한 국가당 한 도시만 후보가 될 수 있다는 규칙에 따라 내부적으로 후보 도시를 결정해야 한다. 후보 도시가 결정되면 후보 도시가 소속된 국가의 올림픽 위원회는 IOC에 개최 신청을 하고, 신청 후에는 올림픽 개최에 대한 질의 응답서를 보내야 한다. 이 질의응답서에서 신청한 도시는 올림픽 헌장을 준수하며 IOC 상임이사회에 의한 다른 규정들을 지킬 것이라는 확신을 주어야 한다. 이 질의응답서는 전문가들이 검토하여 신청 도시들의 잠재성과 계획을 평가한다. 이 전문적인 평가를 바탕으로 IOC 상임이사회에서는 신청도시 중에서 후보도시를 고른다.\\n후보도시로 선택되면 그 도시들은 IOC에 보내는 후보도시에 관한 문서에 그들의 계획을 더욱 상세하고 방대한 양으로 적어서 보내야 한다. 평가조사단들이 이 후보도시들을 평가한다. 평가조사단은 후보도시들을 방문해서 지역 관계자들과 회견을 갖고 경기장 시설을 세심하게 조사한 뒤 개최지 투표를 하기 한달전에 조사를 바탕으로 한 공식 보고를 한다. 회견을 하는 동안에도 후보도시들은 자신들이 올림픽을 개최하는 데 충분한 자금이 조달될 수 있는지 등을 입증할 수 있어야 한다. 평가조사단의 업무가 끝나면 후보지의 국가 위원들은 IOC 정기총회에 참석한다. 이 총회에서 IOC 위원들은 올림픽 개최지를 선정하게 되며 후보지의 국가에 소속된 위원들은 자국의 후보지가 탈락하지 않는 이상 투표를 할 수 없다. 투표가 끝난후에 개최지로 선정된 곳의 유치위원회가 IOC와 개최도시 계약서에 서명을 하면 공식적으로 올림픽 개최도시(개최국)으로 인정된다.\\n2016년까지 올림픽은 23개국 44개 도시에서 열렸으며 유럽과 북아메리카대륙 이외의 대륙에서는 고작 8번 밖에 개최하지 못했다. 1988년 하계 올림픽이 대한민국의 서울에서 열린것을 시작으로 그 후 아시아와 오세아니아 대륙에서 올림픽이 4번이나 열렸으며, 이는 그 이전의 현대 올림픽사와 비교해보면 엄청나게 늘어난 수치였다. 2016년 하계 올림픽이 개최된 브라질의 리우데자네이루는 남미에서 열리는 첫 번째 올림픽이다. 아직 아프리카에서는 올림픽이 한 번도 개최되지 않았다. 2008년 하계 올림픽 때 가장 많은 선수가 참여한 나라는 중국으로 639명이 참가했으며 그 다음은 미국과 러시아로 각각 596명과 455명이 참가했다.\\n미국은 5번의 하계 올림픽과 4번의 동계 올림픽을 개최하면서 최다 올림픽을 개최한 나라이다. 영국은 2012년에 3번째 올림픽을 개최하였다. 독일, 오스트레일리아, 그리스는 하계 올림픽을 2번 개최한 국가이다. 동계 올림픽에서는 이탈리아가 2026년 밀라노-코르티나담페초 개최지로 선정되어 3번 개최될 예정이다. 또한 프랑스가 3번을 개최했으며 2024년 하계올림픽 개최예정으로 영국에 이번 두 번째로 한 도시에서 3번 올림픽 개최하며 하계올림픽3번 개최하였다. 프랑스는 동계, 하계 올림픽 각 3번씩 총 6번 개최로 9번으로 최다개최국인 미국 다음으로 두 번째로 많이 개최한 국가가 된다. 스위스, 오스트리아, 노르웨이, 일본, 이탈리아는 2번씩 개최했다. 일본은 하계,동계 각 2번씩 총 4번으로 미국, 프랑스 다음 세번째로 많이 개최한 국가이다. 2010년에 밴쿠버에서 열린 2010년 동계 올림픽은 캐나다에서 열리는 두 번째 동계 올림픽이고, 동/하계 올림픽을 합쳐 캐나다에서 3번째로 개최되는 올림픽이다.\\n\\n우승자와 메달리스트\\n개인 혹은 팀으로 경기에 출전해서 1위, 2위, 3위를 한 선수는 메달을 받는다. 1912년까지는 우승자에게 순금으로 된 금메달을 주었으며 그 후에는 도금된 금메달을 준다. 하지만, 2010 동계 올림픽에서는 전자제품 부속품을 녹여서 넣었다. 이러한 경우처럼 순금 외에 다른 물질을 넣을 경우에는 순금이 반드시 6g 이상을 함유하고 있어야 한다. 2위를 한 선수는 은메달을, 3위를 한 선수는 동메달을 받는다. 토너먼트로 진행되는 종목의 경우에는(복싱, 태권도 등) 3위를 구분하지 않고 준결승에서 패해서 3/4위전으로 간 선수들에게 모두 동메달을 수여한다. 1896년 하계 올림픽에서는 메달이 2개만 수여됐는데 1위에게 은메달을 주었고 2위에게 동메달을 주었다. 이때 3위에게는 아무것도 없었다. 현재의 메달 수여 방식은 1904년 하계 올림픽 때부터 시작되었다. 1948년부터는 4, 5, 6위를 한 선수에게는 인증서를 수여했다. 1984년 대회부터는 7, 8위를 한 선수에게도 인증서를 수여했다. 아테네에서 열린 2004년 하계 올림픽 때는 1, 2, 3위 선수에게 메달과 함께 올리브 화환도 같이 수여했다. 국가 올림픽 위원회(NOC)와 방송사에서는 자국의 메달 현황을 실시간으로 전달하기도 한다.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec8523a-e87c-4214-aee9-c1aa8d1745c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽\n",
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하\n"
     ]
    }
   ],
   "source": [
    "# 문서 내용\n",
    "print(docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afdf1c6-436e-4026-a178-7c8b48c360ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'data/olympic.txt'}\n",
      "{'source': 'data/olympic.txt', 'category': '스포츠', 'tag': ['올림픽', '동계올림픽', 'IOC']}\n"
     ]
    }
   ],
   "source": [
    "# 문서 관련 정보\n",
    "print(docs[0].metadata)\n",
    "docs[0].metadata['category'] = \"스포츠\"\n",
    "docs[0].metadata['tag']=['올림픽', '동계올림픽', \"IOC\"]\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbbd08-6afc-4f2f-985b-c96da7c3b943",
   "metadata": {},
   "source": [
    "### PDF\n",
    "- PyPDF, Pymupdf 등 다양한 PDF 문서를 읽어들이는 파이썬의  3rd party library들을 이용해 pdf 문서를 Load 한다.\n",
    "    - https://python.langchain.com/docs/integrations/document_loaders/#pdfs\n",
    "- 각 PDF Loader 특징\n",
    "    -  PyMuPDFLoader\n",
    "        -   텍스트 뿐 아니라 이미지, 주석등의 정보를 추출하는데 성능이 좋다.\n",
    "        -   PyMuPDF 라이브러리 기반\n",
    "    - PyPDFLoader\n",
    "        - 텍스트를 빠르게 추출 할 수있다.\n",
    "        - PyPDF2 라이브러리 기반. 경량 라이브러리로 빠르고 큰 파일도 효율적으로 처리한다.\n",
    "    - PDFPlumberLoader\n",
    "        - 표와 같은 복잡한 구조의 데이터 처리하는데 강력한 성능을 보여준다. 텍스트, 이미지, 표 등을 모두 추출할 수 있다. \n",
    "        - PDFPlumber 라이브러리 기반\n",
    "- 설치 패키지\n",
    "    - DocumentLoader와 연동하는 라이브러리들을 설치 해야 한다.\n",
    "    - `pip install pypdf -qU`\n",
    "    - `pip install pymupdf -qU`\n",
    "    - `pip install pdfplumber -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9647515-7c2d-447d-a4e4-d70a18e4e025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m10 packages\u001b[0m \u001b[2min 388ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pypdfium2 \u001b[2m(3.0MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pymupdf \u001b[2m(17.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pdfminer-six \u001b[2m(5.4MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pypdfium2\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pdfminer-six\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pymupdf\n",
      "\u001b[2mPrepared \u001b[1m5 packages\u001b[0m \u001b[2min 738ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m8 packages\u001b[0m \u001b[2min 218ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==46.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpdfminer-six\u001b[0m\u001b[2m==20251107\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpdfplumber\u001b[0m\u001b[2m==0.11.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.23\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpymupdf\u001b[0m\u001b[2m==1.26.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypdf\u001b[0m\u001b[2m==6.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypdfium2\u001b[0m\u001b[2m==5.2.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv pip install pypdf pymupdf pdfplumber "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dad4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import (PyPDFLoader, \n",
    "                                                  PyMuPDFLoader, \n",
    "                                                  PDFPlumberLoader)\n",
    "\n",
    "path = \"data/novel/동백꽃_김유정.pdf\"\n",
    "# loader = PyPDFLoader(path, mode=\"single\") \n",
    "# mode: single - 한개문서로 읽는다., page(default): page별로 doc를 만든다.\n",
    "# loader = PyMuPDFLoader(path)\n",
    "loader = PDFPlumberLoader(path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d588e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/novel/동백꽃_김유정.pdf',\n",
       " 'file_path': 'data/novel/동백꽃_김유정.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 16,\n",
       " 'Author': 'Unknown',\n",
       " 'CreationDate': \"D:20241124070355+00'00'\",\n",
       " 'Creator': 'Wikisource',\n",
       " 'ModDate': \"D:20241124070356+00'00'\",\n",
       " 'Producer': 'Wikisource',\n",
       " 'Title': '동백꽃'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c78a714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b30919fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "for doc in docs:\n",
    "    doc.metadata['author'] = '김유정'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebacac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/novel/동백꽃_김유정.pdf',\n",
       " 'file_path': 'data/novel/동백꽃_김유정.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 16,\n",
       " 'Author': 'Unknown',\n",
       " 'CreationDate': \"D:20241124070355+00'00'\",\n",
       " 'Creator': 'Wikisource',\n",
       " 'ModDate': \"D:20241124070356+00'00'\",\n",
       " 'Producer': 'Wikisource',\n",
       " 'Title': '동백꽃',\n",
       " 'author': '김유정'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdbd7f13-c4d5-4db7-b5d7-27de7984624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쌩이질을 하는 것은 다 뭐냐. 그것도 발소리를 죽여 가지고\n",
      "등뒤로 살며시 와서,\n",
      "\"얘! 너 혼자만 일하니?\"\n",
      "하고 긴치 않는 수작을 하는 것이다.\n",
      "어제까지도 저와 나는 이야기도 잘 않고 서로 만나도 본체\n",
      "만 척하고 이렇게 점잖게 지내던 터이련만 오늘로 갑작스레\n",
      "대견해졌음은 웬일인가. 항차 망아지만 한 계집애가 남 일하\n",
      "는 놈 보구…….\n",
      "\"그럼 혼자 하지 떼루 하디?\"\n",
      "내가 이렇게 내배앝는 소리를 하니까,\n",
      "\"너 일하기 좋니?\"\n",
      "또는,\n",
      "\"한여름이나 되거든 하지 벌써 울타리를 하니?\"\n",
      "잔소리를 두루 늘어놓다가 남이 들을까 봐 손으로 입을 틀어\n",
      "막고는 그 속에서 깔깔댄다. 별로 우스울 것도 없는데 날씨\n",
      "가 풀리더니 이 놈의 계집애가 미쳤나 하고 의심하였다. 게\n",
      "다가 조금 뒤에는 제 집께를 할금 할금 돌아보더니 행주치마\n",
      "의 속으로 꼈던 바른손을 뽑아서 나의 턱밑으로 불쑥 내미는\n",
      "것이다. 언제 구웠는 지 더운 김이 홱 끼치는 굵은 감자 세\n",
      "개가 손에 뿌듯이 쥐였다.\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e04a93",
   "metadata": {},
   "source": [
    "### CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "196a703e-dd86-4cb5-82bf-8b6726aea0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "path = \"data/boston_hosing.csv\"\n",
    "loader = CSVLoader(path)\n",
    "docs = loader.load() # 행 단위로 Document를 생성.\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72b48400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/boston_hosing.csv', 'row': 10}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[10].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96a54a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM: 0.22489\n",
      "ZN: 12.5\n",
      "INDUS: 7.87\n",
      "CHAS: 0.0\n",
      "NOX: 0.524\n",
      "RM: 6.377\n",
      "AGE: 94.3\n",
      "DIS: 6.3467\n",
      "RAD: 5.0\n",
      "TAX: 311.0\n",
      "PTRATIO: 15.2\n",
      "B: 392.52\n",
      "LSTAT: 20.45\n",
      "MEDV: 15.0\n"
     ]
    }
   ],
   "source": [
    "print(docs[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a3adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "888231c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m9 packages\u001b[0m \u001b[2min 209ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 140ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlxml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.8.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install requests beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507b334-e33b-435f-8a50-7dd31fa6da6b",
   "metadata": {},
   "source": [
    "### Web 문서 로드\n",
    "\n",
    "#### WebBaseLoader를 이용해 Web 문서로딩\n",
    "\n",
    "requests와 BeautifulSoup을 이용해 web 페이지의 내용을 크롤링해서 Document로 loading한다.\n",
    "\n",
    "- 주요 파라미터\n",
    "  - **web_paths***: str | list[str]\n",
    "    - 크롤링할 대상 URL\n",
    "  - **requests_kwargs**: dict\n",
    "    - requests.get() 에 전달할 파라미터를 dict로 전달. (key: parameter변수명, value: 전달할 값)\n",
    "    - headers, cookies, verify 등 설정 전달\n",
    "  - **header_template**: dict\n",
    "    - HTTP Header 에 넣을 값을 dict 로 전달.\n",
    "  - **encoding**\n",
    "    - requests의 응답 encoding을 설정 (bs_kwargs의 from_encoding 보다 상위에서 적용됨)\n",
    "  - **bs_kwargs**\n",
    "    - BeautifulSoup initializer에 전달할 파라미터를 dict로 전달. (key: parameter변수명, value: 전달할 값)\n",
    "    -  주요 옵션\n",
    "       - **parse_only**: 요청 페이지에서 특정 요소만 선택해서 가져오기. **SoupStrainer를 사용**한다.\n",
    "         - BeautifulSoup의 `SoupStrainer` 를 이용해 페이지의 일부분만 가져오기\n",
    "           - 웹 페이지를 파싱(parse, 구조 분석)할 때, 페이지 전체가 아닌 특정 부분만 필요한 경우가 많다. BeautifulSoup 라이브러리의 SoupStrainer를 사용하면, 원하는 태그나 속성이 있는 요소만 골라서 파싱할 수 있다.\n",
    "           - BeautifulSoup(\"html문서\", parse_only=Strainer객체)\n",
    "               - Strainer객체에 지정된 영역에서만 내용 찾는다.\n",
    "           - `SoupStrainer(\"태그명\")`, `SoupStrainer([\"태그명\", \"태그명\"])`\n",
    "             - 지정한 태그 만 조회\n",
    "           - `SoupStrainer(name=\"태그명\", attrs={속성명:속성값})`\n",
    "             -  지정한 태그 중 속성명=속성값인 것만 조회\n",
    "        - **from_encoding**: Encoding 설정 \n",
    "          - \"from_encoding\":\"utf-8\"\n",
    "   - **bs_get_text_kwargs**:\n",
    "     - BeautifulSoup객체.get_text() 에 전달할 파라미터 dict로 전달. (key: parameter변수명, value: 전달할 값)\n",
    "     - **RAG 구축시 `separator` 와 `strip=True` 으로 설정하는 것이 좋다.** (RAG 품질을 위해 강력히 권장되는 설정이다.)\n",
    "       -  get_text() 는 기본적으로 태그를 제거하고 텍스트만 이어 붙여 반환한다. `separator=구분자문자` 를 지정하여 추출된 텍스트 요소들 사이에 원하는 구분자를 지정할 수있다. `\\n` 을 구분자로 사용하면 텍스트 블록 사이에 줄바꿈이 들어가 **문단의 구조를 어느정도 살릴 수 있다.**\n",
    "       -  웹 문서의 줄바꿈도 포함해서 읽기 때문에 공백과 줄바꿈이 혼재된 상태로 반환된다. `strip=True`로 설정하면 추출된 문자 앞뒤의 공백 문자들을 제거할 수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da98b0ba-97ac-445d-85c8-1e000299f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------기본-----\n",
      "\n",
      "\n",
      "제목 내용\n",
      "다음문단\n",
      "다음 내용\n",
      "\n",
      "\n",
      "------strip=True-------\n",
      "제목내용다음문단다음 내용\n",
      "----------strip=True, separator=----------\n",
      "제목\n",
      "\n",
      "내용\n",
      "\n",
      "다음문단\n",
      "\n",
      "다음 내용\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_txt = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<p><b>제목</b>  <span>내용</span></p>\n",
    "<p>다음문단</p>\n",
    "<div>다음 내용</div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "soup = BeautifulSoup(html_txt)\n",
    "# 태그 빼고 text만 추출 -> get_text()\n",
    "txt1 = soup.get_text()\n",
    "print(\"-------기본-----\")\n",
    "print(txt1)\n",
    "\n",
    "txt2 = soup.get_text(strip=True) # 좌우 공백문자(공백, 엔터) 제거\n",
    "print(\"------strip=True-------\")\n",
    "print(txt2)\n",
    "\n",
    "txt3 = soup.get_text(strip=True, separator=\"\\n\\n\") # 각 태그의 text를 지정한 구분자로 나눈다.\n",
    "print(\"----------strip=True, separator=----------\")\n",
    "print(txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a405f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# 크롬: my user agent 로 검색\n",
    "# USER AGENT를 환경변수에 등록\n",
    "os.environ['USER_AGENT'] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d293719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls= [\n",
    "    \"https://m.sports.naver.com/kbaseball/article/076/0004357999\",\n",
    "    \"https://m.sports.naver.com/kfootball/article/425/0000177935\"\n",
    "]\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=urls,\n",
    "    default_parser=\"lxml\"  # BeautifulSoup(문서, 'lxml')\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404b5826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'ko',\n",
      " 'source': 'https://m.sports.naver.com/kbaseball/article/076/0004357999',\n",
      " 'title': '떠난 김현수의 5번자리는 누가? 홈런치는 포수, 김현수가 인정한 연습벌레, 1대 롤렉스맨. 염갈량의 선택은'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc73b892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "떠난 김현수의 5번자리는 누가? 홈런치는 포수, 김현수가 인정한 연습벌레, 1대 롤렉스맨. 염갈량의 선택은NAVER스포츠뉴스엔터메뉴홈야구해외야구축구해외축구농구배구N골프일반e스포츠아웃도어NEW뉴스영상일정순위포토K-BASEBALL홈 바로가기NAVER스포츠뉴스엔터스포츠야구해외야구축구해외축구농구배구N골프일반e스포츠아웃도어콘텐츠오늘의 경기승부예측연재이슈톡대학스포츠랭킹기타고객센터공식 블로그메뉴 닫기본문 바로가기떠난 김현수의 5번자리는 누가? 홈런치는 포수, 김현수가 인정한 연습벌레, 1대 롤렉스맨. 염갈량의 선택은입력2025.12.22. 오전 12:40기사원문공감좋아요0슬퍼요0화나요0팬이에요0후속기사 원해요0텍스트 음성 변환 서비스본문 듣기를 종료하였습니다.글자 크기 변경공유하기9일 서울 롯데호텔월드에서 KBO 골든글러브 시상식이 열렸다. KBO 올해의 감독상을 수상한 LG 염경엽 감독. 잠실=송정헌 기자songs@sportschosun.com/2025.12.09/김현수가 KT와 3년 50억원의 대박 계약을 했다. 사진제공=KT 위즈27일 대전 한화생명볼파크에서 열린 KBO리그 한화와 LG의 경기. 1회초 1타점 적시타를 날리고 있는 LG 문성주. 대전=송정헌 기자songs@sportschosun.com/2025.09.27/[스포츠조선 권인하 기자]중심타자 김현수가 떠났다. 이제 LG 트윈스도 다시 새로운 클린업 트리오를 만들어야 한다.LG는 최근 2년 동안 오스틴 딘과 문보경 김현수로 3~5번 타선을 짰다. 셋의 순서가 바뀌기도 했지만 3명이 중심을 맡는 것은 당연했다. 김현수가 올시즌 초반엔 2번타자로 많이 나갔지만 후반엔 5번에서 주자들을 쓸어담는 모습을 많이 보여줬고, 특히 한국시리즈에서 찬스에서 한방을 날려주며 MVP까지 차지했다.올해 3명이 좋은 성적을 합작하며 우승을 이끌었다. 문보경은 24홈런과 108타점을 올렸고, 오스틴은 31홈런에 95타점, 김현수는 12홈런과 90타점을 기록했다. 팀내 타점 1~3위를 차지하며 합쳐서 293타점을 올렸다. 출루율 좋은 테이블세터가 찬스를 만들면 중심타선이 불러들이는 LG의 기본적인 득점 루트가 잘 이뤄지면서 LG의 공격력이 더욱 무서워졌다.김현수가 KT로 떠나면서 LG는 새로운 인물을 줌심타자로 넣어야 한다. 오스틴과 문보경이 3,4번을 맡을 가능성이 높아 5번 타자를 찾아야 하는 상황.올시즌 LG의 타점 순위를 보면 문보경 오스틴 김현수 뒤로 박동원(76타점) 문성주(70타점) 오지환(62타점) 등이 있다. 이들에게 5번 타자의 기회가 갈 가능성이 높다. 30일 대전 한화생명볼파크에서 열린 한국시리즈 4차전 한화 이글스와 LG 트윈스의 경기. 9회초 무사 1루 LG 박동원이 투런포를 날리고 있다. 대전=박재만 기자 pjm@sportschosun.com/2025.10.30/29일 대전 한화생명볼파크에서 열린 LG-한화전. 5회초 1사 오지환이 솔로포를 친 후 환영받고 있다. 대전=정재근 기자 cjg@sportschosun.com/2025.9.29/김현수의 대체 1순위로 꼽히는 이재원은 LG 염경엽 감독이 8번 타자에 고정시켜 경험을 쌓게 하려는 뜻을 밝힌바 있다. 박동원은 22개의 홈런과 함께 타점도 많다. 하지만 타율이 2할5푼3리로 낮은 것이 아쉬운 점이고 포수라서 체력적인 부담을 가진다는 점도 고려 대상이다.김현수가 인정한 연습벌에인 문성주의 경우 타율이 3할5리로 높고 득점권 타율도 3할2푼1리로 좋다. 하지만 장타력이 떨어지는 것은 조금 아쉽다. 올시즌 홈런이 3개이고 장타율이 3할7푼5리로 출루율과 같다.오지환은 2023년 29년만에 우승을 차지했을 때 5번 타자로 활약했었다. 하지만 지난해부터 부진을 보였고, 올시즌에도 타율 2할5푼3리로 타율이 좋지 못했다. 하지만 16개의 홈런을 친 장타력이 있어 내년시즌 정확도를 올린다면 예전에 5번 타자를 쳤던 경험이 있어 기대를 할 수 있다. LG는 주전은 정해져 있지만 이들의 타순이 시즌 처음부터 끝까지 유지되는 편은 아니다. 선수들의 성적과 컨디션 등에 따라 최적의 연결을 위한 타순을 짜기 때문이다. 5번 타자도 일단 초반 컨디션 좋은 타자가 맡을 가능성이 높다. 본문의 검색 링크는 AI 자동 인식으로 제공됩니다. 일부에 대해서는 미제공될 수 있고 동일한 명칭이 다수 존재하는 경우에는 전체 검색 결과로 연결될 수 있습니다.오분류 제보하기권인하 기자구독 0응원 0구독LG는 고우석과 2026 우승 생각했는데... 고우석이 안온다. 2연패는 불가능인가23년,29년,31년만에 황금장갑 받았는데... 여전히 31년,24년,15년간 못받은 포지션있다니. LG 황금시대에 결실맺을까스포츠조선언론사홈 바로가기Copyright ⓒ 스포츠조선. All rights reserved. 무단 전재 및 재배포 금지.기사 섹션 분류 가이드기사 섹션 분류 안내스포츠 기사 섹션(종목) 정보는 언론사 분류와 기술 기반의 자동 분류 시스템을 따르고 있습니다. 오분류에 대한 건은 네이버스포츠로 제보 부탁드립니다.오분류 제보하기닫기2026년 상승운일까 하락운일까. 결과를 확인해보세요. 무료신년운세주요뉴스해당 언론사에서 선정하며 언론사 페이지(아웃링크)로 이동해 볼 수 있습니다.김주하, 결국 청력 잃었다 \"전 남편이 때려 한쪽 고막 파열\"'32세' 톱스타, 자택서 숨진 채 발견→부부 줄초상..안타까운 16주기함소원 8세 딸, 의문男과 손 잡고 등교..\"등원 선생님, 4주에 46만원\" ('동치미')민혜연, ♥주진모에 결국 분노했다 \"너 누구랑 결혼했냐, 이 웬수\"현역 연예인 최초 사형 집행..30대 男배우 장이양 총살형 '1년 전 충격 사건'좋아요0슬퍼요0화나요0팬이에요0후속기사 원해요0\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd70248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import SoupStrainer\n",
    "# SoupStrainer\n",
    "#  (name=\"a\") # a태그들\n",
    "#  (name=\"a\", attr={\"href\":\".....\"}) # 태그 + 속성 조건.\n",
    "#  (id=\"tag의id\") # id로 조회.\n",
    "\n",
    "\n",
    "loader2 = WebBaseLoader(\n",
    "    web_path=urls,\n",
    "    bs_kwargs={\n",
    "        \"parse_only\":SoupStrainer(attrs={\"class\":['_article_content']})\n",
    "    },\n",
    "    bs_get_text_kwargs={\n",
    "        \"separator\":\"\\n\", \"strip\":True\n",
    "    }\n",
    "\n",
    ")\n",
    "docs2 = loader2.load()\n",
    "len(docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ffa86f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://m.sports.naver.com/kbaseball/article/076/0004357999'}\n"
     ]
    }
   ],
   "source": [
    "print(docs2[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2a6f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9일 서울 롯데호텔월드에서 KBO 골든글러브 시상식이 열렸다. KBO 올해의 감독상을 수상한 LG 염경엽 감독. 잠실=송정헌 기자songs@sportschosun.com/2025.12.09/\n",
      "김현수가 KT와 3년 50억원의 대박 계약을 했다. 사진제공=KT 위즈\n",
      "27일 대전 한화생명볼파크에서 열린 KBO리그 한화와 LG의 경기. 1회초 1타점 적시타를 날리고 있는 LG 문성주. 대전=송정헌 기자songs@sportschosun.com/2025.09.27/\n",
      "[스포츠조선 권인하 기자]중심타자\n",
      "김현수\n",
      "가 떠났다. 이제\n",
      "LG 트윈스\n",
      "도 다시 새로운 클린업 트리오를 만들어야 한다.\n",
      "LG는 최근 2년 동안\n",
      "오스틴\n",
      "딘과\n",
      "문보경\n",
      "김현수로 3~5번 타선을 짰다. 셋의 순서가 바뀌기도 했지만 3명이 중심을 맡는 것은 당연했다. 김현수가 올시즌 초반엔 2번타자로 많이 나갔지만 후반엔 5번에서 주자들을 쓸어담는 모습을 많이 보여줬고, 특히 한국시리즈에서 찬스에서 한방을 날려주며 MVP까지 차지했다.\n",
      "올해 3명이 좋은 성적을 합작하며 우승을 이끌었다. 문보경은 24홈런과 108타점을 올렸고, 오스틴은 31홈런에 95타점, 김현수는 12홈런과 90타점을 기록했다. 팀내 타점 1~3위를 차지하며 합쳐서 293타점을 올렸다. 출루율 좋은 테이블세터가 찬스를 만들면 중심타선이 불러들이는 LG의 기본적인 득점 루트가 잘 이뤄지면서 LG의 공격력이 더욱 무서워졌다.\n",
      "김현수가 KT로 떠나면서 LG는 새로운 인물을 줌심타자로 넣어야 한다. 오스틴과 문보경이 3,4번을 맡을 가능성이 높아 5번 타자를 찾아야 하는 상황.\n",
      "올시즌 LG의 타점 순위를 보면 문보경 오스틴 김현수 뒤로\n",
      "박동원\n",
      "(76타점)\n",
      "문성주\n",
      "(70타점)\n",
      "오지환\n",
      "(62타점) 등이 있다. 이들에게 5번 타자의 기회가 갈 가능성이 높다.\n",
      "30일 대전 한화생명볼파크에서 열린 한국시리즈 4차전 한화 이글스와 LG 트윈스의 경기. 9회초 무사 1루 LG 박동원이 투런포를 날리고 있다. 대전=박재만 기자 pjm@sportschosun.com/2025.10.30/\n",
      "29일 대전 한화생명볼파크에서 열린 LG-한화전. 5회초 1사 오지환이 솔로포를 친 후 환영받고 있다. 대전=정재근 기자 cjg@sportschosun.com/2025.9.29/\n",
      "김현수의 대체 1순위로 꼽히는\n",
      "이재원\n",
      "은 LG 염경엽 감독이 8번 타자에 고정시켜 경험을 쌓게 하려는 뜻을 밝힌바 있다.\n",
      "박동원은 22개의 홈런과 함께 타점도 많다. 하지만 타율이 2할5푼3리로 낮은 것이 아쉬운 점이고 포수라서 체력적인 부담을 가진다는 점도 고려 대상이다.\n",
      "김현수가 인정한 연습벌에인 문성주의 경우 타율이 3할5리로 높고 득점권 타율도 3할2푼1리로 좋다. 하지만 장타력이 떨어지는 것은 조금 아쉽다. 올시즌 홈런이 3개이고 장타율이 3할7푼5리로 출루율과 같다.\n",
      "오지환은 2023년 29년만에 우승을 차지했을 때 5번 타자로 활약했었다. 하지만 지난해부터 부진을 보였고, 올시즌에도 타율 2할5푼3리로 타율이 좋지 못했다. 하지만 16개의 홈런을 친 장타력이 있어 내년시즌 정확도를 올린다면 예전에 5번 타자를 쳤던 경험이 있어 기대를 할 수 있다.\n",
      "LG는 주전은 정해져 있지만 이들의 타순이 시즌 처음부터 끝까지 유지되는 편은 아니다. 선수들의 성적과 컨디션 등에 따라 최적의 연결을 위한 타순을 짜기 때문이다. 5번 타자도 일단 초반 컨디션 좋은 타자가 맡을 가능성이 높다.\n"
     ]
    }
   ],
   "source": [
    "print(docs2[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53100cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf81342a",
   "metadata": {},
   "source": [
    "#### RecursiveUrlLoader\n",
    "\n",
    "- 주어진 URL에서 시작하여 그 페이지 안의 내부 링크를 재귀적으로 따라가며 여러 웹 문서를 자동 수집하여 로드한다.\n",
    "  - 시작 url을 요청/페이지를 파싱 한 뒤에 `<a href>` 들을 수집하고 그 페이지들을 요청/페이지 파싱을 한다. \n",
    "- WebBaseLoader가 단일 페이지(단일 URL) 단위라면 RecursiveUrlLoader는 **웹 사이트 구조 전체를 크롤링하는 전용 수집기**에 가깝다.\n",
    "```bash\n",
    "시작 URL\n",
    " ├─ 내부 링크 1\n",
    " │   ├─ 내부 링크 1-1\n",
    " │   └─ 내부 링크 1-2\n",
    " ├─ 내부 링크 2\n",
    " └─ 내부 링크 3\n",
    "```\n",
    "위 구조일때 무든 페이지를 재귀적으로 수집한다.\n",
    "- 주요 파라미터\n",
    "  - **url**: 시작 url\n",
    "  - **max_depth**\n",
    "    - 링크를 몇 단계 **깊이** 까지 따라갈지 제한\n",
    "    - 사이트 폭주를 막기 위한 안전장치\n",
    "      - **0**: 시작페이지만, **1**: 시작페이지 + 1차링크, **2**(기본값): 시작페이지 + 1차링크 + 2차링크\n",
    "  - **exclude_dirs**: list[str]\n",
    "    - 크롤링 제외 경로\n",
    "    - ex) `exclude_dirs=['/login', 'signup']`\n",
    "  - **prevent_outside**: bool\n",
    "    - True: base_url 바깥 링크는 가져오지 않고 무시한다.\n",
    "  - **base_url**: str\n",
    "    - prevent_outside=True일 때 바깥링크의 기준. 없으면 `url`(시작 url)의 host가 된다. \n",
    "  - **extractor**\n",
    "    - 문서 내용 추출 사용자 정의 함수\n",
    "    - default는 응답 받은 페이지를 `BeautifulSoup(응답페이지).get_text()` 로 텍스트를 추출한다.\n",
    "    - ````python\n",
    "        def custom_extractor(html:str) ->str:\n",
    "            # 웹 페이지 문서를 입력으로 받는다.\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            return soup.select_one('article').get_text() # 원하는 항목을 추출해서 반환한다.\n",
    "        \n",
    "        loader = RecursiveUrlLoader(\n",
    "            url=start_url,\n",
    "            extractor=custom_extractor\n",
    "        )    \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a6a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "\n",
    "def extractor(html:str)->str:\n",
    "    # 전체 페이지를 받아서 원하는 부분만 parsing 한 뒤에 반환.\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    body = soup.select_one(\"div.body\")\n",
    "    return body.get_text(strip=True, separator=\"\\n\") if body else soup.get_text(strip=True, separator=\"\\n\")\n",
    "\n",
    "url = \"https://docs.python.org/3\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url,\n",
    "    extractor=extractor,\n",
    "    max_depth=2, \n",
    "    prevent_outside=True, # url 외부 링크는 가져오지 안도록 한다. (defualt: url의 host)\n",
    "    base_url=url\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb1ac965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78dbf806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content_type': 'text/html',\n",
      " 'language': None,\n",
      " 'source': 'https://docs.python.org/3.8/',\n",
      " 'title': '3.8.20 Documentation'}\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "pprint(docs[idx].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "213f109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.20 documentation\n",
      "Welcome! This is the documentation for Python 3.8.20.\n",
      "Parts of the documentation:\n",
      "What's new in Python 3.8?\n",
      "or\n",
      "all \"What's new\" documents\n",
      "since 2.0\n",
      "Tutorial\n",
      "start here\n",
      "Library Reference\n",
      "keep this under your pillow\n",
      "Language Reference\n",
      "describes syntax and language elements\n",
      "Python Setup and Usage\n",
      "how to use Python on different platforms\n",
      "Python HOWTOs\n",
      "in-depth documents on specific topics\n",
      "Installing Python Modules\n",
      "installing from the Python Package Index & other sources\n",
      "Distributing Python Modules\n",
      "publishing modules for installation by others\n",
      "Extending and Embedding\n",
      "tutorial for C/C++ programmers\n",
      "Python/C API\n",
      "reference for C/C++ programmers\n",
      "FAQs\n",
      "frequently asked questions (with answers!)\n",
      "Indices and tables:\n",
      "Global Module Index\n",
      "quick access to all modules\n",
      "General Index\n",
      "all functions, classes, terms\n",
      "Glossary\n",
      "the most important terms explained\n",
      "Search page\n",
      "search this documentation\n",
      "Complete Table of Contents\n",
      "lists all sections and subsections\n",
      "Meta information:\n",
      "Reporting bugs\n",
      "Contributing to Docs\n",
      "About the documentation\n",
      "History and License of Python\n",
      "Copyright\n"
     ]
    }
   ],
   "source": [
    "print(docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d7c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd26b68d",
   "metadata": {},
   "source": [
    "### ArxivLoader\n",
    "- https://github.com/lukasschwab/arxiv.py\n",
    "- [arXiv-아카이브](https://arxiv.org/) 는 미국 코렐대학에서 운영하는 **무료 논문 저장소**로, 물리학, 수학, 컴퓨터 과학, 생물학, 금융, 경제 등 **과학, 금융 분야의 논문**들을 공유한다.\n",
    "- `ArxivLoader` 를 사용해 원하는 주제의 논문들을 arXiv에서 가져와 load할 수 있다.\n",
    "- **arXiv API**를 사용해 논문을 가져올 수 있다.\n",
    "  - https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html\n",
    "- 설치\n",
    "  - `pip install langchain-community -qU`\n",
    "  - `pip install arxiv -qU`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f45cfa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m8 packages\u001b[0m \u001b[2min 2.93s\u001b[0m\u001b[0m\n",
      "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m sgmllib3k\u001b[2m==1.0.0\u001b[0m\n",
      "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sgmllib3k\u001b[2m==1.0.0\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 711ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1marxiv\u001b[0m\u001b[2m==2.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfeedparser\u001b[0m\u001b[2m==6.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msgmllib3k\u001b[0m\u001b[2m==1.0.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6072b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m2 packages\u001b[0m \u001b[2min 91ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pip \u001b[2m(1.7MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pip\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 382ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 307ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpip-system-certs\u001b[0m\u001b[2m==5.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# windows\n",
    "!uv pip install pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb21d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip_system_certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b569dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv lib 사용\n",
    "import arxiv\n",
    "# 검색 설정\n",
    "search = arxiv.Search(\n",
    "    query=\"Advanced RAG\", # 검색어\n",
    "    max_results=5, # 검색 논문 최대 개수.\n",
    "    sort_by=arxiv.SortCriterion.LastUpdatedDate # 정렬기준.\n",
    ")\n",
    "# 정렬기준: LastUpdatedDate-논문이 마지막으로 수정된 날짜 기준.\n",
    "#          Relevance: Query와 관련성이 높은 순서\n",
    "#          SubmittedDate: 논문이 처음 제출된 날짜 기준\n",
    "\n",
    "# 검색 처리 Client\n",
    "client = arxiv.Client()\n",
    "results = client.results(search) # 검색 (iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e0b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'itertools.islice'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results)) # iterator: next(), for in\n",
    "# 첫번째 것만 조회\n",
    "paper = next(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86402ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoint Counting Classifiers: Turning Vision Transformers into Self-Explainable Models Without Training\n",
      "[arxiv.Result.Author('Kristoffer Wickstrøm'), arxiv.Result.Author('Teresa Dorszewski'), arxiv.Result.Author('Siyan Chen'), arxiv.Result.Author('Michael Kampffmeyer'), arxiv.Result.Author('Elisabeth Wetzer'), arxiv.Result.Author('Robert Jenssen')]\n",
      "Kristoffer Wickstrøm\n",
      "Current approaches for designing self-explainable models (SEMs) require complicated training procedures and specific architectures which makes them impractical. With the advance of general purpose foundation models based on Vision Transformers (ViTs), this impracticability becomes even more problematic. Therefore, new methods are necessary to provide transparency and reliability to ViT-based foundation models. In this work, we present a new method for turning any well-trained ViT-based model into a SEM without retraining, which we call Keypoint Counting Classifiers (KCCs). Recent works have shown that ViTs can automatically identify matching keypoints between images with high precision, and we build on these results to create an easily interpretable decision process that is inherently visualizable in the input. We perform an extensive evaluation which show that KCCs improve the human-machine communication compared to recent baselines. We believe that KCCs constitute an important step towards making ViT-based foundation models more transparent and reliable.\n",
      "https://arxiv.org/pdf/2512.17891v1\n",
      "2512.17891v1\n"
     ]
    }
   ],
   "source": [
    "# 논문 정보\n",
    "print(paper.title)# 제목\n",
    "print(paper.authors) # 논문 저자\n",
    "print(paper.authors[0].name) # Author.name : 이름 추출\n",
    "print(paper.summary) # 논문 요약(초록)\n",
    "print(paper.pdf_url) # arivx의 논문 URL\n",
    "print(paper.get_short_id()) # arivx 의 이 논문의 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b79e21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/papers\\\\2512.17891v1.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 논문 저장 \n",
    "import os \n",
    "os.makedirs('data/papers', exist_ok=True)\n",
    "\n",
    "paper.download_pdf(dirpath=\"data/papers\", filename=f\"{paper.get_short_id()}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b446e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 다운로드\n",
    "for paper in results:\n",
    "    paper.download_pdf(dirpath=\"data/papers\", filename=f\"{paper.get_short_id()}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf4bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain - ArxivLoader\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(\n",
    "    query=\"RAG\",\n",
    "    top_k_results=10\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b18af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b13407b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2025-05-31',\n",
       " 'Title': 'RAG-Gym: Systematic Optimization of Language Agents for Retrieval-Augmented Generation',\n",
       " 'Authors': 'Guangzhi Xiong, Qiao Jin, Xiao Wang, Yin Fang, Haolin Liu, Yifan Yang, Fangyuan Chen, Zhixing Song, Dengyu Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang',\n",
       " 'Summary': 'Retrieval-augmented generation (RAG) has shown great promise for knowledge-intensive tasks and recently advanced with agentic RAG, where language agents engage in multi-round interactions with external knowledge sources for adaptive information retrieval. However, existing agentic RAG methods often depend on ad-hoc prompt engineering and lack a unified optimization framework. We introduce RAG-Gym, a comprehensive platform that systematically explores three optimization dimensions: (1) prompt engineering, (2) actor tuning, and (3) critic training. For prompt engineering, we propose Re$^2$Search, a novel agent incorporating reasoning reflection that significantly outperforms standard prompts. In actor tuning, we evaluate three popular post-training algorithms with fine-grained process supervision and identify direct preference optimization as the most effective. We further demonstrate that a trained critic can enhance inference by selecting higher-quality intermediate reasoning steps. Together, these findings lead to the optimized Re$^2$Search++ agent, which surpasses most recent methods like Search-R1 by a relative increase of 3.2% to 11.6% in average F1. Finally, we examine the impact of different reward sources and analyze scaling properties in training and inference, offering practical insights for agentic RAG optimization. The project homepage is available at https://rag-gym.github.io.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content) # 논문 내용.\n",
    "# 다운로드 기능은 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984953e",
   "metadata": {},
   "source": [
    "### Docling\n",
    "- IBM Research에서 개발한 오픈소스 문서처리 도구로 다양한 종류의 문서를 구조화된 데이터로 변환해 생성형 AI에서 활용할 수있도록 지원한다.\n",
    "- **주요기능**\n",
    "  - PDF, DOCX, PPTX, XLSX, HTML, 이미지 등 여러 형식을 지원\n",
    "  - PDF의 **페이지 레이아웃, 읽기 순서, 표 구조, 코드, 수식** 등을 분석하여 정확하게 읽어들인다.\n",
    "  - OCR을 지원하여 스캔된 PDF나 이미지에서 텍스트를 추출할 수있다.\n",
    "  - 읽어들인 내용을 markdown, html, json등 다양한 형식으로 출력해준다.\n",
    "- 설치 : `pip install langchain-docling ipywidgets -qU` \n",
    "- 참조\n",
    "  - docling 사이트: https://github.com/docling-project/docling\n",
    "  - 랭체인-docling https://python.langchain.com/docs/integrations/document_loaders/docling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406c0672-a932-4b55-bc39-1863e00ef3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv pip install langchain-docling transformers ipywidgets\n",
    "!uv pip install accelerate\n",
    "## 딥러닝 모델 사용. gpu가 있을 경우 torch cuda 버전을 먼저 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e423ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface 로그인 - 모델 받기 위해.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "login(hf_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e55241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "path = \"data/papers/2507.01939v4.pdf\"\n",
    "loader = DoclingLoader(\n",
    "    file_path=path,\n",
    "    export_type=ExportType.MARKDOWN\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a1b323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b653a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'data/papers/2507.01939v4.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a639f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars\n",
      "\n",
      "XIAOSHENG ZHAO , 1, 2, 3 , ∗ YANG HUANG , 1, 2 GUIRONG XUE , 4, ∗ XIAO KONG , 2, 1 , ∗ JIFENG LIU , 2, 1 XIAOYU TANG, 5 TIMOTHY C. BEERS , 6, 7 YUAN-SEN TING , 8, 9 AND A-LI LUO 2, 1\n",
      "\n",
      "1 School of Astronomy and Space Science, University of Chinese Academy of Sciences, Beijing 100049, People's Republic of China\n",
      "\n",
      "2 National Astronomical Observatories, Chinese Academy of Sciences, Beijing 100012, People's Republic of China\n",
      "\n",
      "3 Department of Physics &amp; Astronomy, The Johns Hopkins University, Baltimore, MD 21218, USA\n",
      "\n",
      "4 Zhejiang Laboratory, Hangzhou 311121, People's Republic of China\n",
      "\n",
      "5 Research Center for Astronomical Computing, Zhejiang Laboratory, Hangzhou 311121, People's Republic of China\n",
      "\n",
      "6 Department of Physics and Astronomy, University of Notre Dame, Notre Dame, IN 46556, USA\n",
      "\n",
      "7 Joint Institute for Nuclear Astrophysics - Center for the Evolution of the Elements (JINA-CEE), USA\n",
      "\n",
      "8 Department of Astronomy, The Ohio State University, 140 West 18th Avenue, Columbus, OH 43210, USA\n",
      "\n",
      "9 Center for Cosmology and AstroParticle Physics (CCAPP), The Ohio State University, Columbus, OH 43210, USA\n",
      "\n",
      "## ABSTRACT\n",
      "\n",
      "In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types-LAMOST low-resolution and Gaia XP-followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, the former being achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework that enables intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates bench-marked against external survey data. In addition, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy. Our code SpecCLIP is publicly available on GitHub /github .\n",
      "\n",
      "Keywords: Galaxy: stellar content - stars: fundamental parameters - stars: distances - methods: data analysis\n",
      "\n",
      "## 1. INTRODUCTION\n",
      "\n",
      "Over the past decades, large-scale spectroscopic surveys have revolutionized our understanding of the formation and evolution of the Milky Way (Gilmore et al. 1989; Freeman &amp; Bland-Hawthorn 2002; Gray et al. 2002; Wyse 2009; Helmi 2020). These advances have been driven by three key forces. First, the continuous development of large-scale spec-\n",
      "\n",
      "Corresponding author: Yang Huang huangyang@ucas.ac.cn\n",
      "\n",
      "∗ These authors contributed equally to this work.\n",
      "\n",
      "troscopic surveys - such as RAVE (Steinmetz et al. 2006), SEGUE (de Jong et al. 2010), APOGEE (Majewski et al. 2017), GALAH (De Silva et al. 2015), LAMOST (Zhao et al. 2012), and DESI (DESI Collaboration et al. 2016) - has provided an unprecedented volume of stellar spectra across diverse Galactic populations. Second, the creation of powerful data infrastructures (Helou et al. 1991; Szalay &amp; Gray 2001; Gray et al. 2002; Fitzpatrick et al. 2014; Moitinho et al. 2017), exemplified by the SkyServer (Szalay et al. 2001) and CasJobs (OMullane et al. 2005) systems built for the Sloan Digital Sky Survey (SDSS, Margon 1999; Abazajian et al. 2003, has democratized access to these datasets and enabled\n",
      "\n",
      "efficient large-scale analyses. Third, the refinement of algorithms for extracting physical parameters from these spectra has enabled increasingly precise stellar characterization.\n",
      "\n",
      "The latter effort encompasses traditional line-index methods, such as the SEGUE Stellar Parameter Pipeline (SSPP) (Lee et al. 2008); template-matching techniques, including UlySS (Koleva et al. 2009), the LAMOST stellar parameter pipeline (LASP; Wu et al. 2014) and the LAMOST stellar parameter pipeline at Peking University (LSP3; Xiang et al. 2015); as well as a range of machine learning approaches, among which the SSPP also incorporates a neural network module, alongside methods such as the Cannon (Ness et al. 2015), the Payne (Ting et al. 2017, 2019),the DD-Payne (Xiang et al. 2019), and the TransformerPayne (R´ o˙ za´ nski et al. 2025). All of these approaches, though diverse in methodology, rely heavily on supervision - either empirical or theoretical.\n",
      "\n",
      "Empirical approaches are limited by the coverage of the reference libraries they use, even when these libraries are derived from fundamental measurements. For instance, the official LAMOST stellar parameter pipeline (LASP; Wu et al. 2014), which is based on the UlySS algorithm, can only measure iron abundances down to [Fe/H] = -2 . 5 , due to the limited parameter coverage of the ELODIE library (Moultaka et al. 2004). Theoretical approaches, while offering broader parameter coverage, are still subject to discrepancies between synthetic and observed spectra.\n",
      "\n",
      "In addition, most existing pipelines are designed primarily to estimate atmospheric parameters, such as effective temperature ( T eff ), surface gravity (log g ) and iron abundance ([Fe/H]), in conjunction with a small set of elemental abundances. In contrast, determining other stellar properties, including reddening, stellar mass, and age, typically requires dedicated, task-specific pipelines. These efforts are further complicated by the diversity of spectral data in terms of wavelength coverage, resolution, and signal-to-noise ratio (SNR) - we refer to such quantities here as ' modalities '. Achieving consistency and placing all inferred parameters onto a uniform scale remains a significant challenge in the prevailing framework, where each parameter is commonly derived using a distinct, often non-overlapping model.\n",
      "\n",
      "In parallel, the past five years have witnessed the remarkable success of large language models (LLMs) in natural language understanding, conversational AI, and text generation (Vaswani et al. 2017; Devlin et al. 2018; Radford et al. 2018, 2019; Brown et al. 2020). Breakthroughs in high-impact scientific domains - such as AlphaFold for protein structure prediction (Jumper et al. 2021) - have been enabled by the combination of massive datasets, large-scale models, and modern computational infrastructure (Kaplan et al. 2020).\n",
      "\n",
      "Stellar spectra can be analogized to a structured language: their rich absorption features and overall shapes encode key information about a star's physical properties and evolutionary history. With the accumulation of millions of stellar spectra, it has become feasible to train foundation models (Leung &amp; Bovy 2024; Buck &amp; Schwarz 2024; Parker et al. 2024; Rizhko &amp; Bloom 2024; Smith et al. 2024; Zhong et al. 2024; Euclid Collaboration et al. 2025; Pattnaik et al. 2025) on these data using techniques inspired by LLMs. Here, 'foundation models' refer to models pre-trained on large and diverse datasets. The broader the spectral distribution and parameter ranges used during pre-training, the better the model can learn the underlying structure of the 'spectral language'. Once pre-trained, these models can be quickly fine-tuned with a small set of high-quality labels to perform a variety of downstream tasks, such as parameter estimation.\n",
      "\n",
      "A particularly promising framework for learning across modalities is the Contrastive Language-Image Pre-training (CLIP) algorithm (Radford et al. 2021), which aligns text and image representations via contrastive learning. CLIP jointly trains two encoders (one for each modality) by maximizing the similarity between representations of matched pairs and minimizing it for mismatched ones. The result is a shared embedding space that enables direct comparison between different modalities, allowing the model to retrieve or match one modality given the other, even for new inputs not seen during training.\n",
      "\n",
      "When applied to stellar spectra (Buck &amp; Schwarz 2024; Parker et al. 2024; Rizhko &amp; Bloom 2024), CLIP-style models can align spectra from different instruments or modalities with other astrophysical measurements, allowing for more flexible downstream tasks such as parameter estimation and anomaly detection. However, a known limitation of CLIP is that it prioritizes the shared information between modalities, potentially removing modality-specific features that are still important for some downstream tasks (Shwartz Ziv &amp; LeCun 2024).\n",
      "\n",
      "Partly motivated by this issue, we introduce the SpecCLIP project - a unified framework for cross-modal representation learning of stellar spectra. SpecCLIP begins with pre-training on two types of spectra: LAMOST (Cui et al. 2012) low-resolution spectra (LRS; Zhao et al. 2012) and Gaia XP spectra (De Angeli et al. 2023; Gaia Collaboration et al. 2023). These are aligned in a shared embedding space using a CLIP-like contrastive objective, enhanced by auxiliary decoders to preserve the mutual information between the learned embeddings and the input spectra.\n",
      "\n",
      "Mutual information (MI, Barber &amp; Agakov 2003; Poole et al. 2019; Devon Hjelm et al. 2018; Sui et al. 2023; Ting\n",
      "\n",
      "2025) 1 is a key concept in information theory that quantifies how much one variable tells us about another. It serves as a natural objective for representation learning. Although we do not explicitly compute MI between the spectra and their embeddings, we adopt a simple and effective strategy (Wang et al. 2022): increasing contrastive training with input reconstruction as a regularization mechanism, similar to using a decoder in an autoencoder to encourage informative representations.\n",
      "\n",
      "Another interesting feature enabled by our model is spectrum-to-spectrum translation . If the embeddings capture physically meaningful and shared information between spectra of different modalities, then it should be possible to predict one modality from the other, given suitable (spectrato-spectra) supervision. In parallel, Buck &amp; Schwarz (2024) demonstrated a similar idea using contrastive learning between Gaia XP and RVS spectra, employing CNN and multilayer perceptron (MLP) architectures. In our framework, we combine contrastive training and cross-modal prediction, augmented by spectral reconstruction within a unified architecture, enabling both spectrum-to-spectrum and spectrumto-parameter applications.\n",
      "\n",
      "The key contributions of this work are:\n",
      "\n",
      "- We design distinct tokenization and model structures tailored to LAMOST LRS and Gaia XP spectra to improve representation learning.\n",
      "- Wedemonstrate that our unified model enables both inmodal and cross-modal search, as well as cross-modal prediction.\n",
      "\n",
      "The remainder of this paper is organized as follows. In Section 2, we introduce the SpecCLIP model, including the separate pre-trained models and the CLIP-based alignment. Section 3 describes the downstream tasks, including modeling and sample selection for parameter estimation. The results, including parameter inference, spectral retrieval, and cross-modal prediction, are presented in Section 5. Section 6 offers further discussion and Section 7 summarizes the work. Additional material is provided in the appendices: Appendix A (additional results); Appendix B (continuum fitting); Appendix C (normalizing flows for parameter inference); Appendix D (pre-training details); Appendix E (projection models and decoders); and Appendix G (summary of key hyper-parameters and configurations)\n",
      "\n",
      "1 Formally, the mutual information between two continuous random variables X and Y is defined as\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where p ( x, y ) is the joint density, and p ( x ) , p ( y ) are the marginals. For discrete variables, the integral becomes a sum.\n",
      "\n",
      "## 2. SPECCLIP\n",
      "\n",
      "SpecCLIP, developed in this work, is a foundation model designed to align stellar spectra across different modalities, such as those with varying wavelength coverage, resolution, and SNRs, using a CLIP-inspired architecture. 2 Our approach builds upon transformer-based foundation models or MLP-based autoencoders tailored for specific spectral types. These are combined with contrastive learning to align different spectra using a standard contrastive loss, supplemented by additional modules to capture both shared and modalityspecific information. Once trained, SpecCLIP enables various downstream tasks with either branch (not combination) of modalities, using a relatively small number of labeled examples (i.e., few-shot learning, as referred to in the literature).\n",
      "\n",
      "Figure 1 provides an overview of the SpecCLIP framework. Foundation models are first independently pre-trained on each spectral modality in an unsupervised fashion. These models are then aligned using contrastive learning, with additional decoders added to enhance information retention. After this process, the final model is capable of handling a wide range of downstream tasks. Below, we describe the key experimental settings, including data-selection criteria, model architectures, loss functions for the foundation model training, and the connection of reconstruction loss to mutual information. Further details of the implementation are provided in Appendix D and Appendix E.\n",
      "\n",
      "## 2.1. Pre-trained Foundation Model for LAMOST LRS\n",
      "\n",
      "The most recent LAMOST data release (DR11) 3 includes more than 10 million low-resolution spectra (Luo et al. 2015), used for a variety of scientific tasks, including estimation of stellar parameters, chemical abundances, reddening, radial velocity, stellar mass, and age. Our aim in pre-training a foundation model for LAMOST LRS is to learn informative and transferable representations that support many of these tasks with a small to moderate amount of labeled data.\n",
      "\n",
      "In our pre-trained LRS model, each spectrum is tokenized into overlapping segments (tokens) of 20 flux points 20 flux points ( ≈ 22 ˚ A at a wavelength of 5000 ˚ A, corresponding to ∼ 10 resolution elements and capturing typical local line structures), with the overlap of 10 points to preserve continuity, producing 146 tokens per spectrum. These tokens, together with one special token-the logarithmic standard deviation of the spectrum-are passed through 6 self-attention lay-\n",
      "\n",
      "2 CLIP stands for Contrastive Language-Image Pre-training. In this work, we adopt the contrastive learning concept from the original CLIP framework, applying it to spectra-spectra pre-training. Although our use case differs from the original text-image alignment, we retain the term CLIP for consistency.\n",
      "\n",
      "3 https://www.lamost.org/dr11/\n",
      "\n",
      "Figure 1. Architecture of SpecCLIP. Two types of spectra (Shown here are examples of normalized LAMOST LRS and Gaia XP spectra varying with metallicities) are passed through two pre-trained spectral foundation models to obtain embeddings, where the pre-trained models can be either transformer-based networks or multilayer perceptron (MLP)-based autoencoders. These embeddings are then projected into a joint embedding space, which may optionally be split into a shared and a non-shared subspace. Based on the projected embeddings, we construct various loss functions to enable CLIP-like contrastive learning, cross-modal prediction, and spectral reconstruction. The combination of these loss functions results in five model variants: a baseline CLIP without decoders, CLIP-r with only reconstruction decoders, CLIP-p with only prediction decoders, CLIP-pr with full decoders, and CLIP-split with full decoders and an explicit separation of shared and non-shared embedding spaces (see Section 2.3)\n",
      "\n",
      "ers, each yielding a 768-dimensional token embedding. During training, 6 non-overlapping chunks (each 10 tokens, corresponding to an overall effective masking rate of ≈ 45%) are randomly masked to encourage robust representation learning. The resulting transformer-like framework with mask modeling (denoted as the masked transformer, or MT) has a total of 42.7 million trainable parameters.\n",
      "\n",
      "## 2.2. Pre-trained Foundation Model for Gaia XP Spectra\n",
      "\n",
      "Gaia XP low-resolution spectra (De Angeli et al. 2023), obtained via the Blue (with resolving power R ranging from 30 to 100) and Red ( R ranging from 70 to 100) Photometers (BP and RP), are essential for determining key stellar properties such as stellar atmospheric parameters and chemical compositions. The differences in resolution and wavelength range compared to LAMOST LRS motivate the construction of a separate foundation model tailored to the XP modality.\n",
      "\n",
      "Two types of models are explored for Gaia XP. The first is a transformer-based MT model, structurally similar to that used for LAMOST LRS, but with tokenization at the individual flux-point level, yielding 343 tokens per spectrum, together with two special tokens-the mean and standard deviation of the spectrum. Like the LRS model, this version uses 6 self-attention layers and masks 6 chunks (20 tokens each, corresponding to an overall masking rate of ≈ 35%) during training.\n",
      "\n",
      "The second model is a MLP-based ordinary autoencoder (denoted as OAE), with a bottleneck layer of 768 dimensions. Both XP models have approximately the same number of trainable parameters as the LRS model and are trained for the same number of epochs. In this paper, we use the OAE\n",
      "\n",
      "for Gaia XP to test results in tables, unless otherwise noted, because of its better performance, as discussed in Section 6.6.\n",
      "\n",
      "## 2.3. Contrastive Learning with Decoders\n",
      "\n",
      "To align the two spectral modalities, we use 820,568 paired LAMOST LRS and Gaia XP spectra. The backbone of the alignment model leverages contrastive loss, augmented by auxiliary decoders that contribute to additional supervision.\n",
      "\n",
      "As shown in Figure 1, the embeddings of the LRS and XP foundation models are projected onto a shared embedding space. The LRS projection head includes a cross-attention block with a recurrence vector that is learnable, following Parker et al. (2024). For Gaia XP, the projection head is either a cross-attention block (when following the attention-based model) or an MLP (when based on the OAE model). The core alignment objective is the contrastive loss between these projected embeddings.\n",
      "\n",
      "To enrich the learned embeddings, we incorporate four auxiliary decoders:\n",
      "\n",
      "- Two in-modal decoders reconstruct each spectrum from its projected embedding;\n",
      "- Two cross-modal decoders predict one spectrum modality from the other.\n",
      "\n",
      "These components serve to retain modality-specific information, support cross-modal translation, and increase the robustness of learned representations. Although our multidecoder design is motivated by the need to enrich spectral embeddings with diverse reconstruction pathways, we note that related ideas have appeared independently in other domains, such as the sensor-agnostic image retrieval framework in remote sensing proposed by Hackstein et al. (2024). As discussed in further detail in the final subsection of this section, reconstructing the original spectra also helps to increase the mutual information between the projected embeddings and the inputs.\n",
      "\n",
      "Model Variants -To assess the contributions of each model component, we construct five SpecCLIP variants:\n",
      "\n",
      "- CLIP: A baseline contrastive model without auxiliary decoders.\n",
      "- CLIP-r: Adds only reconstruction decoders to the baseline.\n",
      "- CLIP-p: Adds only cross-modal prediction decoders to the baseline.\n",
      "- CLIP-pr: Adds both reconstruction and prediction decoders, implicitly encouraging shared and modalityspecific representation learning.\n",
      "- CLIP-split: Extends CLIP-pr by explicitly partitioning the embedding space into shared and modalityspecific subspaces through two separate projection networks, potentially disentangling the two spaces.\n",
      "\n",
      "## 2.4. Loss Functions during Contrastive Training\n",
      "\n",
      "The total training objective L total for the SpecCLIP model - whether for CLIP or CLIP-variants - comprises three components: a contrastive CLIP loss, a reconstruction loss, and a cross-modal prediction loss. The total loss is a weighted sum:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where δ recon and δ pred are binary indicators that control the inclusion of reconstruction losses and cross-modal prediction, respectively. The weights w recon and w pred control the relative contribution of the reconstruction and prediction losses and are fixed at 1 (i.e., equal weighting) throughout this work.\n",
      "\n",
      "Contrastive CLIP Loss -The contrastive loss aligns the XP and LRS embeddings in a shared embedding space. Let f xp and f lrs denote the encoders for XP and LRS inputs (including their pre-trained models and projection networks). For a batch of N paired examples { ( x xp i , x lrs i ) } N i =1 , their projected embeddings are computed as described below.\n",
      "\n",
      "In the CLIP-pr model, we use all projected embeddings and normalize them to unit length: z xp i = f xp ( x xp i ) and z lrs i = f lrs ( x lrs i ) , where each embedding is L2-normalized. In the CLIP-split model, only the shared components of the embeddings are used and similarly normalized: z xp i = f shared xp ( x xp i ) and z lrs i = f shared lrs ( x lrs i ) .\n",
      "\n",
      "The similarity matrix are scaled by a temperature parameter τ (set to 15.5, following Parker et al. 2024):\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where ⟨· , ·⟩ denotes the dot product between two embedding vectors. This dot product becomes equivalent to cosine similarity if the vectors are normalized. The parameter τ controls how confidently the contrastive loss distinguishes positives from negatives. The larger τ leads to greater confidence and greater push/pull between the matched and mismatched pairs.\n",
      "\n",
      "Then the CLIP loss is computed as:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where ℓ i, : and ℓ : ,i are the similarity scores for XP-to-LRS and LRS-to-XP matching, respectively, and CE ( · , i ) denotes the cross-entropy loss with label i defined as CE ( ℓ i, : , i ) =\n",
      "\n",
      "-log ( exp( ℓ i,i ) / ∑ N j =1 exp( ℓ i,j ) ) . The cross-entropy loss encourages the matched pairs to have a higher similarity than the mismatched ones in the shared embedding space.\n",
      "\n",
      "Reconstruction Loss -Each modality has its own decoder to reconstruct the original spectrum from its embedding. In the CLIP-pr model, reconstruction is based on the full projected embedding. In the CLIP-r and CLIP-split models, reconstruction uses both shared and non-shared embeddings, which come from separate projection branches. Let ˆ x xp i and ˆ x lrs i denote the reconstructions. The loss is:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where µ i and σ i are the mean and standard deviation of the LRS input x lrs i , used to further normalize the input before reconstruction 4 .\n",
      "\n",
      "Cross-Modal Prediction Loss -To facilitate spectrum translation, cross-modal decoders predict one modality from the embedding of the other. In CLIP-pr, this is done by using the full embedding. In CLIP-p and CLIP-split, only the shared embedding component is used for cross-modal prediction. Let ˆ x xp ← lrs i and ˆ x lrs ← xp i be the cross-predicted spectra:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "## 2.5. Connection of Reconstruction Loss to Mutual Information\n",
      "\n",
      "Minimizing the reconstruction loss encourages the latent embedding to retain as much information as possible about the original input spectra. This intuition can be formalized via the mutual information between the input spectrum (either x xp or x lrs ) and its corresponding embedding ( z xp or z lrs ). For notational simplicity, we use x and z to denote a generic input spectrum and its embedding, respectively. The mutual information can be written as (Barber &amp; Agakov 2003; Ting 2025):\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "4 This normalization step is optional. We initially adopted this design for potential training stability. Although each spectrum is already fluxnormalized by continuum division during pre-processing, this additional normalization (1) centers the input distribution and (2) focuses the decoder on learning the shape of spectral features. This makes the projected embedding retain essential LRS information. In contrast, for Gaia XP, we reconstruct the relative fluxes (colors) normalized by the 550 nm flux, aiming to recover the full chromatic information.\n",
      "\n",
      "where H ( x ) = -E p ( x ) [log p ( x )] is the marginal entropy of the spectrum and H ( x | z ) = -E p ( z,x ) [log p ( x | z )] is the conditional entropy given the embedding. Since H ( x ) is independent of model parameters, maximizing I ( z, x ) is equivalent to minimizing H ( x | z ) .\n",
      "\n",
      "However, the true conditional distribution p ( x | z ) is typically intractable. In practice, we introduce a variational approximation q ( x | z ) -often realized by a neural decoder-leading to the following bound:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where the inequality follows from the non-negativity of the Kullback-Leibler divergence KL( p ( x | z ) ∥ q ( x | z )) (Barber &amp; Agakov 2003; Poole et al. 2019). Thus, minimizing the expected negative log-likelihood under q ( x | z ) serves as a variational lower bound on the mutual information I ( z, x ) .\n",
      "\n",
      "When q ( x | z ) is modeled as a Laplace distribution centered at a deterministic decoder output ˆ x ( z ) , the negative loglikelihood reduces (up to constants) to the ℓ 1 reconstruction error:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "which justifies the use of L1 loss in our reconstruction objective. This choice is particularly appropriate for stellar spectra, especially LAMOST LRS data, which contain sharp absorption features and may occasionally include unflagged bad pixels. The L1 loss is robust to such outliers and better preserves narrow spectral lines compared to L2.\n",
      "\n",
      "Alternatively, assuming a Gaussian likelihood q ( x | z ) = N ( x ; ˆ x ( z ) , σ 2 I ) leads to the standard mean squared error (MSE) loss:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "which penalizes larger residuals more strongly and encourages smooth reconstruction. While MSE may be suitable for high-SNR or denoised spectra, it tends to overly smooth localized features and is less robust to localized artifacts.\n",
      "\n",
      "In summary, minimizing the reconstruction loss-whether L1 or L2-amounts to maximizing a variational lower bound on the mutual information between the input spectrum and its embedding. This encourages the representation to be informative and faithful to the original input.\n",
      "\n",
      "## 3. DOWNSTREAM TASKS\n",
      "\n",
      "We evaluate the performance of SpecCLIP on several downstream tasks, including parameter estimation, spectral retrieval (or search), and cross-modal prediction given a query spectrum. This section focuses on parameter estimation, detailing the model choices and sample-selection criteria.\n",
      "\n",
      "## 3.1. Models for Parameter Estimation\n",
      "\n",
      "We explore two complementary approaches for stellar parameter estimation: MLPs and simulation-based inference (SBI), also known as implicit-likelihood or likelihood-free inference (Tejero-Cantero et al. 2020; Ho et al. 2024). SBI enables inference of parameter posteriors by learning the underlying distribution (e.g., the posterior itself) and evaluating on observed data, without requiring an explicit likelihood function.\n",
      "\n",
      "## 3.1.1. Multilayer Perceptrons\n",
      "\n",
      "For most downstream tasks involving LAMOST LRS and Gaia XP spectra, we employ MLPs due to their training efficiency and scalability, which make them suitable for processing large datasets with limited computational resources. Each MLP has the following layer architecture: [ input dim , 1024 , 512 , 64 , 1] , where input dim = { 1462 , 343 , 768 } depending on whether the input is raw LRS spectra, raw XP spectra, or embeddings. The output dimension is one, corresponding to a single stellar parameter. For pre-trained models via MT, we first reduce the representations by averaging over the sequence dimension (e.g., from [146 , 768] to [768] for the LAMOST model). The resulting 768-dimensional embeddings and their high-quality labels are then used as input to the MLP. For CLIP models and the pre-trained XP model via OAE, no reduction of dimension is required and we directly use the 768-dimensional (projected) embeddings together with their labels. Each MLP model has approximately 1.4 million trainable parameters when applied to the embeddings.\n",
      "\n",
      "## 3.1.2. Simulation-Based Inference\n",
      "\n",
      "For selected tasks, we also apply SBI for posterior inference. We report the median of the posterior as the point estimate.\n",
      "\n",
      "We follow the Neural Posterior Estimation (NPE) framework to directly estimate the posterior distribution of parameters given observations, using neural density estimators. This NPE-based approach is relatively straightforward to implement and computationally efficient, making it a practical choice compared to other variants such as Neural Likelihood Estimation (NLE). We adopt two types of (conditional) normalizing flows as density estimators from the sbi package (Tejero-Cantero et al. 2020): Masked Autoregressive Flow (MAF) (Papamakarios et al. 2017) and Neural Spline Flow (NSF) (Durkan et al. 2019). Each SBI model uses two transformations with 60 hidden units (unless otherwise noted), totaling roughly 0.1 million trainable parameters. Details of the adopted normalizing flows are described in Appendix C.\n",
      "\n",
      "To evaluate the calibration of the inferred posteriors, we perform simulation-based calibration (SBC, Talts et al. 2018) using rank statistics, also known as Probability Integral\n",
      "\n",
      "Transform (PIT) values in some literature (Gneiting et al. 2007), complemented by the Kolmogorov-Smirnov (K-S) test (Kolmogorov 1992). The K-S test measures the maximum discrepancy between the empirical cumulative distribution function (CDF) of the ranks and the expected uniform CDF, providing a non-parametric test of distributional consistency. For each (out of 200 in total) spectrum-parameter pair, we draw posterior samples and compute the rank of the ground-truth parameter value. Well-calibrated posteriors yield uniformly distributed ranks, which we assess via the K-S test. We consider results valid if the p -value exceeds 0.05, indicating that there is no significant deviation from uniformity and therefore reliable posterior coverage.\n",
      "\n",
      "## 4. DATASETS\n",
      "\n",
      "## 4.1. Sample Selection for Pre-training\n",
      "\n",
      "For the LRS model, we select a subset of 966,082 highquality spectra for pre-training, using a 9:1 train-validation split (the same split ratio is used for the other modeling efforts described in the following two subsections). The selection criteria are: (1) SNR in the SDSS g -band greater than 50, and (2) apparent g -band magnitude less than 15.8. Additionally, we include all spectral types beyond the AFGK classes, while attempting to balance the four AFGK types themselves. We also aim to balance giant and dwarf stars; however, due to the intrinsic distribution of the dataset, the final ratio of dwarfs to giants is approximately 3.8:1.\n",
      "\n",
      "For the XP model, we pre-train this model using one million Gaia XP spectra, with around 80% having matching LAMOST LRS spectra. Each XP spectrum consists of 343 flux points spanning wavelengths from 336 nm to 1021 nm.\n",
      "\n",
      "## 4.2. Sample Selection for Parameter Estimation\n",
      "\n",
      "For LAMOST LRS spectra, we evaluate parameter estimation across several classes of physical properties:\n",
      "\n",
      "1. Stellar atmospheric parameters: effective temperature ( T eff ), surface gravity (log g ), and iron abundance ([Fe/H]);\n",
      "2. Other elemental abundances: [ α /Fe], [C/Fe], [N/Fe], [Mg/Fe], [O/Fe], [Al/Fe], [Si/Fe], [Ca/Fe], [Ti/Fe], [Mn/Fe], [Ni/Fe], [Cr/Fe];\n",
      "3. Asteroseismic parameters and derived physical parameters: large frequency separation ( ∆ ν ), frequency of maximum oscillation power ( ν max ), stellar mass ( M ⊙ ), radius ( R ⊙ ), age (Gyr), and period spacing of gravity modes ( ∆Π );\n",
      "4. Other parameters: radial velocity ( v r ) and extinction E ( BP -RP ) .\n",
      "\n",
      "We selected approximately 100,000 stars per parameter to balance the parameter distribution and computational tractability. The quality-control criteria include g -band spectral SNR g &gt; 20, Gaia g -band magnitude &lt; 16.5, and | v r | &lt; 800 kms -1 to exclude likely extragalactic sources. LAMOST DR11 is used throughout; we adopt a 3 ′′ matching radius between it and other catalogs. For APOGEE, we typically (unless otherwise noted) require APOGEE SNR (median SNR per pixel in combined frame (at apStar sampling)) &gt; 50.\n",
      "\n",
      "Sample selection strategies for individual parameters are summarized below:\n",
      "\n",
      "- Radial Velocity ( v r ): We select 100,299 stars in common between APOGEE DR17 (Abdurro'uf et al. 2022) and the LAMOST LRS sample. Their radial velocities are approximately uniformly distributed over the range [ -800 , 800] km s -1 , divided into 800 bins, each containing up to 1600 stars.\n",
      "- Effective Temperature ( T eff ): Approximately 100,000 stars are uniformly sampled in the T eff -log g plane, divided into a 100 × 100 grid, with up to four stars per bin. The values of T eff are adopted from the LAMOST catalog.\n",
      "- Surface Gravity ( log g ): 100,000 stars combining log g labels from Kepler (Li et al. 2022b, mainly for red giant stars) and APOGEE DR17 (Abdurro'uf et al. 2022). Binned into 750 intervals (up to 350 stars per bin), with priority given to Kepler-based values.\n",
      "- Iron Abundance ( [Fe / H] ): A total of 100,118 stars are selected from a merged dataset comprising APOGEE DR17 (Abdurro'uf et al. 2022, for stars with [Fe / H] &gt; -2 . 0 ), supplemented with metal-poor stars from the PASTEL and SAGA compilations (Huang et al. 2024), the LAMOST/Subaru VMP sample (Li et al. 2022a), and UMP datasets (Sestito et al. 2019). Atargeted sampling strategy is used to ensure balanced coverage in [Fe/H].\n",
      "- Other Elemental Abundances : 85,400 stars from LAMOST-APOGEE cross-matches, filtered by APOGEE SNR &gt; 40 and valid abundance flags (i.e., C FE FLAG = 0, N FE FLAG = 0, MG FE FLAG = 0). A 2D binning in [Mg/Fe]-[Fe/H] space ( 632 × 632 bins) ensures broad and uniform sampling. The [ α /Fe] values used here are computed from APOGEE measurements as ALPHA M -( FE H -M H ), where ALPHA M includes O, Mg, Si, S, Ca, Ti, and Ti II (J¨ onsson et al. 2020).\n",
      "- Extinction ( E ( BP -RP ) ): A total of 86,000 stars, with extinction values estimated using the star-pair\n",
      "- technique (Yuan et al. 2013) based on the LAMOST stellar parameter catalog.\n",
      "- Asteroseismic Parameters: A total of 3,029 stars have asteroseismic parameters ∆ ν and ν max derived from Kepler light curves (Li et al. 2022b; Chaplin et al. 2014), including 2,718 red giant stars and 311 mainsequence/turn-off stars. In addition, 4,034 red giant stars have measured gravity-mode period spacing ∆Π , taken from published catalogs (Vrard et al. 2016).\n",
      "\n",
      "For Gaia XP spectra, we examine the following key parameters (with sample number in brackets) - [ α /Fe] (94,584), [C/Fe] (99,934), [N/Fe] (95,089), T eff (100,000), log g , [Fe/H] (113,218), and color excess E ( BP -RP ) (99,087) - based on consistent data sources. These datasets are crossmatched with the Gaia XP catalog. To enhance [C/Fe] coverage in the metal-poor regime, we further include stars from the LAMOST very metal-poor catalog, where [C/Fe] has been estimated using a customized version of the SEGUE Stellar Parameter Pipeline (LSSPP; Lee et al. 2015).\n",
      "\n",
      "All datasets are divided into a ratio of 0.81:0.09:0.10 for training, validation, and testing, respectively. The validation set is used for early stopping, that is, training is halted when performance on the validation set no longer improves within 10 training epochs. The testing set is kept out and used exclusively for reporting all downstream task results shown in the tables throughout the paper. An exception is made for the figures generated from the MLP-based downstream models, where we combine the training and validation sets for model training, as explained in Section 6.5.\n",
      "\n",
      "## 4.3. Sample Selection for External Validation\n",
      "\n",
      "Weuse multiple external datasets for validation. For LAMOST LRS, we perform two types of comparisons:\n",
      "\n",
      "1. Radial Velocity: Compared with GALAH DR4 (Buder et al. 2025), where 49,905 stars are selected for which GALAH's global RV fit succeeded ( FIT GLOBAL RV = True), with SNR PX CCD2 ≥ 20, LAMOST SNR g ≥ 20, and both GALAH RV COMP 1 and LAMOST RV having absolute values ≤ 999 km s -1 .\n",
      "\n",
      "## 2. Iron Abundance:\n",
      "\n",
      "- DESI DR1 (DESI Collaboration et al. 2025; Koposov et al. 2025): 119,335 stars are selected with LAMOST SNR g ≥ 30, DESI SN B ≥ 30, SUCCESS = True, and [Fe/H] ≥ -3 . 8 .\n",
      "- GALAH DR4: 33,411 stars are retained with FLAG FE H = 0, SNR PX CCD2 ≥ 30, LAMOST SNR g ≥ 30 in both surveys, and T eff ≥ 4000 K.\n",
      "\n",
      "For Gaia XP, the iron abundance validation uses:\n",
      "\n",
      "1. GALAH DR4: 33,411 stars satisfying FLAG SP = 0, SNR PX CCD2 ≥ 50, and T eff ≥ 4000 K.\n",
      "2. Gaia RVS catalog (Viswanathan et al. 2024): 1,413 cross-matched stars are used.\n",
      "\n",
      "## 4.4. Preprocessing\n",
      "\n",
      "For the LAMOST LRS spectrum, to focus on the most informative spectral features, we retain the 400-560 nm wavelength range, resulting in 1462 flux points per spectrum. The spectra are normalized before being input into the model; the normalization procedure is described in Appendix B, where an iterative polynomial fitting algorithm robustly estimates the stellar continuum across both blue and red wavelength segments while suppressing absorption features and noise. For the Gaia XP spectra, broad-band color information may sometimes carry more discriminative power than individual spectral features. We therefore normalize each spectrum by its flux at 550 nm which lies near the center of the V -band.\n",
      "\n",
      "## 5. RESULTS\n",
      "\n",
      "This section presents a comprehensive evaluation of SpecCLIP across multiple dimensions. We begin by comparing model variants, followed by parameter-estimation results for representative parameters using both LAMOST LRS and Gaia XP spectra. We end with demonstrations of spectral retrieval and cross-modal prediction.\n",
      "\n",
      "## 5.1. Model Comparison\n",
      "\n",
      "Table 1 summarizes the overall performance of different models on held-out test datasets for parameter estimation. The pre-trained model on LAMOST LRS spectra generally outperforms the raw spectra, and importantly, CLIP-based models consistently improve performance for both LAMOST LRS and Gaia XP spectra, in most tasks where raw spectra or pre-trained (on LAMOST LRS or Gaia XP only) models alone were less effective. One notable exception is the radial velocity v r from LAMOST LRS, where most CLIP-based models perform worse than the LRS pre-trained model. This is understandable, as radial velocity is primarily determined by line features in LAMOST LRS spectra, and the alignment between LAMOST and Gaia - taken at slightly different stellar epochs - may introduce inconsistencies that degrade performance. Another exception is the Asteroseismic Parameters -sbi task, where no clear differences are observed among models, possibly due to the small dataset size (3,029 stars). These results highlight the value of CLIP-based alignment.\n",
      "\n",
      "In particular, if checked more carefully, models with inmodal reconstruction decoders (e.g., CLIP-r and CLIP-pr compared with CLIP, and CLIP-pr compared with CLIP-p) generally show improved performance, as revealed by the\n",
      "\n",
      "'number of wins' in the table (last row), fairly accounting for the MLP-based downstream models only. This indicates enhanced informativeness of the learned representations for the estimation of downstream parameters. Overall, these results suggest that the inclusion of in-modal reconstruction decoders improves representation quality in most downstream applications.\n",
      "\n",
      "We hypothesize that these performance gains come from the model's ability to retain shared and modality-specific (non-shared) information. In the CLIP-pr variant, this is encouraged by jointly optimizing the contrastive loss, crossmodal prediction loss, and in-modal reconstruction loss. This architecture implicitly encourages the embeddings to retain complementary information from each modality.\n",
      "\n",
      "To further explore this hypothesis, we introduce the CLIPsplit model, which explicitly separates the projected embeddings into a 512-dimensional shared space and a 128dimensional non-shared space. Despite using fewer parameters (see Appendix E), CLIP-split performs competitively, particularly for core stellar parameters such as T eff , log g , and [Fe/H]. It also recovers radial velocity performance to a level comparable with the LAMOST LRS pre-trained model, suggesting that the embedding split scheme retains more LRSspecific line features relevant to RV estimation.\n",
      "\n",
      "Beyond parameter estimation, we also evaluated the models on two additional tasks using 50,000 paired spectra selected from the validation split of the datasets used for contrastive training with decoders.\n",
      "\n",
      "- Similarity Score: Measures how closely projected embeddings (or shared embeddings for CLIP-split) from different modalities align, which is crucial for cross-modal retrieval. Higher scores indicate more effective alignment.\n",
      "- Cross-Modal Prediction Score: Evaluates the weighted (by measurement error 5 ) mean squared error (MSE) between predicted and ground-truth spectra in cross-modal translation (e.g., LRS → XP or XP → LRS).\n",
      "\n",
      "These results are summarized in Table 2. We find that models with both reconstruction and prediction decoders (CLIPpr) yield improved performance on LRS → XP prediction, but slightly degrade the similarity score, an expected tradeoff when the embeddings are trained to retain both shared\n",
      "\n",
      "5 For comparison purposes (not exactly strictly), for LAMOST LRS, we propagate the inverse variance ( ivar ) of the flux measurements by multiplying by the square of the continuum fit ( C 2 ), transforming ivar to ivar · C 2 for the normalized spectrum. For Gaia XP spectra, when normalizing the flux ( F ) by the flux at 550nm ( F 550 ), the error ( σ F N ) of the normalized flux ( F N = F/F 550 ) is calculated using the standard error propagation for division: σ F N = F N √ ( σ F /F ) 2 +( σ F 550 /F 550 ) 2 , where σ F and σ F 550 are the respective flux errors.\n",
      "\n",
      "Table 1. Comparison of Model Performance (standard deviation of the residuals σ and coefficient of determination R 2 ) for different models evaluating on the held-out test datasets\n",
      "\n",
      "| LRS Models                          | LRS Models                          | LRS Models                    | LRS Models                    | LRS Models                | LRS Models                    | LRS Models                    | LRS Models                    |\n",
      "|-------------------------------------|-------------------------------------|-------------------------------|-------------------------------|---------------------------|-------------------------------|-------------------------------|-------------------------------|\n",
      "| Parameter                           | Raw Spectra σ / R 2                 | Pre-trained σ / R 2           | CLIP σ / R 2                  | CLIP-r σ / R 2            | CLIP-p σ / R 2                | CLIP-pr σ / R 2               | CLIP-split σ / R 2            |\n",
      "| Atmospheric Parameters              |                                     |                               |                               |                           |                               |                               |                               |\n",
      "| [Fe / H]                            | 0.070 / - 0.882                     | 0.066 / 0.939                 | 0.058 / 0.949                 | 0.057/0.949               | 0.058 / 0.949                 | 0.057 / 0.949                 | 0.056 / 0.954                 |\n",
      "| T eff (K)                           | 225.733 / 0.863                     | 147.344 / 0.989               | 131.069 / 0.990               | 137.360/ 0.990            | 131.095 / 0.990               | 128.065 / 0.990               | 132.669 / 0.990               |\n",
      "| T eff -sbi (maf) (K)                | 106.903 / 0.979                     | 94.942 / 0.990                | 96.577 / 0.990                | 94.930/ 0.990             | 95.004 / 0.990                | 95.346 / 0.990                | 93.047 / 0.990                |\n",
      "| T eff -sbi (nsf) (K)                | 76.986 / 0.982                      | 84.991 / 0.991 †              | 85.365 / 0.990                | 84.763/ 0.991             | 85.065 / 0.990                | 84.101 / 0.991                | 82.309 / 0.991                |\n",
      "| log g                               | 0.101 / 0.958                       | 0.091 / 0.981                 | 0.086 / 0.982                 | 0.084/0.983               | 0.086 / 0.982                 | 0.085 / 0.983                 | 0.079 / 0.985                 |\n",
      "| log g -sbi (maf)                    | 0.063 / 0.967                       | 0.062 / 0.981                 | 0.064 / 0.982                 | 0.065/0.983               | 0.065 / 0.984                 | 0.066 / 0.983                 | 0.064 / 0.985                 |\n",
      "| Elemental Abundances                |                                     |                               |                               |                           |                               |                               |                               |\n",
      "| [ α/ Fe]                            | 0.023 / 0.872                       | 0.021 / 0.906                 | 0.020 / 0.912                 | 0.020 /0.913              | 0.020 / 0.911                 | 0.020 / 0.916                 | 0.020 / 0.911                 |\n",
      "| [C / Fe]                            | 0.041 / 0.758                       | 0.039 / 0.792                 | 0.037 / 0.813                 | 0.037 /0.812              | 0.037 / 0.812                 | 0.037 / 0.814                 | 0.037 / 0.813                 |\n",
      "| [N / Fe]                            | 0.054 / 0.598                       | 0.052 / 0.642                 | 0.049 / 0.664                 | 0.049 /0.665              | 0.049 / 0.664                 | 0.049 / 0.667                 | 0.049 / 0.667                 |\n",
      "| [Al / Fe]                           | 0.049 / 0.691                       | 0.048 / 0.711                 | 0.046 / 0.741                 | 0.046 /0.739              | 0.046 / 0.738                 | 0.046 / 0.738                 | 0.046 / 0.736                 |\n",
      "| [Ca / Fe]                           | 0.032 / 0.670                       | 0.030 / 0.697                 | 0.029 / 0.719                 | 0.029 /0.720              | 0.029 / 0.721                 | 0.029 / 0.723                 | 0.029 / 0.714                 |\n",
      "| [Mg / Fe]                           | 0.031 / 0.866                       | 0.032 / 0.871                 | 0.031 / 0.882                 | 0.031 /0.882              | 0.031 / 0.881                 | 0.031 / 0.883                 | 0.031 /0.880                  |\n",
      "| [Si / Fe]                           | 0.029 / 0.776                       | 0.029 / 0.803                 | 0.028 / 0.813                 | 0.028 / 0.813             | 0.028 / 0.813                 | 0.028 / 0.812                 | 0.028 / 0.812                 |\n",
      "| [Ti / Fe]                           | 0.061 / 0.492                       | 0.058 / 0.532                 | 0.056 / 0.550                 | 0.055 /0.551              | 0.056 / 0.551                 | 0.055 / 0.552                 | 0.056 / 0.551                 |\n",
      "| [Mn / Fe]                           | 0.033 / 0.761                       | 0.032 / 0.780                 | 0.031 / 0.796                 | 0.031 / 0.798             | 0.031 / 0.797                 | 0.031 / 0.798                 | 0.031 / 0.793                 |\n",
      "| [Ni / Fe]                           | 0.027 / 0.426                       | 0.026 / 0.454                 | 0.025 / 0.490                 | 0.025 /0.486              | 0.025 / 0.486                 | 0.025 / 0.488                 | 0.025 / 0.485                 |\n",
      "| [O / Fe]                            | 0.051 / 0.698                       | 0.050 / 0.722                 | 0.049 / 0.729                 | 0.049/ 0.730              | 0.049 / 0.728                 | 0.048 / 0.730                 | 0.049 / 0.729                 |\n",
      "| [Cr / Fe]                           | 0.081 / 0.177                       | 0.076 / 0.225                 | 0.074 / 0.242                 | 0.075/0.240               | 0.075 / 0.239                 | 0.075 / 0.239                 | 0.075 / 0.232                 |\n",
      "| Asteroseismic Parameters -sbi (maf) | Asteroseismic Parameters -sbi (maf) |                               |                               |                           |                               |                               |                               |\n",
      "| ∆ ν                                 | 1.372 /0.901                        | 1.705/0.958                   | 1.491/0.841                   | 1.515/0.859               | 1.630/0.818                   | 1.491/0.862                   | 1.507/ 0.963                  |\n",
      "| ν max                               | 20.470 / 0.676                      | 23.597/0.330                  | 22.590/0.171                  | 23.738/0.296              | 22.149/0.615                  | 22.136/0.606                  | 23.822/0.623                  |\n",
      "| Mass ( M ⊙ )                        | 0.095/0.518                         | 0.094/0.570                   | 0.086/ 0.674                  | 0.087/0.670               | 0.084 /0.669                  | 0.085/0.664                   | 0.089/0.658                   |\n",
      "| Radius ( R ⊙ )                      | 0.604 /0.873                        | 0.708/0.859                   | 0.738/0.853                   | 0.728/0.853               | 0.723/0.843                   | 0.737/0.847                   | 0.713/ 0.880                  |\n",
      "| Age (Gyr)                           | 1.565/0.655                         | 1.488/0.684                   | 1.397/0.721                   | 1.347/0.744               | 1.347/ 0.751                  | 1.352/0.747                   | 1.337 /0.723                  |\n",
      "| ∆Π                                  | 28.078/0.891                        | 25.703/0.904                  | 21.471/0.923                  | 21.814/0.920              | 22.057/0.917                  | 21.346 /0.924                 | 22.713/ 0.925                 |\n",
      "| Other Parameters                    |                                     |                               |                               |                           |                               |                               |                               |\n",
      "| E ( BP - RP )                       | 0.075 / - 36.886                    | 0.076 / 0.711                 | 0.070 / 0.739                 | 0.070/0.740               | 0.069 / 0.742                 | 0.069 / 0.743                 | 0.072 / 0.741                 |\n",
      "| v r (km s - 1 )                     | 6.071 / 0.970                       | 5.345 / 0.978                 | 6.782 / 0.969                 | 6.158/0.972               | 6.749 / 0.969                 | 6.243 / 0.972                 | 5.289 / 0.979                 |\n",
      "| v r -sbi (maf) (km s - 1 )          | 4.573 / 0.963                       | 4.653 / 0.979                 | 5.774 / 0.959                 | 5.238/0.959               | 5.786 / 0.960                 | 5.270 / 0.961                 | 4.581 / 0.978                 |\n",
      "|                                     |                                     |                               | XP Models                     |                           |                               |                               |                               |\n",
      "| Parameter                           | Raw Spectra                         | Pre-trained σ / R 2           | CLIP 2                        | CLIP-r 2                  | CLIP-p 2                      | CLIP-pr 2                     | CLIP-split 2                  |\n",
      "|                                     | σ / R 2                             |                               | σ / R                         | σ / R                     | σ / R                         | σ / R                         | σ / R                         |\n",
      "| Atmospheric Parameters              |                                     |                               |                               |                           |                               |                               |                               |\n",
      "| [Fe / H]                            | 0.469 / -0.389                      | 0.126 / 0.884                 | 0.111 / 0.900                 | 0.111 / 0.900             | 0.111 / 0.900                 | 0.112 / 0.899                 | 0.113 / 0.894                 |\n",
      "| T eff (K)                           | 220.258 / 0.965                     | 199.458 / 0.969               | 172.722 / 0.974               | 169.602 / 0.974           | 172.638 / 0.974               | 171.811 / 0.974               | 170.696 / 0.973               |\n",
      "| T eff -sbi (maf) (K)                | . . . / . . . ‡                     | . . . / . . .                 | 173.804 / 0.968               | . . . /. . .              | . . . / . . .                 | . . . / . . .                 | . . . / . . .                 |\n",
      "| T eff -sbi (nsf) (K) log g          | 137.247 / 0.970 0.757 / 0.580       | 150.437 / 0.964 0.206 / 0.953 | 130.980 / 0.970 0.175 / 0.962 | 132.889/0.971 0.173/0.962 | 130.689 / 0.972 0.173 / 0.962 | 129.708 / 0.970 0.171 / 0.963 | 131.251 / 0.972 0.174 / 0.961 |\n",
      "| log g -sbi (maf)                    |                                     |                               |                               | 0.166/                    |                               | 0.167 / 0.959                 | 0.164 / 0.959                 |\n",
      "|                                     | 0.202 / 0.941                       | 0.182 / 0.952                 | 0.166 / 0.959                 | 0.959                     | 0.165 / 0.958                 |                               |                               |\n",
      "| Elemental Abundances                |                                     |                               |                               |                           |                               |                               |                               |\n",
      "| [ α/ Fe]                            | 0.103 / - 0.047                     | 0.056 / 0.737                 | 0.049 / 0.774                 | 0.048 / 0.777             | 0.049 / 0.773                 | 0.049 / 0.770                 | 0.050 / 0.765                 |\n",
      "| [C / Fe]                            | 0.194 / 0.073                       | 0.127 / 0.527                 | 0.118 / 0.547                 | 0.118/ 0.553              | 0.118 / 0.550                 | 0.117 / 0.549                 | 0.118 / 0.551                 |\n",
      "| [N / Fe]                            | 0.115 / - 4.040                     | 0.077 / 0.643                 | 0.072 / 0.673                 | 0.072 / 0.676             | 0.073 / 0.672                 | 0.072 / 0.674                 | 0.073 / 0.669                 |\n",
      "| Other Parameters E ( BP - RP )      | 0.077 / 0.725                       | 0.036 / 0.921                 | 0.036 / 0.926                 | 0.035 /0.927              | 0.036 / 0.925                 | 0.035 / 0.926                 | 0.035 / 0.929                 |\n",
      "| Number of wins (best σ or           | 0                                   | 0                             | 19                            | 24                        | 15                            | 29                            | 19                            |\n",
      "\n",
      "Note. 'CLIP' for contrastive training-only model, 'CLIP-r' for CLIP+reconstruction (LRS/XP) decoders, 'CLIP-p' for CLIP+cross decoders, 'CLIP-pr' for CLIP+all decoders, 'CLIP-split' for CLIP+all decoders and an explicit separation of shared and non-shared embedding spaces. Most values are run with down-stream models of MLP but the ones with '-sbi' suffix are generated by the SBI models, where two kinds of SBI models, MAF and NSF models, are applied. Numbers in bold indicate the best performance (i.e., lowest σ or highest R 2 ) for each parameter across all models. The last row reports the number of times each model achieves the best performance (i.e., lowest σ or highest R 2 ) for any parameter, based on results from MLP-based downstream models only. Some outliers in prediction may dominate the overall R 2 , occasionally leading to negative R 2 values. The numbers are reported as the average over 5 independent training runs, except for the results using SBI. For these, we report the single best-performing run among the five, selected based on a simulation-based calibration (SBC) test with a p -value threshold of at least 0.05, and prioritized by the lowest σ . † Results marked exclude a failed NSF sampling case on one extreme spectrum. ‡ Entries with dots indicate cases where all five runs failed the SBC test and no further tuning was performed. The same convention applies to other tables in this paper. We report the robust standard deviation of residuals ( σ ) using the Tukey Biweight Scale Estimator (Hoaglin et al. 1983), implementation available in robust sigma.py , in all tables where σ was used for internal model comparisons. For the plots involving external comparisons, we instead use sigma clip from astropy with 3 σ clipping, for ease of replication.\n",
      "\n",
      "Table 2. Comparison of Cross-Modal Prediction Errors and Similarity Scores in the Projected Embeddings\n",
      "\n",
      "| Model      | XP → LRS MSE   | LRS → XP MSE   |   Similarity |\n",
      "|------------|----------------|----------------|--------------|\n",
      "| CLIP       | . . .          | . . .          |       0.7828 |\n",
      "| CLIP-r     | . . .          | . . .          |       0.7783 |\n",
      "| CLIP-p     | 0.3932         | 3.20 × 10 - 3  |       0.782  |\n",
      "| CLIP-pr    | 0.3934         | 3.15 × 10 - 3  |       0.7778 |\n",
      "| CLIP-split | 0.3929         | 3.48 × 10 - 3  |       0.7854 |\n",
      "\n",
      "Note. Numbers in bold indicate the best performance (i.e., lowest MSE or highest similarity scores) across all models. Entries with dots indicate that the corresponding models are not applicable to the task.\n",
      "\n",
      "and non-shared information. Nevertheless, their similarity scores remain significantly higher than the baseline similarity (0.0533) obtained from comparing the embeddings between modality-specific pre-trained models.\n",
      "\n",
      "CLIP-split achieves the highest similarity score overall, even surpassing the baseline CLIP model, possibly aided by its lower embedding dimensionality, which tends to produce higher cosine similarities. It also delivers the best performance on the prediction of the LRS spectrum of XP → LRS, demonstrating the robustness of the model in all modalities.\n",
      "\n",
      "In summary, models with prediction and reconstruction decoders (CLIP-pr and CLIP-split) offer the best overall performance by balancing parameter-estimation accuracy, crossmodal predictability, and embedding similarity.\n",
      "\n",
      "## 5.2. Parameter Estimation 5.2.1. LAMOST LRS\n",
      "\n",
      "Figure 2 presents results for radial velocity and iron abundance estimation 6 . For radial velocity, we compare predictions from the LRS pre-trained model and the CLIP-split model with the official LAMOST stellar parameter catalog, using GALAH DR4 - which is not included in the training set - as an external benchmark. While our models produce slightly larger standard deviations (4.51 and 4.53 km s -1 compared to 4.22 km s -1 from the official LAMOST pipeline), they exhibit significantly smaller biases, producing values that are closer to the true measurements.\n",
      "\n",
      "From a computational perspective, our LRS-based RV inference is highly efficient: In an environment with 1 core (Intel® Xeon® Gold 6248 @ 2.50GHz) and 1 V100 GPU, inference takes ∼ 5ms per spectrum using SBI, and 1ms per spectrum using an MLP. However, as seen in Table 1, SBI\n",
      "\n",
      "6 The reported std values for all plots are calculated using sigma clip from astropy with 3 σ clipping.\n",
      "\n",
      "models provide better precision (lower σ ), while MLPs offer comparable or better accuracy ( R 2 ).\n",
      "\n",
      "For iron abundance [Fe/H], we benchmark our models against the DESI DR1 and GALAH DR4. Compared to DESI, the CLIP-split model demonstrates significantly better performance than the LAMOST official pipeline. The plateau in [Fe/H] around -2 . 5 , which arises from the lack of metal-poor stars in the stellar library used by the LAMOST pipeline, is effectively addressed by our models, although the overall scatter remains comparable. When benchmarked against GALAH, the CLIP-split model achieves both lower bias and lower scatter, highlighting its competitive performance relative to physically motivated pipelines. We further investigated the impact of rest-frame correction by applying the predicted RVs to shift the spectra before feeding them into the [Fe/H] prediction models. This additional step yields predictions that are broadly consistent with those from uncorrected inputs, indicating that correcting for radial velocity is not critical-at least for the resolution and wavelength coverage of LAMOST LRS. The insensitivity of the MLP-based [Fe/H] predictions to small redshifts implies that the model has implicitly learned to accommodate these variations.\n",
      "\n",
      "Although our main pipeline estimates one parameter per MLP model (multi-variate MLP is also straightforward, though we did not explore it in this paper), we also experimented with SBI variants that estimate either one or all parameters jointly. While overall performance was similar, joint estimation, especially with SBI, better captures parameter degeneracies. An example of inferred chemical abundances with SBI is shown in Appendix A, Figure A1.\n",
      "\n",
      "In general, our method compares favorably with previous work (Xiang et al. 2019; Li &amp; Lin 2023; Wang et al. 2023; Zhang et al. 2025; Zhao et al. 2025). Compared with the other data-driven methods listed, our approach generally requires fewer labeled training samples (typically &lt; 90,000) and minimal hyperparameter tuning, as we adopt a unified architecture for all downstream models. Relative to physicsdriven methods such as template fitting or forward modeling, our model does not require synthetic spectral templates or explicit physical modeling at inference time. This design, combined with diverse training data, enables applicability across a wide range of stellar types and delivers fast predictions once trained. Although our method avoids physical modeling during inference, its effectiveness still depends on high-quality labels, all of which are ultimately derived from physics-based modeling approaches. These characteristics make our method both efficient and broadly applicable in practice. However, direct comparison with previous literature remains challenging due to differences in the composition of the test set. For example, our iron abundance test set extends to [Fe/H] ∼ -4 , increasing the difficulty of achieving a general low scatter or a high R 2 .\n",
      "\n",
      "Figure 2. Comparison between the LAMOST catalog and SpecCLIP models (including the pre-trained LRS model and the LRS branch of the CLIP-split model). From top to bottom: The radial velocity (RV) comparison as a function of the GALAH labels; [Fe/H] comparison as a function of the DESI labels; [Fe/H] comparison as a function of the GALAH labels; and [Fe/H] comparison as a function of the GALAH labels with input spectra shifted to the rest frame using the predicted RVs from the corresponding models in the top row. For RV, which is inferred using the SBI downstream model, the pre-trained LRS model and CLIP-split model have slightly larger scatter but smaller bias, compared with the LAMOST catalog; For [Fe/H], inferred using MLP downstream models (as with all other figures), the pre-trained LRS model and CLIP-split model gives either smaller scatter over the metal-poor region (referring to DESI labels) or overall smaller scatter and bias (referring to GALAH labels). The RV-corrected spectra result in similar [Fe/H] prediction performance, suggesting that the trained MLP models are relatively robust to modest Doppler shifts in the LAMOST LRS spectra. The dashed lines are the one-to-one lines. The numbers in the upper left of each panel are the mean offsets and standard deviation of the residuals (y-axis minus x-axis).\n",
      "\n",
      "## 5.2.2. Gaia XP\n",
      "\n",
      "Figure 3 shows [Fe/H] predictions from the Gaia XP model (both pre-trained and CLIP-split models) compared with ground truth from the GALAH DR4 and Gaia RVS catalog. Our predictions are consistent across the entire iron abundance range, including the metal-poor regime down to about [Fe/H] = -3 . 5 or even -4 . 0 , and outperform previous machine learning methods (Andrae et al. 2023), particularly at our ability to extend to low iron abundances. The overall scatter is below 0.08 dex for stars with [Fe/H] &gt; -2 . 0 , and below 0.18 dex for stars with [Fe/H] &lt; -2 . 0 . This performance surpasses that achieved by traditional low-resolution spectroscopy.\n",
      "\n",
      "Figure 4 highlights 135,370 extremely metal-poor (EMP) star candidates with iron abundances in the range -5 &lt; [Fe / H] &lt; -3 , identified by our XP branch of the CLIP-\n",
      "\n",
      "Figure 3. Comparison of [Fe/H] estimates from SpecCLIP (pre-trained XP model and XP branch of the CLIP-pr model) with reference labels from GALAH (top) and Gaia RVS (bottom). Both models correlate well with reference labels, with the CLIP-pr model yielding lower scatter and bias. The dashed lines are the one-to-one lines. The numbers is the upper left of each panel are the mean offsets and standard deviation of the residuals.\n",
      "\n",
      "pr model. These stars exhibit a pronounced concentration toward the Galactic center, reminiscent of the 'metal-poor heart of the Galaxy' reported by Rix et al. (2022), but now extending to significantly lower iron abundances than previously observed. A dedicated follow-up study based on this sample is currently underway, aiming to shed light on the earliest phases of the Milky Way's chemical and structural evolution.\n",
      "\n",
      "Performance metrics in various XP models are shown in Table 1. Again, CLIP-based models (CLIP, CLIP-pr, CLIPsplit) are competitive compared to earlier approaches, including Huang et al. (2024) and Li et al. (2024b). Notably, our test sets span a wide parameter range. For example, [Fe/H] extends down to around -4 . 0 and T eff extends up to 13,500 K, further validating the robustness of our models.\n",
      "\n",
      "## 5.3. Spectral Retrieval and Prediction 5.3.1. Spectral Retrieval\n",
      "\n",
      "Beyond parameter estimation, SpecCLIP also enables retrieval of similar spectra within the learned embedding space, both within a single modality and across different modalities.\n",
      "\n",
      "Figure 4. Spatial density distributions of extremely metal-poor stars ( -5 &lt; [Fe / H] &lt; -3 ) derived from SpecCLIP (CLIP-pr model) in Galactic coordinates, showing a clear 'metal-poor old heart' of our Galaxy.\n",
      "\n",
      "Figure 5 shows examples of in-modal and cross-modal retrievals given a specific query spectrum. Retrieval is based on cosine similarity in the (projected) embedding space, using either the full or shared embeddings (for CLIP-split). In this figure, the search is performed using the CLIP-pr model\n",
      "\n",
      "Figure 5. Two examples of in-modal retrieval, cross-modal retrieval, cross-modal prediction, and the LAMOST (Gaia) spectra corresponding to Gaia (LAMOST) in-modal retrieval. The similarity scores are defined in the projected embedding space.\n",
      "\n",
      "on a test set of 82,057 spectra, with the query spectrum excluded from the database. In both LAMOST LRS and Gaia XP cases, the retrieved spectra closely resemble the query spectra, indicating that the model has learned well-aligned representations across modalities.\n",
      "\n",
      "In practice, additional strategies can be used to retrieve spectra using auxiliary catalog links. For example, given a query LAMOST spectrum and a LAMOST-to-Gaia crossmatch library, one could first retrieve the top LAMOST matches (in-modal) and then fetch their Gaia counterparts via the library. Alternatively, if the paired Gaia spectrum of the query is known, one could retrieve similar Gaia spectra directly (in-modal), or indirectly by performing a Gaia-toLAMOST retrieval followed by a database lookup to obtain the corresponding Gaia spectra. While Figure 5 presents only two retrieval use cases, assuming that we know only the information of the query spectrum itself, not its paired othermodal spectrum. The other more elaborate approaches are straightforward extensions.\n",
      "\n",
      "These capabilities suggest promising applications in data mining and search-based discovery. For instance, starting from a LAMOST spectrum of a rare type of star, one could search for spectrally similar candidates in the Gaia XP database of over two billion stars. Such functionality could\n",
      "\n",
      "Table 3. Comparison of Model Performance (standard deviation of the residuals σ and coefficient of determination R 2 ) for pre-trained XP models with different embedding dimensions (256, 343, 512, 768), where 768 is adopted in this paper\n",
      "\n",
      "| XP Models              | XP Models              | XP Models              | XP Models              | XP Models              | XP Models              |\n",
      "|------------------------|------------------------|------------------------|------------------------|------------------------|------------------------|\n",
      "| Parameter              | Raw Spectra σ / R 2    | 256 σ / R 2            | 343 σ / R 2            | 512 σ / R 2            | 768 σ / R 2            |\n",
      "| Atmospheric Parameters | Atmospheric Parameters | Atmospheric Parameters | Atmospheric Parameters | Atmospheric Parameters | Atmospheric Parameters |\n",
      "| [Fe / H]               | 0.469 / - 0.389        | 0.128 / 0.881          | 0.127 / 0.882          | 0.129 / 0.879          | 0.126 / 0.884          |\n",
      "| T eff (K)              | 220.258 / 0.965        | 201.126 / 0.967        | 203.142 / 0.967        | 196.401 / 0.968        | 199.458 / 0.969        |\n",
      "| log g                  | 0.757 / 0.580          | 0.207 / 0.952          | 0.208 / 0.951          | 0.197 / 0.955          | 0.206 / 0.953          |\n",
      "| Elemental Abundances   | Elemental Abundances   | Elemental Abundances   | Elemental Abundances   | Elemental Abundances   | Elemental Abundances   |\n",
      "| [ α/ Fe]               | 0.103 / - 0.047        | 0.057 / 0.732          | 0.057 / 0.731          | 0.056 / 0.738          | 0.056 / 0.737          |\n",
      "| [C / Fe]               | 0.194 / 0.073          | 0.129 / 0.527          | 0.128 / 0.525          | 0.129 / 0.526          | 0.127 / 0.527          |\n",
      "| [N / Fe]               | 0.115 / - 4.040        | 0.079 / 0.631          | 0.080 / 0.628          | 0.077 / 0.641          | 0.077 / 0.643          |\n",
      "| Other Parameters       | Other Parameters       | Other Parameters       | Other Parameters       | Other Parameters       | Other Parameters       |\n",
      "| E ( BP - RP )          | 0.077 / 0.725          | 0.038 / 0.913          | 0.039 / 0.915          | 0.036 / 0.915          | 0.036 / 0.921          |\n",
      "\n",
      "Note. Numbers in bold indicate the best performance (i.e., lowest σ or highest R 2 ) for each parameter across all models.\n",
      "\n",
      "significantly enhance large-scale searches for rare or unusual stellar types.\n",
      "\n",
      "## 5.3.2. Spectral Prediction\n",
      "\n",
      "SpecCLIP's cross-modal decoders also support spectral translation, that is, predicting the spectrum in one modality from a spectrum in another. These decoders operate directly on the projected embeddings (shared embeddings in the case of CLIP-split), using learned mappings between modalities.\n",
      "\n",
      "We find that for the majority of the test dataset, the model performs well in both directions (LRS → XP and XP → LRS), indicating that it effectively learns the mapping between these two spectroscopic modalities. Examples of such predictions are shown in Figure 5 as black curves.\n",
      "\n",
      "However, for a subset of sources-particularly in the LRS → XP direction-prediction quality deteriorates. Apart from the potential effect of extinction, which may be poorlycaptured by the trained model. This discrepancy may suggest that the source does not follow the behavior of a typical single star. For instance, it could be an unresolved binary or an otherwise anomalous object. These cases highlight an exciting future direction, using the cross-modal prediction error as a basis for anomaly detection.\n",
      "\n",
      "We leave a more systematic exploration of anomaly detection and rare-object identification to future work.\n",
      "\n",
      "## 6. DISCUSSION\n",
      "\n",
      "## 6.1. SBI Performance with NSF and MAF\n",
      "\n",
      "In Table 1, we present the SBI results for several parameters ( T eff , log g , v r , and asteroseismic parameters) that demonstrate the benefits of adopting SBI. For parameters showing relatively clear differences between NSF and MAF, we include results from both; for those exhibiting visually biased predictions in one of the two SBI methods, we conservatively report only the other. For parameters modeled by both methods (e.g., T eff ), we observe better performance with NSF, likely due to its higher flexibility in representing non- linear conditional dependencies between spectra and stellar parameters.\n",
      "\n",
      "In our additional experiments, we observed that applying NSF to projected embeddings led to degraded performance in the low-iron abundance regime ( [Fe / H] ≲ -1 . 5 ). Similarly, LAMOST LRS radial velocity predictions exhibited a systematic underestimation of the absolute value at large radial velocities; a similar issue is widely discussed in machine learning-based estimators (Ting 2024). Interestingly, replacing NSF with MAF eliminated these issues.\n",
      "\n",
      "These results suggest that NSF is more expressive than MAF, this increased expressiveness can adversely affect performance in our applications when modeling distributions near parameter-space boundaries. A likely explanation is that the spline transformations used in NSF, while highly flexible within their domain, become problematic in sparsely sampled boundary regions. Specifically, NSF employs rational-quadratic splines over a finite interval (default: ± 3 σ in standardized space), with linear tail transformations beyond this range.\n",
      "\n",
      "In astrophysical parameter spaces where extreme values ( [Fe / H] ≲ -1 . 5 , | v rad | ≳ 150 km s -1 ) represent several percent of the population, these linear tails systematically mis-model the true distribution shape. Furthermore, the flexibility of spline binning can lead to overfitting in regions with sparse training coverage, where bin allocation becomes poorly constrained.\n",
      "\n",
      "In contrast, MAF's simpler affine transformations naturally extend over the full unbounded support of the distribution with stable linear extrapolation, providing more robust behavior at distribution boundaries despite lower overall expressiveness. The contrasting performance between NSF and MAF highlights the importance of matching normalizing flow architecture to the characteristics of astrophysical parameter distributions, and motivates further investigation of boundary-aware flow designs for simulation-based inference in astronomy.\n",
      "\n",
      "## 6.2. Compression vs. Feature Learning\n",
      "\n",
      "A common assumption is that compression improves downstream performance. However, our Gaia XP foundation model shows a more nuanced behavior. In Table 3, we vary the embedding dimension and find that reducing it from 343 (the original XP spectrum length) to 256 leads to comparable performance. In contrast, using embedding dimensions equal to or greater than the input size yields better results.\n",
      "\n",
      "This suggests that effective feature learning. rather than compression alone, is key to high downstream performance in this case. Mapping 343 flux points into a higherdimensional latent space (e.g., 768) may allow the model to capture richer nonlinear correlations and disentangle latent physical factors (e.g., T eff , log g , [Fe/H], extinction), forming expressive embeddings for downstream prediction. We note, however, that increasing the embedding dimension also increases the number of trainable parameters in the downstream MLP, which may partly explain the improved performance. These interpretations remain tentative and will be further examined in future work.\n",
      "\n",
      "## 6.3. Interpretability of Parameter Estimation\n",
      "\n",
      "One potential concern is that the models may rely on spurious correlations in the data to estimate parameters. While forward models like Payne and DD-Payne allow straightforward inspection of such behavior, our neural networks do not offer easy interpretability.\n",
      "\n",
      "Recent techniques, such as sparse autoencoders (Cunningham et al. 2023), could improve the explainability of the model in future work. However, our model achieves high precision and accuracy on held-out datasets, suggesting that it is indeed learning physically meaningful representations. Further testing with carefully designed datasets will be necessary to validate this assumption and improve model interpretability.\n",
      "\n",
      "## 6.4. SBI vs. MLP\n",
      "\n",
      "Although we report MLP results for most tasks, we observe that SBI tends to outperform MLP in terms of uncertainty (as measured by σ ), while MLP yields comparable or better accuracy (as measured by R 2 ), as shown in Table 1.\n",
      "\n",
      "This discrepancy may arise from their differing training objectives; MLPs minimize the MSE, which aligns closely with R 2 , whereas SBI focuses on modeling the entire posterior distribution. In this work, we estimate the posterior median from SBI (rather than the mean), which is more robust to outliers. However, we note that differences in the adopted hyperparameters (see Appendix G) may also contribute to the discrepancy\n",
      "\n",
      "Thus, for applications where uncertainty quantification is essential, SBI is the preferred choice. For fast and accurate point estimates, MLP is more suitable. In particular, our\n",
      "\n",
      "SBI models use only ∼ 0.1 million trainable parameters, compared to ∼ 1.4 million for the MLP models.\n",
      "\n",
      "## 6.5. Training Sample Size and Dataset Configuration\n",
      "\n",
      "We observe a positive correlation between the size of the training set and the performance of the model in the downstream tasks. Although our benchmark experiments use ∼ 100,000 stars per parameter, we note that performance may not have plateaued, indicating room for improvement with additional data.\n",
      "\n",
      "Nevertheless, even with this moderate sample size, our models match or outperform state-of-the-art results in the literature (Section 5.2). To maximize data usage, we report metrics based on held-out test sets, while for plots generated using the downstream models, we combine the training and validation sets for training, with early stopping based on performance on the test set.\n",
      "\n",
      "Future work may adopt more advanced techniques such as k -fold cross-validation, which would allow iterative use of the entire dataset and further improve model reliability and performance.\n",
      "\n",
      "## 6.6. Is Transformer Overkill?\n",
      "\n",
      "In Table 4, we compare MT and OAE with equivalent numbers of trainable parameters and identical training epochs. For LAMOST LRS spectra, MT outperforms OAE. However, for Gaia XP spectra, OAE performs better.\n",
      "\n",
      "These results suggest that transformers may be more advantageous for longer spectra (e.g., LRS with 1462 flux points), while offering limited benefits, or even unnecessary complexity, for shorter inputs like Gaia XP spectra (343 points). Another possible explanation is the difference in optimal training epochs for different architectures, as discussed in R´ o˙ za´ nski &amp; Ting (2025) and R´ o˙ za´ nski et al. (2025). This warrants further exploration to better match model capacity to data complexity.\n",
      "\n",
      "## 6.7. Fine-tuning Loss Weights\n",
      "\n",
      "Not all non-shared information in the spectra is necessarily beneficial-some components, such as noise, may even hinder downstream performance. Moreover, the importance of shared versus non-shared information can vary across tasks; some may depend more on modality-specific features, while others benefit primarily from shared representations. Therefore, fine-tuning the weight terms in Equation 1, particularly the loss weight of reconstruction, may be a promising direction for future work.\n",
      "\n",
      "In this work, we fix both weights to 1, applying equal weighting to the reconstruction and cross-modal prediction losses. This choice shows that models incorporating reconstruction loss already perform competitively without explicit weight adjustment, as evidenced by the number of highest\n",
      "\n",
      "performing metrics (i.e. 'wins') in Table 1 (last row)-e.g., CLIP-r vs. CLIP, and CLIP-pr/CLIP-split vs. CLIP-p. However, the magnitude of performance gains remains modest and somewhat task-dependent. Reweighting the losses may further increase the total number of improvements or yield more substantial gains on specific parameters. However, the latter-optimizing for specific tasks-might come at the cost of generality, which is contrary to the fundamental goal of building a model that performs robustly across diverse downstream tasks.\n",
      "\n",
      "Table 4. Comparison of Model Performance (standard deviation of the residuals σ and coefficient of determination R 2 ) between masked transformer (MT) and MLP-based ordinary auto-encoder (OAE)\n",
      "\n",
      "| LRS Models                     | LRS Models             | LRS Models             | LRS Models             |\n",
      "|--------------------------------|------------------------|------------------------|------------------------|\n",
      "| Parameter                      | Raw Spectra σ / R 2    | MT σ / R 2             | OAE σ / R 2            |\n",
      "| Atmospheric Parameters         | Atmospheric Parameters | Atmospheric Parameters | Atmospheric Parameters |\n",
      "| [Fe / H]                       | 0.070 / - 0.882        | 0.066 / 0.939          | 0.070 / 0.905          |\n",
      "| T eff (K)                      | 225.733 / 0.863        | 147.344 / 0.989        | 181.777 / 0.975        |\n",
      "| log g                          | 0.101 / 0.958          | 0.091 / 0.981          | 0.084 / 0.973          |\n",
      "| Elemental Abundances           | Elemental Abundances   | Elemental Abundances   | Elemental Abundances   |\n",
      "| [ α/ Fe]                       | 0.023 / 0.872          | 0.021 / 0.906          | 0.020 / 0.904          |\n",
      "| [C / Fe]                       | 0.041 / 0.758          | 0.039 / 0.792          | 0.039 / 0.776          |\n",
      "| [N / Fe]                       | 0.054 / 0.598          | 0.052 / 0.642          | 0.053 / 0.624          |\n",
      "| [Al / Fe]                      | 0.049 / 0.691          | 0.048 / 0.711          | 0.049 / 0.693          |\n",
      "| [Ca / Fe]                      | 0.032 / 0.670          | 0.030 / 0.697          | 0.031 / 0.688          |\n",
      "| [Mg / Fe]                      | 0.031 / 0.866          | 0.032 / 0.871          | 0.030 / 0.873          |\n",
      "| [Si / Fe]                      | 0.029 / 0.776          | 0.029 / 0.803          | 0.029 / 0.793          |\n",
      "| [Ti / Fe]                      | 0.061 / 0.492          | 0.058 / 0.532          | 0.059 / 0.507          |\n",
      "| [Mn / Fe]                      | 0.033 / 0.761          | 0.032 / 0.780          | 0.033 / 0.758          |\n",
      "| [Ni / Fe]                      | 0.027 / 0.426          | 0.026 / 0.454          | 0.027 / 0.445          |\n",
      "| [O / Fe]                       | 0.051 / 0.698          | 0.050 / 0.722          | 0.051 / 0.704          |\n",
      "| [Cr / Fe]                      | 0.081 / 0.177          | 0.076 / 0.225          | 0.079 / 0.200          |\n",
      "| Other Parameters E ( BP - RP ) | 0.076 / - 23.199       | 0.076 / 0.711          | 0.076 / 0.681          |\n",
      "| v r (km s - 1 )                | 6.418 / 0.942          | 5.345 / 0.978          | 5.938/0.966            |\n",
      "| XP Models                      | XP Models              | XP Models              | XP Models              |\n",
      "| Parameter                      | Raw Spectra σ / R 2    | MT σ / R 2             | OAE σ / R 2            |\n",
      "| Atmospheric Parameters         | Atmospheric Parameters | Atmospheric Parameters | Atmospheric Parameters |\n",
      "| [Fe / H]                       | 0.469 / - 0.389        | 0.137 / 0.867          | 0.126 / 0.884          |\n",
      "| T eff (K)                      | 220.258 / 0.965        | 215.299 / 0.965        | 199.458 / 0.969        |\n",
      "| log g                          | 0.757 / 0.580          | 0.206 / 0.953          | 0.206 / 0.953          |\n",
      "| Elemental Abundances           | Elemental Abundances   | Elemental Abundances   | Elemental Abundances   |\n",
      "| [ α/Fe ]                       | 0.103 / - 0.047        | 0.059 / 0.713          | 0.056 / 0.737          |\n",
      "| [C / Fe]                       | 0.194 / 0.073          | 0.132 / 0.498          | 0.127 / 0.527          |\n",
      "| [N / Fe]                       | 0.115 / - 4.040        | 0.079 / 0.615          | 0.077 / 0.643          |\n",
      "| Other Parameters E ( BP - RP ) | 0.077 / 0.725          | 0.041 / 0.913          | 0.036 / 0.921          |\n",
      "\n",
      "Note. Numbers in bold indicate the best performance (i.e., lowest σ or highest R 2 ) for each parameter across all models.\n",
      "\n",
      "In this work, we develop a foundation model framework for stellar spectra that enables strong and efficient performance across multiple downstream tasks. Our approach integrates separate pre-trained models, each trained on a distinct spectroscopic modality (LAMOST LRS or Gaia XP), and aligns them using CLIP-style contrastive learning. To further enhance the information capacity of the embeddings, we introduce decoder modules that increase the mutual information between the embeddings and input spectra and enable translation (prediction) between different spectral types.\n",
      "\n",
      "Our main findings are summarized below:\n",
      "\n",
      "- The pre-trained foundation models for both spectral modalities demonstrate strong performance with a relatively small number of labeled examples (i.e., fewshot learning). Using ∼ 100,000 stars with highquality labels, they achieve competitive parameter inference performance across a range of stellar parameters. Comparisons with the LAMOST official release and high-resolution reference catalogs (e.g., GALAH, and APOGEE) confirm the accuracy and reliability of our method.\n",
      "- Performance is further improved by contrastive alignment and the addition of decoders, which increase the robustness and expressiveness of the learned embeddings. These enhancements are especially beneficial for parameter estimation and spectral prediction.\n",
      "- We explore the use of SBI as an alternative to MLPs for downstream parameter estimation. SBI provides improved uncertainty modeling and higher precision for certain parameters, albeit at a higher inference cost and a lower model capacity.\n",
      "- Our models support both in-modal and cross-modal spectrum retrieval, as well as spectrum-to-spectrum prediction across modalities. High similarity and prediction scores demonstrate that the learned representations capture shared physical information. These modules also offer promising avenues for anomaly detection and similarity-based searches in large spectral archives.\n",
      "\n",
      "Looking ahead, we plan to extend this framework to additional spectroscopic modalities, including LAMOST medium-resolution spectra (MRS, Li et al. 2024a), APOGEE infrared spectra (Majewski et al. 2017), Subaru PFS spectra (Takada et al. 2014), and DESI DR1 spectra (DESI Collaboration et al. 2025). Our approach can be readily adapted to new instruments by pre-training modality-specific encoders and aligning them with contrastive objectives and decoder structures developed in this work. In future iterations, we will also explore efficient adaptation via neural network adapters,\n",
      "\n",
      "enabling scalable multi-survey alignment with minimal computational cost. In forthcoming work, a large-scale application and catalog release is planned.\n",
      "\n",
      "## ACKNOWLEDGEMENTS\n",
      "\n",
      "The Guoshoujing Telescope (the Large Sky Area MultiObject Fiber Spectroscopic Telescope, LAMOST) is a National Major Scientific Project built by the Chinese Academy of Sciences. Funding for the project has been provided by the National Development and Reform Commission. LAMOST is operated and managed by the National Astronomical Observatories, Chinese Academy of Sciences.\n",
      "\n",
      "CEE), and OISE-1927130; The International Research Network for Nuclear Astrophysics (IReNA), awarded by the US National Science Foundation, and DE-SC002312; the Center for Nuclear Astrophysics Across Messengers (CeNAM), awarded by the U.S. Department of Energy, Office of Science, Office of Nuclear Physics. Y.S.T. is supported by the National Science Foundation under Grant No. AST2406729. G.X. and X.T. acknowledge the support from Key R&amp;D Program of Zhejiang (2024SSYS0006).\n",
      "\n",
      "We are thankful for useful discussions with Ce Sui, Alexander S. Szalay, Rosemary F.G. Wyse, and Benjamin D. Wandelt during the early stages of this work.\n",
      "\n",
      "Y.H. acknowledges support from the National Science Foundation of China (NSFC grant No. 12422303), the Fundamental Research Funds for the Central Universities (grant Nos. 118900M122, E5EQ3301X2, and E4EQ3301X2), and the National Key R&amp;D Program of China (grant No. 2023YFA1608303). X.Z. acknowledges partial support through a grant from the Schmidt Sciences Foundation. While this project was initiated prior to his current appointment at JHU, a significant portion of the work was completed during his Schmidt-supported position. T.C.B. acknowledges partial support from grants PHY 14-30152; Physics Frontier Center/JINA Center for the Evolution of the Elements (JINA-\n",
      "\n",
      "## DATA AVAILABILITY\n",
      "\n",
      "All observational data used in this work are publicly available from the archives. A frozen version of the SpecCLIP software used in this analysis has been archived on Zenodo (Zhao &amp; Huang 2025) in compliance with the AAS Journals software policy. No proprietary data were used.\n",
      "\n",
      "Software: SpecCLIP (Zhao &amp; Huang 2025), PyTorch (Paszke et al. 2019), Astropy (Astropy Collaboration et al. 2013, 2018)\n",
      "\n",
      "## APPENDIX\n",
      "\n",
      "Here we present additional information on multiple aspects of this work, including elemental-abundance prediction, continuum fitting, normalization flows for parameter estimation, the use of pre-trained models, projection models and decoders, and loss curves.\n",
      "\n",
      "## A. ADDITIONAL RESULTS FOR ELEMENTAL-ABUNDANCE ESTIMATION\n",
      "\n",
      "Figure A1 presents an example of chemical-abundance predictions from one input spectrum. This result is obtained using SBI trained with a single model for all parameters simultaneously. The inset in the upper right corner shows results from simulationbased calibration (SBC). Most elemental abundances exhibit well-calibrated posteriors, except for [Ti/Fe] and [Ca/Fe], which fall below the significance threshold of 0.05. This provides an example where, despite the model learns posterior distributions well overall, further tuning of the SBI architecture or its hyper-parameters is necessary to achieve reliable multivariate inference of elemental abundances-an aspect we did not further refine in this work.\n",
      "\n",
      "In Table A1, we provide downstream task results using CLIP-based models aligned between the LAMOST LRS MT and Gaia XP MT encoders. This serves as a comparison to Table 1, where alignment is performed between the LAMOST LRS MT and Gaia XP OAE models. We find that the latter configuration shows overall comparable or better performance across the evaluation metrics, possibly due to the stronger pretraining of the XP OAE model. For completeness, in Figure A2 we include an external comparison analogous to Figure 2 in the main text, but using the models from Table A1.\n",
      "\n",
      "## B. CONTINUUM FITTING ALGORITHM\n",
      "\n",
      "Although we applied continuum fitting only to the blue segment ( 4000 ˚ A ≤ λ ≤ 5600 ˚ A) of the LAMOST LRS spectra for our analysis, we describe here the full continuum fitting algorithm, which is designed to robustly estimate the stellar continuum over the full wavelength range ( 3850 ˚ A ≤ λ ≤ 9000 ˚ A), and remains effective under varying SNRs. The method takes as input the observed wavelength array w , the corresponding flux array f , and an estimate of the average SNR, and returns a smooth continuum model c .\n",
      "\n",
      "The procedure is summarized as follows:\n",
      "\n",
      "Figure A1. An example of posterior distributions of 12 elemental abundances inferred using simulation-based inference (SBI), with a downstream model trained jointly in the 12-dimensional parameter space. The embeddings used for training are from the pre-trained LRS foundation model. The upper-right panel shows simulation-based calibration (SBC) results, indicating that most posteriors are well-calibrated except for [Ti/Fe] and [Ca/Fe], which fall below the 0.05 significance threshold.\n",
      "\n",
      "1. Pre-processing: The flux array is first smoothed using a median filter of width 7 pixels to reduce the impact of narrow-line features and noise. The resulting smoothed flux is split into two wavelength segments: a blue side ( 3700 ≤ λ ≤ 5700 ˚ A) and a red side ( λ &gt; 6100 ˚ A).\n",
      "2. Denoising with Savitzky-Golay filter: The Savitzky-Golay filter is applied to each segment independently, with a smoothing window size of 3.\n",
      "3. Blue Segment Adjustment (if sufficiently sampled): A fifth-order polynomial is initially fit to the smoothed blue-side flux to identify the peak region. If the peak occurs at wavelengths &lt; 4500 ˚ A, interpolation is applied over three manu-\n",
      "\n",
      "Table A1. Similar to Table 1 for 'LRS Models', but the results for all CLIP-based models are from the alignment between the LAMOST LRS MT and Gaia XP MT (see Section 6.6 for discussion, and Appendices D and E for model details).\n",
      "\n",
      "| LRS Models                | LRS Models          | LRS Models          | LRS Models      | LRS Models      | LRS Models      | LRS Models         |\n",
      "|---------------------------|---------------------|---------------------|-----------------|-----------------|-----------------|--------------------|\n",
      "| Parameter                 | Raw Spectra σ / R 2 | Pre-trained σ / R 2 | CLIP σ / R 2    | CLIP-p σ / R 2  | CLIP-pr σ / R 2 | CLIP-split σ / R 2 |\n",
      "| Atmospheric Parameters    |                     |                     |                 |                 |                 |                    |\n",
      "| [Fe / H]                  | 0.070 / - 0.882     | 0.066 / 0.939       | 0.058 / 0.948   | 0.059 / 0.948   | 0.057 / 0.949   | 0.058 / 0.950      |\n",
      "| T eff (K)                 | 225.733 / 0.863     | 147.344 / 0.989     | 139.242 / 0.989 | 129.569 / 0.990 | 133.980 / 0.990 | 131.461 / 0.990    |\n",
      "| T eff -sbi (maf) (K)      | 106.903 / 0.979     | 94.942 / 0.990      | 97.396 / 0.990  | 95.147 / 0.989  | 96.208 / 0.990  | 93.155 / 0.990     |\n",
      "| T eff -sbi (nsf) (K)      | 76.986 / 0.982      | 84.991 / 0.991 †    | 86.515 / 0.991  | 86.133 / 0.989  | 84.517 / 0.990  | 84.694 / 0.992     |\n",
      "| log g                     | 0.101 / 0.958       | 0.091 / 0.981       | 0.087 / 0.982   | 0.084 / 0.982   | 0.084 / 0.982   | 0.083 / 0.983      |\n",
      "| log g -sbi(maf)           | 0.063 / 0.967       | 0.062 / 0.981       | 0.064 / 0.985   | 0.065 / 0.983   | 0.064 / 0.983   | 0.064 / 0.983      |\n",
      "| Elemental Abundances      |                     |                     |                 |                 |                 |                    |\n",
      "| [ α/ Fe]                  | 0.023 / 0.872       | 0.021 / 0.906       | 0.020 / 0.912   | 0.020 / 0.912   | 0.020 / 0.913   | 0.021 / 0.909      |\n",
      "| [C / Fe]                  | 0.041 / 0.758       | 0.039 / 0.792       | 0.038 / 0.806   | 0.038 / 0.804   | 0.038 / 0.805   | 0.038 / 0.803      |\n",
      "| [N / Fe]                  | 0.054 / 0.598       | 0.052 / 0.642       | 0.050 / 0.662   | 0.050 / 0.661   | 0.050 / 0.665   | 0.051 / 0.657      |\n",
      "| [Al / Fe]                 | 0.049 / 0.691       | 0.048 / 0.711       | 0.046 / 0.739   | 0.046 / 0.739   | 0.046 / 0.740   | 0.046 / 0.737      |\n",
      "| [Ca / Fe]                 | 0.032 / 0.670       | 0.030 / 0.697       | 0.029 / 0.714   | 0.029 / 0.714   | 0.029 / 0.716   | 0.030 / 0.711      |\n",
      "| [Mg / Fe]                 | 0.031 / 0.866       | 0.032 / 0.871       | 0.031 / 0.882   | 0.031 / 0.882   | 0.031 / 0.881   | 0.031 / 0.878      |\n",
      "| [Si / Fe]                 | 0.029 / 0.776       | 0.029 / 0.803       | 0.028 / 0.814   | 0.028 / 0.813   | 0.028 / 0.816   | 0.028 / 0.807      |\n",
      "| [Ti / Fe]                 | 0.061 / 0.492       | 0.058 / 0.532       | 0.056 / 0.551   | 0.056 / 0.552   | 0.056 / 0.555   | 0.056 / 0.544      |\n",
      "| [Mn / Fe]                 | 0.033 / 0.761       | 0.032 / 0.780       | 0.031 / 0.800   | 0.031 / 0.799   | 0.031 / 0.798   | 0.031 / 0.792      |\n",
      "| [Ni / Fe]                 | 0.027 / 0.426       | 0.026 / 0.454       | 0.025 / 0.487   | 0.025 / 0.489   | 0.025 / 0.489   | 0.026 / 0.479      |\n",
      "| [O / Fe]                  | 0.051 / 0.698       | 0.050 / 0.722       | 0.049 / 0.728   | 0.049 / 0.729   | 0.049 / 0.729   | 0.049 / 0.728      |\n",
      "| [Cr / Fe]                 | 0.081 / 0.177       | 0.076 / 0.225       | 0.075 / 0.234   | 0.075 / 0.233   | 0.075 / 0.237   | 0.075 / 0.232      |\n",
      "| Other Parameters          |                     |                     |                 |                 |                 |                    |\n",
      "| E ( BP - RP )             | 0.075 / - 36.886    | 0.076 / 0.711       | 0.070 / 0.746   | 0.069 / 0.748   | 0.069 / 0.748   | 0.070 / 0.742      |\n",
      "| v r (km s - 1 )           | 6.071 / 0.970       | 5.345 / 0.978       | 6.785 / 0.969   | 6.834 / 0.969   | 6.226 / 0.973   | 5.361 / 0.979      |\n",
      "| v r -sbi(maf) (km s - 1 ) | 4.573 / 0.963       | 4.653 / 0.979       | 5.636 / 0.958   | 5.621 / 0.963   | 5.070 / 0.965   | 4.578 / 0.981      |\n",
      "\n",
      "Note. Numbers in bold indicate the best performance (i.e., lowest σ or highest R 2 ) for each parameter across all models. † Results marked exclude a failed NSF sampling case on one extreme spectrum.\n",
      "\n",
      "ally selected continuum windows ([4030-4160], [4270-4410], [4800-4940] ˚ A) to estimate local maxima and reduce the influence of absorption features on the continuum estimation. An iterative process is then performed. In each iteration, a fifth-order polynomial is fit to the updated flux, and the fit is used to suppress absorption features, effectively lifting the continuum. Ten such iterations are performed to ensure convergence.\n",
      "\n",
      "4. Red Segment Correction: A fourth-order polynomial fit is applied iteratively to the red-side segment. At each step, outliers deviating more than 3 σ below the fit (or any point below the fit) are replaced by the polynomial value. This process is repeated up to 8 iterations to suppress absorption features and stabilize the continuum estimate.\n",
      "5. Final Continuum Assembly: The fitted continuum segments are combined to form the full continuum model c over the input wavelength grid. Values of c ≤ 0 are replaced by 1.0 to ensure a strictly positive continuum.\n",
      "\n",
      "## C. NORMALIZING FLOWS FOR PARAMETER ESTIMATION\n",
      "\n",
      "Normalizing flows provides a flexible and tractable approach to modeling complex probability distributions by transforming a simple base distribution through a sequence of invertible and differentiable mappings. In SBI, we use normalizing flows to learn an approximate posterior q ϕ ( θ | x ) , conditioned on observations x , following the Neural Posterior Estimation (NPE) framework.\n",
      "\n",
      "Let z ∼ p Z ( z ) denote a sample from a base distribution (e.g., standard Gaussian), and let f ϕ ( · ; x ) be an invertible transformation conditioned on x , mapping z ↦→ θ . Then, the density of θ under the flow model is given by the change-of-variables formula:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where θ = f ϕ ( z ; x ) .\n",
      "\n",
      "For simplicity, we present the flow as a single transformation f ϕ , but in practice it consists of a sequence of transformations:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "Figure A2. Similar to Figure 2, but the results for all CLIP-based models are from the alignment between the LAMOST LRS MT and Gaia XP MT (see Section 6.6 for discussion, and Appendices D and E for model details).\n",
      "\n",
      "where each f k is an invertible and differentiable function with a tractable Jacobian. The log-determinant of the full transformation is the sum of the log-determinants of each layer:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where h k = f k ( h k -1 ) , with h 0 = z and h K = θ .\n",
      "\n",
      "## C.1. Masked Autoregressive Flow (MAF)\n",
      "\n",
      "MAF (Papamakarios et al. 2017)) models the forward transformation z ↦→ θ as a sequence of autoregressive operations. Each component of θ is computed as:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where µ i and σ i are outputs of neural networks that depend on the previous components z &lt;i (or equivalently, the previous output components θ &lt;i ) and the conditioning variable x . The Jacobian of this transformation is lower triangular, which allows the\n",
      "\n",
      "log-determinant to be computed efficiently:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "C.2. Neural Spline Flow (NSF)\n",
      "\n",
      "NSF (Durkan et al. 2019) generalizes MAF by replacing affine transformations with monotonic rational-quadratic splines. Each component is transformed as:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where ψ i are spline parameters (bin widths, heights, and derivatives) predicted by a neural network conditioned on z &lt;i and x . The log-determinant of the Jacobian is given by:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where each derivative term is efficiently computed from the analytical form of the spline. Note that while this autoregressive form is analogous to MAF, the default implementation based on the provided code is often the coupling layer variant of NSF (NSF-C), which is typically more efficient for density evaluation. Details on the coupling layer structure can be referred to in Durkan et al. (2019).\n",
      "\n",
      "In summary, both MAF and NSF enable flexible posterior approximation in the NPE setting, while maintaining exact likelihood evaluation and efficient training via maximum likelihood.\n",
      "\n",
      "## D. PRE-TRAINED MODELS\n",
      "\n",
      "In this paper, we tried two different kinds of pre-trained models, one is the transformer-based model and the other is a MLPbased auto-encoder. Both kinds of networks have the same number of trainable parameters (42.7 million). We use a batch size of 64 per GPU. The models are optimized using AdamW (Loshchilov &amp; Hutter 2017) with a learning rate of 1 × 10 -5 and a weight decay of 0.1. The learning rate follows a cosine annealing schedule with linear warm-up.\n",
      "\n",
      "## D.1. Transformer-Based Spectral Pre-trained Models\n",
      "\n",
      "We describe two transformer models designed for the masked reconstruction of stellar spectra, based on Parker et al. (2024), each tailored to the characteristics of a different input data set: LAMOST and Gaia XP.\n",
      "\n",
      "## D.1.1. Masked Spectral Modeling for LAMOST Spectra\n",
      "\n",
      "This model is designed for higher-resolution (compared with Gaia XP) spectra from instruments like LAMOST, where each input sample is x ∈ R T × 1 with T = 1462 wavelength bins. The model operates as a masked sequence autoencoder using transformers.\n",
      "\n",
      "Input Pre-processing. -Each spectrum x ∈ R T × 1 is standardized with:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "Then, the standardized spectrum is sliced into overlapping chunks of length L (e.g., L = 20 ) with overlap O = 10 , forming an input sequence of length S = 146 , and a special token x ′ 0 = log 10 σ is pre-pended, forming an extended sequence x ′ ∈ R T ′ × ( L +1) with sequence length T ′ = S +1 .\n",
      "\n",
      "Model Architecture. -The input is linearly embedded and added to the learned positional embeddings. Then it passes through N = 6 layers of standard transformer blocks with H = 6 attention heads. The output is normalized and decoded through a linear projection.\n",
      "\n",
      "Masking Strategy. -To train the model in a self-supervised fashion, we applied a chunk-based masking strategy. Given an input sequence of length T ′ , we conceptually divide it into M = 6 segments of equal-length and randomly select a contiguous piece of width w = 10 within each segment to mask. For each chunk, its starting index is sampled uniformly from the allowable range within the segment. This ensures that the masked regions are distributed across the sequence and sufficiently separated.\n",
      "\n",
      "Formally, let the i -th segment span the indices [ s i , s i + ℓ ] , where ℓ = ⌊ T ′ /M ⌋ . Then the masked region for segment i is:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where t ∈ [0 , T ′ -1] is the sequence index. This strategy preserves long-range contextual integrity and forces the model to interpolate realistic spectral values across variable scales. Compared to random masking, chunk-based masking is more appropriate for spectral data, where features span contiguous wavelength regions.\n",
      "\n",
      "Loss Function. -Let f θ (˜ x ) denote the model's reconstruction output, the model is trained to reconstruct only the masked regions using a masked MSE loss:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "where m t = 1 if t is masked and 0 otherwise.\n",
      "\n",
      "LAMOST spectra benefit from local patterns and detailed features. Thus, using dense chunk-based masking and slicing helps the transformer leverage locality while preserving the global context. We train this model with 8 GPUs over a total of 128 epochs, a process that takes roughly 20 hours.\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "This model targets low-resolution Gaia XP spectra where each sample is x ∈ R T × 1 with T = 343 wavelength bins.\n",
      "\n",
      "Input Pre-processing. -As in the LAMOST model, we standardize the spectrum and pre-pend two (mean and standard deviation) tokens:\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "The masked input ˜ x is defined as:\n",
      "\n",
      "forming an extended sequence x ′ ∈ R ( T +2) × 1 .\n",
      "\n",
      "The model architecture and the loss function are similar to the LAMOST case.\n",
      "\n",
      "We train this model with 8 GPUs and a total of 191 epochs, which is roughly 40 hours.\n",
      "\n",
      "## D.2. MLP-based Autoencoder\n",
      "\n",
      "For comparison with the transformer-based models, we also construct an MLP-based autoencoder to pre-train the stellar spectra. For both LAMOST LRS and Gaia XP, the network architectures are similar: an initial projection layer of shape [ input dim , hidden dim ] ; the encoder consists of two MLP blocks, each with structure [ hidden dim , 3 × hidden dim , hidden dim ] ; followed by a bottleneck layer of shape [ hidden dim , 768] . The decoder mirrors this structure to reconstruct the input spectra. For LAMOST LRS, we use input dim = 1462 + 1 and hidden dim = 1245 ; for Gaia XP, we use input dim = 343 + 2 and hidden dim = 1290 . The former includes one additional (logarithmic) standard deviation as the first token, while the latter includes both the mean and the standard deviation as the first two tokens. We train the LRS model on 4 GPUs for 128 epochs, taking approximately 140 minutes, and the Gaia XP model 4 GPUs for 191 epochs, taking approximately 150 minutes.\n",
      "\n",
      "## E. PROJECTION MODELS AND DECODERS\n",
      "\n",
      "This section provides details about the modules used in CLIP-based model training. For these models, we use 8 GPU and require a total of roughly 3 hours for training. All model variants use a batch size of 1024 per GPU for contrastive training with decoders. We adopt the AdamW optimizer with a learning rate of 1 × 10 -4 and a weight decay of 0.05. The learning rate is scheduled using a cosine annealing schedule with linear warm-up.\n",
      "\n",
      "## E.1. Projection Networks\n",
      "\n",
      "For the projection networks, the LAMOST LRS model follows Parker et al. (2024). We first obtain the output from a pre-trained LAMOST LRS model, then go through a cross-attention module with a learnable query vector. The cross-attention module has four attention heads with an output dimension of 768. Finally, we have an MLP layer with hidden features that have dimension 4 × 768 . We did not compress the information more in this projected network in order to investigate the information gain without compression. Therefore, the dimension of the final projected embedding is still 768. The number of trainable parameters is about 7.1 million.\n",
      "\n",
      "For the Gaia XP spectra pre-trained with the transformer-based spectral model, we use the same projection networks as for the LAMOST LRS model. For the Gaia XP spectra pre-trained with a MLP-based autoencoder, our projection network has the dimension of [768 , 768 , 1160 , 768] , with a residual MLP block at the end with hidden dimension 4 × 768 . The choice of number of layers and the dimension of each layer is arbitrary; the key control condition is to maintain the same number of total trainable parameters as its cross-attention counterpart (7.1 million).\n",
      "\n",
      "For the CLIP-split model, the LAMOST LRS projection network (5.1 million) outputs two branches for shared and non-shared representations:\n",
      "\n",
      "- Shared : uses CrossAttentionHead with 512-D projection and n = 4 heads.\n",
      "- Non-shared : uses CrossAttentionHead with 256-D projection and n = 2 heads.\n",
      "\n",
      "Both branches use MLPs with hidden size 4 × 768 .\n",
      "\n",
      "The Gaia XP projection network paired with the transformer-based pre-trained model has the same architecture as the LAMOST LRS projection network. For the projection network (also 5.1 million trainable parameters) paired with MLP-based pretrained model, it outputs two latent representations:\n",
      "\n",
      "- Shared : linear projection to 512-D, followed by MLP: [512, 1160, 512].\n",
      "- Non-shared : linear projection to 256-D, followed by MLP: [256, 1160, 256].\n",
      "\n",
      "Each pathway includes a residual MLP block at the end with hidden dimension of 4 × 512 and 4 × 256 , respectively.\n",
      "\n",
      "## E.2. Decoders\n",
      "\n",
      "For the CLIP-pr model, the XP Decoder and LRS → XP cross decoder share the same architecture with MLP layer dimensions: [in, 4 × in, 2 × in, in, out] (8.5 million). The LRS decoder and XP → LRS cross decoder share the same architecture with layer dimensions: [in, 4 × in, 4 × in, 4 × in, out] (25.8 million), where in = 768 ; out = 1462 and 343 for LAMOST LRS and Gaia XP, respectively. Note that for LAMOST LRS, we are only reconstructing the normalized spectra with the mean and standard deviation calculated for each spectra, similar for the CLIP-split model.\n",
      "\n",
      "For the CLIP-split model, both LRS (14.0 million) and XP (0.1 million) decoders take shared and non-shared features to reconstruct the original spectra. Shared and non-shared inputs are projected to the out dimension, where out = 1462 and 343 for LAMOST LRS and Gaia XP, respectively. The two outputs are concatenated, and the final reconstruction layer contains [out × 2, out × 2, out].\n",
      "\n",
      "For the cross-modal decoder of the CLIP-split model, we take only the shared representation as input. The decoder architecture depends on the output dimension, yielding approximately 12.5 and 3.9 million trainable parameters for the following two setups:\n",
      "\n",
      "- For LAMOST (out &gt; shared) : [512, 2048, 2048, 2048, out].\n",
      "- For Gaia XP (out ≤ shared) : [512, 2048, 1024, 512, out].\n",
      "\n",
      "## F. LOSS CURVES\n",
      "\n",
      "This section presents the comparisons of the loss curves between the CLIP-pr and CLIP-split models, as shown in Figure F3. Although the CLIP-pr model achieves a lower CLIP loss during training, it exhibits a lower absolute cosine similarity in test pairs, as shown in Table 2. This discrepancy may arise from two factors. First, the geometry of the high-dimensional embedding spaces-768 dimensions in the CLIP-pr projected embedding versus 512 in the CLIP-split shared embedding-tends to yield lower cosine similarity in the former. Second, the CLIP loss focuses on relative alignment rather than absolute similarity. Additionally, the CLIP-pr model yields slightly lower cross-modal prediction losses. In contrast, the CLIP-split model converges more quickly in learning the reconstruction and achieves marginally lower reconstruction loss, likely due to its design of a non-shared projected embedding space.\n",
      "\n",
      "Figure F3. Loss curves of the CLIP-pr and CLIP-split models.\n",
      "\n",
      "## G. SUMMARY OF KEY HYPER-PARAMETERS AND CONFIGURATIONS\n",
      "\n",
      "Table G2 summarizes the key hyper-parameters and configurations used across the main training stages. For complete details and implementation settings, please refer to Appendix D, Appendix E, and Section 2.\n",
      "\n",
      "Table G2. Summary of hype-parameters and configurations across main training stages.\n",
      "\n",
      "| CLIP temp   | Loss weights             | Epochs / Time Loss fn.                           | GPUs   | Batch / GPU       | Learning rate Weight decay LR schedule   | Masking / Rate Optimizer   | Latent dim. Tokenization              | Encoder / Layers                     | Setting              |            | Loss fn. Loss weights CLIP temp τ                                | Epochs / Time                 | LR schedule Batch / GPU                        | rate decay          | Learning Weight            | Latent dim. Tokenization Chunks Masking / Rate Optimizer   | Encoder / Layers                    | Setting     |\n",
      "|-------------|--------------------------|--------------------------------------------------|--------|-------------------|------------------------------------------|----------------------------|---------------------------------------|--------------------------------------|----------------------|------------|------------------------------------------------------------------|-------------------------------|------------------------------------------------|---------------------|----------------------------|------------------------------------------------------------|-------------------------------------|-------------|\n",
      "| 15.5        | w recon = w pred = 1 . 0 | 110 / 3 h L CLIP + w recon L recon + w pred L    | 1024 8 | Cosine + warm-up  | 1 × 10 - 4 0.05                          | - AdamW                    | 768 Same as CLIP                      | Cross-Attn (4 heads)+MLP             | CLIP-pr              |            | Masked MSE - -                                                   | 128 / 20 h                    | Cosine + warm-up 64                            | 1 × 10 - 5 0.10     | Chunk-based ( ∼ 45%) AdamW | 768 ( L =20 , O =10 )+ log 10 σ                            | 6 Self-Attn (6 heads) 2             | LRSMT       |\n",
      "| 15.5        | w recon = w pred = 1 . 0 | 110 / 3 h pred L CLIP + w recon L recon + w pred | 1024 8 | Cosine + warm-up  | 1 × 10 - 4 0.05                          | - AdamW                    | 512+256 Same as CLIP                  | 2 Cross-Attn branches                | CLIP-split           | (Continue) | - - - 15.5                                                       | 191 / 2.5 h 110 /3 MSE L CLIP | Cosine + warm-up Cosine + 64 1024              | 1 × 10 - 5 1 × 0.10 | - AdamW AdamW              | 768 768 Prepend µ,σ Use pre-trained -                      | MLP blocks enc.+dec. Cross-Attn (4  | XP OAE CLIP |\n",
      "| -           | -                        | Max. 100 / < 10 min L pred MSE                   | 32 1   | ReduceLROnPlateau | 1 × 1 × 10 - 4                           | - AdamW                    | Raw spectra /                         | 4 MLP [in,1024,512,64,1]             | Downstream MLP       |            | 15.5                                                             | h L CLIP + w recon            | warm-up Cosine + 1024                          | 10 - 4 1 0.05       |                            | 768 embeddings Same as                                     | heads)+MLP Cross-Attn (4            | CLIP-r      |\n",
      "| -           | -                        | - / < 10 min Negative log-likelihood             | 50 1   | -                 | 10 - 5 5 × 10 -                          | - Adam - 4                 | - embeddings Raw spectra / embeddings | 2 transforms, 60 hidden units each - | Downstream SBI (NPE) |            | recon L CLIP + w pred L pred w recon = 1 . 0 w pred = 1 . 0 15.5 | 110 / 3 h 110 / 3 h L         | 1 × 10 0.05 0.05 warm-up Cosine + warm-up 1024 | × 10 - 4            | - AdamW AdamW - 4          | 768 CLIP Same as CLIP -                                    | heads)+MLP Cross-Attn (4 heads)+MLP | CLIP-p      |\n",
      "\n",
      "## REFERENCES\n",
      "\n",
      "Abazajian, K., Adelman-McCarthy, J. K., Ag¨ ueros, M. A., et al. 2003, AJ, 126, 2081, doi: 10.1086/378165\n",
      "\n",
      "Euclid Collaboration, Siudek, M., Huertas-Company, M., et al. 2025, arXiv e-prints, arXiv:2503.15312,\n",
      "\n",
      "Abdurro'uf, Accetta, K., Aerts, C., et al. 2022, ApJS, 259, 35, doi: 10.3847/1538-4365/ac4414\n",
      "\n",
      "Andrae, R., Rix, H.-W., &amp; Chandra, V. 2023, ApJS, 267, 8, doi: 10.3847/1538-4365/acd53e\n",
      "\n",
      "Astropy Collaboration, Robitaille, T. P., Tollerud, E. J., et al. 2013, A&amp;A, 558, A33, doi: 10.1051/0004-6361/201322068\n",
      "\n",
      "Astropy Collaboration, Price-Whelan, A. M., Sip˝ ocz, B. M., et al. 2018, AJ, 156, 123, doi: 10.3847/1538-3881/aabc4f\n",
      "\n",
      "Barber, D., &amp; Agakov, F. 2003, in Proceedings of the 17th International Conference on Neural Information Processing Systems, NIPS'03 (Cambridge, MA, USA: MIT Press), 201-208\n",
      "\n",
      "Brown, T., Mann, B., Ryder, N., et al. 2020, in Advances in Neural Information Processing Systems, ed. H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, &amp; H. Lin, Vol. 33 (Curran Associates, Inc.), 1877-1901. https://proceedings.neurips.cc/paper files/ paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n",
      "\n",
      "Buck, T., &amp; Schwarz, C. 2024, arXiv e-prints, arXiv:2410.16081, doi: 10.48550/arXiv.2410.16081\n",
      "\n",
      "Buder, S., Kos, J., Wang, X. E., et al. 2025, PASA, 42, e051, doi: 10.1017/pasa.2025.26\n",
      "\n",
      "Chaplin, W. J., Basu, S., Huber, D., et al. 2014, ApJS, 210, 1, doi: 10.1088/0067-0049/210/1/1\n",
      "\n",
      "Cui, X.-Q., Zhao, Y.-H., Chu, Y.-Q., et al. 2012, Research in Astronomy and Astrophysics, 12, 1197, doi: 10.1088/1674-4527/12/9/003\n",
      "\n",
      "Cunningham, H., Ewart, A., Riggs, L., Huben, R., &amp; Sharkey, L. 2023, arXiv e-prints, arXiv:2309.08600, doi: 10.48550/arXiv.2309.08600\n",
      "\n",
      "De Angeli, F., Weiler, M., Montegriffo, P., et al. 2023, A&amp;A, 674, A2, doi: 10.1051/0004-6361/202243680\n",
      "\n",
      "de Jong, J. T. A., Yanny, B., Rix, H.-W., et al. 2010, ApJ, 714, 663, doi: 10.1088/0004-637X/714/1/663\n",
      "\n",
      "De Silva, G. M., Freeman, K. C., Bland-Hawthorn, J., et al. 2015, MNRAS, 449, 2604, doi: 10.1093/mnras/stv327\n",
      "\n",
      "DESI Collaboration, Aghamousa, A., Aguilar, J., et al. 2016, arXiv e-prints, arXiv:1611.00036, doi: 10.48550/arXiv.1611.00036\n",
      "\n",
      "DESI Collaboration, Abdul-Karim, M., Adame, A. G., et al. 2025, arXiv e-prints, arXiv:2503.14745, doi: 10.48550/arXiv.2503.14745\n",
      "\n",
      "Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. 2018, arXiv e-prints, arXiv:1810.04805, doi: 10.48550/arXiv.1810.04805\n",
      "\n",
      "Devon Hjelm, R., Fedorov, A., Lavoie-Marchildon, S., et al. 2018, arXiv e-prints, arXiv:1808.06670, doi: 10.48550/arXiv.1808.06670\n",
      "\n",
      "Durkan, C., Bekasov, A., Murray, I., &amp; Papamakarios, G. 2019, arXiv e-prints, arXiv:1906.04032, doi: 10.48550/arXiv.1906.04032\n",
      "\n",
      "doi: 10.48550/arXiv.2503.15312\n",
      "\n",
      "Fitzpatrick, M. J., Olsen, K., Economou, F., et al. 2014, in Observatory Operations: Strategies, Processes, and Systems V, ed. A. B. Peck, C. R. Benn, &amp; R. L. Seaman, Vol. 9149, International Society for Optics and Photonics (SPIE), 91491T, doi: 10.1117/12.2057445\n",
      "\n",
      "Freeman, K., &amp; Bland-Hawthorn, J. 2002, ARA&amp;A, 40, 487, doi: 10.1146/annurev.astro.40.060401.093840\n",
      "\n",
      "Gaia Collaboration, Vallenari, A., Brown, A. G. A., et al. 2023, A&amp;A, 674, A1, doi: 10.1051/0004-6361/202243940\n",
      "\n",
      "Gilmore, G., Wyse, R. F. G., &amp; Kuijken, K. 1989, ARA&amp;A, 27, 555, doi: 10.1146/annurev.aa.27.090189.003011\n",
      "\n",
      "Gneiting, T., Balabdaoui, F., &amp; Raftery, A. E. 2007, Journal of the Royal Statistical Society Series B: Statistical Methodology, 69, 243, doi: 10.1111/j.1467-9868.2007.00587.x\n",
      "\n",
      "Gray, J., Szalay, A. S., Thakar, A. R., Stoughton, C., &amp; vandenBerg, J. 2002, in Virtual Observatories, ed. A. S. Szalay, Vol. 4846, International Society for Optics and Photonics (SPIE), 103 - 107, doi: 10.1117/12.461524\n",
      "\n",
      "Hackstein, J., Sumbul, G., Clasen, K. N., &amp; Demir, B. 2024, arXiv e-prints, arXiv:2401.07782, doi: 10.48550/arXiv.2401.07782\n",
      "\n",
      "Helmi, A. 2020, ARA&amp;A, 58, 205, doi: 10.1146/annurev-astro-032620-021917\n",
      "\n",
      "Helou, G., Madore, B. F., Schmitz, M., et al. 1991, in Astrophysics and Space Science Library, Vol. 171, Databases and On-line Data in Astronomy, ed. M. A. Albrecht &amp; D. Egret, 89-106, doi: 10.1007/978-94-011-3250-3 10\n",
      "\n",
      "Ho, M., Bartlett, D. J., Chartier, N., et al. 2024, The Open Journal of Astrophysics, 7, 54, doi: 10.33232/001c.120559\n",
      "\n",
      "Hoaglin, D. C., Mosteller, F., &amp; Tukey, J. W. 1983, Understanding Robust and Exploratory Data Analysis (New York: John Wiley &amp;Sons)\n",
      "\n",
      "Huang, Y., Beers, T. C., Xiao, K., et al. 2024, ApJ, 974, 192, doi: 10.3847/1538-4357/ad6b94\n",
      "\n",
      "J¨ onsson, H., Holtzman, J. A., Allende Prieto, C., et al. 2020, AJ, 160, 120, doi: 10.3847/1538-3881/aba592\n",
      "\n",
      "Jumper, J., Evans, R., Pritzel, A., et al. 2021, nature, 596, 583 Kaplan, J., McCandlish, S., Henighan, T., et al. 2020, CoRR, abs/2001.08361. https://arxiv.org/pdf/2001.08361.pdf\n",
      "\n",
      "Koleva, M., Prugniel, P., Bouchard, A., &amp; Wu, Y. 2009, A&amp;A, 501, 1269, doi: 10.1051/0004-6361/200811467\n",
      "\n",
      "Kolmogorov, A. 1992, On the Empirical Determination of a Distribution Function, ed. S. Kotz &amp; N. L. Johnson (New York,\n",
      "\n",
      "NY: Springer New York), 106-113, doi: 10.1007/978-1-4612-4380-9 10\n",
      "\n",
      "Koposov, S. E., Li, T. S., Allende Prieto, C., et al. 2025, arXiv e-prints, arXiv:2505.14787, doi: 10.48550/arXiv.2505.14787\n",
      "\n",
      "- Lee, Y. S., Beers, T. C., Sivarani, T., et al. 2008, AJ, 136, 2022, doi: 10.1088/0004-6256/136/5/2022\n",
      "- Lee, Y. S., Beers, T. C., Carlin, J. L., et al. 2015, AJ, 150, 187, doi: 10.1088/0004-6256/150/6/187\n",
      "- Leung, H. W., &amp; Bovy, J. 2024, MNRAS, 527, 1494, doi: 10.1093/mnras/stad3015\n",
      "- Li, C.-q., Shi, J.-r., Yan, H.-l., et al. 2024a, ApJS, 273, 18, doi: 10.3847/1538-4365/ad5002\n",
      "- Li, H., Aoki, W., Matsuno, T., et al. 2022a, ApJ, 931, 147, doi: 10.3847/1538-4357/ac6514\n",
      "- Li, J., Wong, K. W. K., Hogg, D. W., Rix, H.-W., &amp; Chandra, V. 2024b, ApJS, 272, 2, doi: 10.3847/1538-4365/ad2b4d\n",
      "- Li, T., Li, Y ., Bi, S., et al. 2022b, ApJ, 927, 167, doi: 10.3847/1538-4357/ac4fbf\n",
      "- Li, X., &amp; Lin, B. 2023, MNRAS, 521, 6354, doi: 10.1093/mnras/stad831\n",
      "- Loshchilov, I., &amp; Hutter, F. 2017, arXiv e-prints, arXiv:1711.05101, doi: 10.48550/arXiv.1711.05101\n",
      "- Luo, A. L., Zhao, Y.-H., Zhao, G., et al. 2015, Research in Astronomy and Astrophysics, 15, 1095, doi: 10.1088/1674-4527/15/8/002\n",
      "- Majewski, S. R., Schiavon, R. P., Frinchaboy, P. M., et al. 2017, AJ, 154, 94, doi: 10.3847/1538-3881/aa784d\n",
      "- Margon, B. 1999, Philosophical Transactions of the Royal Society of London Series A, 357, 93, doi: 10.1098/rsta.1999.0316\n",
      "- Moitinho, A., Krone-Martins, A., Savietto, H., et al. 2017, A&amp;A, 605, A52, doi: 10.1051/0004-6361/201731059\n",
      "- Moultaka, J., Ilovaisky, S. A., Prugniel, P., &amp; Soubiran, C. 2004, PASP, 116, 693, doi: 10.1086/422177\n",
      "- Ness, M., Hogg, D. W., Rix, H. W., Ho, A. Y. Q., &amp; Zasowski, G. 2015, ApJ, 808, 16, doi: 10.1088/0004-637X/808/1/16\n",
      "- OMullane, W., Li, N., Nieto-Santisteban, M., et al. 2005, arXiv e-prints, cs/0502072, doi: 10.48550/arXiv.cs/0502072\n",
      "- Papamakarios, G., Pavlakou, T., &amp; Murray, I. 2017, arXiv e-prints, arXiv:1705.07057, doi: 10.48550/arXiv.1705.07057\n",
      "- Parker, L., Lanusse, F., Golkar, S., et al. 2024, MNRAS, 531, 4990, doi: 10.1093/mnras/stae1450\n",
      "- Radford, A., Wu, J., Child, R., et al. 2019, Language models are unsupervised multitask learners.\n",
      "\n",
      "https://www.semanticscholar.org/paper/ Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/ 9405cc0d6169988371b2755e573cc28650d14dfe\n",
      "\n",
      "- Radford, A., Kim, J. W., Hallacy, C., et al. 2021, arXiv e-prints, arXiv:2103.00020, doi: 10.48550/arXiv.2103.00020\n",
      "- Rix, H.-W., Chandra, V., Andrae, R., et al. 2022, ApJ, 941, 45, doi: 10.3847/1538-4357/ac9e01\n",
      "\n",
      "Rizhko, M., &amp; Bloom, J. S. 2024, arXiv e-prints, arXiv:2411.08842, doi: 10.48550/arXiv.2411.08842\n",
      "\n",
      "- R´ o˙ za´ nski, T., &amp; Ting, Y .-S. 2025, arXiv e-prints, arXiv:2503.18617, doi: 10.48550/arXiv.2503.18617\n",
      "- R´ o˙ za´ nski, T., Ting, Y .-S., &amp; Jabło´ nska, M. 2025, ApJ, 980, 66, doi: 10.3847/1538-4357/ad9b99\n",
      "- Sestito, F., Longeard, N., Martin, N. F., et al. 2019, MNRAS, 484, 2166, doi: 10.1093/mnras/stz043\n",
      "- Shwartz Ziv, R., &amp; LeCun, Y. 2024, Entropy, 26, 252, doi: 10.3390/e26030252\n",
      "- Smith, M. J., Roberts, R. J., Angeloudi, E., &amp; Huertas-Company, M. 2024, arXiv e-prints, arXiv:2405.14930, doi: 10.48550/arXiv.2405.14930\n",
      "- Steinmetz, M., Zwitter, T., Siebert, A., et al. 2006, AJ, 132, 1645, doi: 10.1086/506564\n",
      "- Sui, C., Zhao, X., Jing, T., &amp; Mao, Y. 2023, in Machine Learning for Astrophysics, 30, doi: 10.48550/arXiv.2307.04994\n",
      "- Szalay, A., &amp; Gray, J. 2001, Science, 293, 2037, doi: 10.1126/science.293.5537.2037\n",
      "- Szalay, A., Gray, J., Thakar, A., et al. 2001, arXiv e-prints, cs/0111015, doi: 10.48550/arXiv.cs/0111015\n",
      "- Takada, M., Ellis, R. S., Chiba, M., et al. 2014, PASJ, 66, R1, doi: 10.1093/pasj/pst019\n",
      "- Talts, S., Betancourt, M., Simpson, D., Vehtari, A., &amp; Gelman, A. 2018, arXiv preprint arXiv:1804.06788\n",
      "- Tejero-Cantero, A., Boelts, J., Deistler, M., et al. 2020, Journal of Open Source Software, 5, 2505, doi: 10.21105/joss.02505\n",
      "\n",
      "Ting, Y.-S. 2024, arXiv e-prints, arXiv:2412.05806, doi: 10.48550/arXiv.2412.05806\n",
      "\n",
      "Paszke, A., Gross, S., Massa, F., et al. 2019, in Advances in Neural Information Processing Systems 32 (Curran Associates, Inc.), 8024-8035. http://papers.neurips.cc/paper/\n",
      "\n",
      "- -. 2025, arXiv e-prints, arXiv:2506.12230, doi: 10.48550/arXiv.2506.12230\n",
      "- Ting, Y.-S., Conroy, C., Rix, H.-W., &amp; Cargile, P. 2019, ApJ, 879, 69, doi: 10.3847/1538-4357/ab2331\n",
      "\n",
      "9015-pytorch-an-imperative-style-high-performance-deep-learning-library. pdf\n",
      "\n",
      "- Ting, Y.-S., Rix, H.-W., Conroy, C., Ho, A. Y. Q., &amp; Lin, J. 2017, ApJL, 849, L9, doi: 10.3847/2041-8213/aa921c\n",
      "- Pattnaik, R., Kartaltepe, J. S., &amp; Binu, C. 2025, arXiv e-prints, arXiv:2501.01070, doi: 10.48550/arXiv.2501.01070\n",
      "\n",
      "Poole, B., Ozair, S., van den Oord, A., Alemi, A. A., &amp; Tucker, G. 2019, arXiv e-prints, arXiv:1905.06922, doi: 10.48550/arXiv.1905.06922\n",
      "\n",
      "- Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. 2018\n",
      "\n",
      "Vaswani, A., Shazeer, N., Parmar, N., et al. 2017, in Advances in Neural Information Processing Systems, ed. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, &amp; R. Garnett, Vol. 30 (Curran Associates, Inc.).\n",
      "\n",
      "https://proceedings.neurips.cc/paper files/paper/2017/file/ 3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
      "\n",
      "- Viswanathan, A., Starkenburg, E., Matsuno, T., et al. 2024, A&amp;A, 683, L11, doi: 10.1051/0004-6361/202347944\n",
      "- Vrard, M., Mosser, B., &amp; Samadi, R. 2016, A&amp;A, 588, A87, doi: 10.1051/0004-6361/201527259\n",
      "- Wang, H., Guo, X., Deng, Z.-H., &amp; Lu, Y. 2022, arXiv e-prints, arXiv:2203.07004, doi: 10.48550/arXiv.2203.07004\n",
      "- Wang, R., Luo, A. L., Zhang, S., et al. 2023, ApJS, 266, 40, doi: 10.3847/1538-4365/acce36\n",
      "- Wu, Y., Du, B., Luo, A., Zhao, Y., &amp; Yuan, H. 2014, in IAU Symposium, Vol. 306, Statistical Challenges in 21st Century Cosmology, ed. A. Heavens, J.-L. Starck, &amp; A. Krone-Martins, 340-342, doi: 10.1017/S1743921314010825\n",
      "- Wyse, R. F. G. 2009, in IAU Symposium, Vol. 258, The Ages of Stars, ed. E. E. Mamajek, D. R. Soderblom, &amp; R. F. G. Wyse, 11-22, doi: 10.1017/S1743921309031664\n",
      "- Xiang, M., Ting, Y.-S., Rix, H.-W., et al. 2019, ApJS, 245, 34, doi: 10.3847/1538-4365/ab5364\n",
      "- Xiang, M. S., Liu, X. W., Yuan, H. B., et al. 2015, MNRAS, 448, 822, doi: 10.1093/mnras/stu2692\n",
      "- Yuan, H. B., Liu, X. W., &amp; Xiang, M. S. 2013, MNRAS, 430, 2188, doi: 10.1093/mnras/stt039\n",
      "- Zhang, M., Xiang, M., Ting, Y.-S., et al. 2025, arXiv e-prints, arXiv:2506.02763, doi: 10.48550/arXiv.2506.02763\n",
      "- Zhao, G., Zhao, Y.-H., Chu, Y.-Q., Jing, Y.-P., &amp; Deng, L.-C. 2012, Research in Astronomy and Astrophysics, 12, 723, doi: 10.1088/1674-4527/12/7/002\n",
      "- Zhao, X., &amp; Huang, Y. 2025, SpecCLIP v1.0.0: Aligning and Translating Spectroscopic Measurements for Stars, v1.0.0, Zenodo, doi: 10.5281/zenodo.17824840\n",
      "- Zhao, X., Li, X., Li, H., &amp; Liu, X. 2025, ApJS, 278, 41, doi: 10.3847/1538-4365/adcf9b\n",
      "- Zhong, F., Napolitano, N. R., Heneka, C., et al. 2024, arXiv e-prints, arXiv:2412.21130, doi: 10.48550/arXiv.2412.21130\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cd786-947d-49ae-933c-627ca714c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0d3eb-8af4-432f-a207-728ff62358ee",
   "metadata": {},
   "source": [
    "### UnstructuredLoader\n",
    "- 다양한 비정형 문서들을 읽어 오는 Unstrctured 를 사용해, 다양한 형식의 문서들을 load 해 RAG, 모델 파인튜닝에 적용할 수있게 한다.\n",
    "  - 지원 파일 형식: \"csv\", \"doc\", \"docx\", \"epub\", \"image\", \"md\", \"msg\", \"odt\", \"org\", \"pdf\", \"ppt\", \"pptx\", \"rtf\", \"rst\", \"tsv\", \"xlsx\"\n",
    "- **다양한 형식의 파일로 부터 text를 로딩**해야 할 경우 유용하다. \n",
    "- Local에 library를 설치해서 사용하거나,  Unstructured 가 제공하는 API service를 사용할 수 있다.\n",
    "  - https://docs.unstructured.io\n",
    "- 텍스트 파일, PDF, 이미지, HTML, XML, ms-office(word, ppt), epub 등 다양한 비정형 데이터 파일을 처리할 수 있다.\n",
    "  - 설치, 지원 문서: https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - Langchain 문서: https://python.langchain.com/docs/integrations/document_loaders/unstructured_file\n",
    "\n",
    "> - UnstructuredLoader PDF Load 시 Document 분할 기준\n",
    ">     -  문서의 구조와 콘텐츠를 기반으로 텍스트를 분할해 Document에 넣는다.\n",
    ">     -  분할 기준\n",
    ">        - 헤더(Header): 문서의 제목이나 섹션 제목 등\n",
    ">        - 본문 텍스트(NarrativeText): 일반적인 문단이나 설명문\n",
    ">        - 표(Table): 데이터가 표 형식으로 구성된 부분\n",
    ">        - 리스트(List): 순서가 있거나 없는 목록\n",
    ">        - 이미지(Image): 사진이나 그래픽 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87686d9-03d9-401a-9573-d57a2aacf965",
   "metadata": {},
   "source": [
    "#### 설치할 프로그램\n",
    "- poppler\n",
    "  - pdf 파일을 text로 변환하기 위해 필요한 프로그램\n",
    "  - windows: https://github.com/oschwartz10612/poppler-windows/releases/ 에서 최신 버전 다운로드 후 압축 풀어서 설치.\n",
    "    - 환경변수 Path에 \"설치경로\\Library\\bin\" 을 추가. (설치 후 IDE를 다시 시작한다.)\n",
    "  - macOS: `brew install poppler`\n",
    "  - Linux: `sudo apt-get install poppler-utils`\n",
    "- tesseract-ocr\n",
    "  - OCR 라이브러리로 pdf 이미지를 text로 변환하기 위해 필요한 프로그램 \n",
    "  - windows: https://github.com/UB-Mannheim/tesseract/wiki 에서 다운받아 설치. \n",
    "    - 환경변수 Path에 설치 경로(\"C:\\Program Files\\Tesseract-OCR\") 추가 한다. (설치 후 IDE를 다시 시작한다.)\n",
    "  - macOS: `brew install tesseract`\n",
    "  - linux(unbuntu): `sudo apt install tesseract-ocr`\n",
    "- 설치 할 패키지\n",
    "  - **libmagic 설치**\n",
    "      - windows: `pip install python-magic-bin -qU`\n",
    "      - macOS: `brew install libmagic`\n",
    "      - linux(ubuntu): `sudo apt-get install libmagic-dev`\n",
    "  - `pip install \"unstructured[pdf]\" -qU`\n",
    "      - 문서 형식별로 sub module을 설치한다. (pdf, docx ..)\n",
    "      - 모든 sub module 설치: `pip install unstructured[all-docs]`\n",
    "      - https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - `pip install langchain-unstructured -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4081c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 82ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-magic-bin\u001b[0m\u001b[2m==0.4.14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d98a32d3-b64c-427f-8663-86e00ee88f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m122 packages\u001b[0m \u001b[2min 800ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m grpcio \u001b[2m(4.5MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pi-heif \u001b[2m(1.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m matplotlib \u001b[2m(7.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m onnx \u001b[2m(15.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m rapidfuzz \u001b[2m(1.5MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m fonttools \u001b[2m(2.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m onnxruntime \u001b[2m(12.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pikepdf \u001b[2m(3.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m unstructured \u001b[2m(1.7MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pi-heif\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m rapidfuzz\n",
      "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m langdetect\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pikepdf\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m grpcio\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m unstructured\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m fonttools\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m onnxruntime\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m matplotlib\n",
      "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m langdetect\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m onnx\n",
      "\u001b[2mPrepared \u001b[1m40 packages\u001b[0m \u001b[2min 17.24s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m49 packages\u001b[0m \u001b[2min 2.37s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==25.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meffdet\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflatbuffers\u001b[0m\u001b[2m==25.12.19\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.61.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-api-core\u001b[0m\u001b[2m==2.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-vision\u001b[0m\u001b[2m==3.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.72.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio-status\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhtml5lib\u001b[0m\u001b[2m==1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangdetect\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mml-dtypes\u001b[0m\u001b[2m==0.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmsoffcrypto-tool\u001b[0m\u001b[2m==5.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.9.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1molefile\u001b[0m\u001b[2m==0.47\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnx\u001b[0m\u001b[2m==1.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpdf2image\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpi-heif\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpikepdf\u001b[0m\u001b[2m==10.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mproto-plus\u001b[0m\u001b[2m==1.27.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycocotools\u001b[0m\u001b[2m==2.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypandoc\u001b[0m\u001b[2m==1.16.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyreadline3\u001b[0m\u001b[2m==3.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-iso639\u001b[0m\u001b[2m==2025.11.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-magic\u001b[0m\u001b[2m==0.4.27\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.21\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-oxmsg\u001b[0m\u001b[2m==0.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtimm\u001b[0m\u001b[2m==1.0.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured\u001b[0m\u001b[2m==0.18.21\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured-client\u001b[0m\u001b[2m==0.42.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured-inference\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured-pytesseract\u001b[0m\u001b[2m==0.3.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebencodings\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxlrd\u001b[0m\u001b[2m==2.0.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install unstructured[all-docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372606d9-8859-4d08-a488-dcd5e81fe9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m41 packages\u001b[0m \u001b[2min 143ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m onnxruntime \u001b[2m(10.6MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m onnxruntime\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 374ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 39ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 421ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-unstructured\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.19.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "INFO: pikepdf C++ to Python logger bridge initialized\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    }
   ],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "path = ['data/olympic_wiki.md', 'data/novel/메밀꽃_필_무렵_이효석.pdf']\n",
    "\n",
    "loader = UnstructuredLoader(path)\n",
    "docs = loader.load() # 문단 단위로 문서를 split 해서 Document에 넣어 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466443ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3d2c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/olympic_wiki.md',\n",
       " 'category_depth': 0,\n",
       " 'languages': ['kor'],\n",
       " 'file_directory': 'data',\n",
       " 'filename': 'olympic_wiki.md',\n",
       " 'filetype': 'text/markdown',\n",
       " 'last_modified': '2025-12-11T09:07:54',\n",
       " 'category': 'Title',\n",
       " 'element_id': '869efdd92ae840d110075ad507174066'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b433d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14. ↑ 念, 무엇을 하려고 하는 생각이나 마음 15. ↑ 흐뭇하게 16. ↑ ⼟房, 방에 들어가는 문 앞에 약간 높게 다진 흙바닥 17. ↑ 집안의 살림을 팔려고 나가야 할 18. ↑ 한 장날에서 다음 장날 사이를 세는 단위 19. ↑ 恒⽤, 흔히 늘 20. ↑ 사시장천(四時⻑天), 사계절 쉬지 않고 연달아 21. ↑ 견디기가 힘들고 고단하여 22. ↑ 돈망나니, 돈이라면 사족을 못 쓰고 못된 짓을 하는 사람 23. ↑ 나이로는 24. ↑ 철듦 25. ↑ \"가볍게\"의 방언 26. ↑ 다 자란 암말. 빈마(牝⾺)라고도 한다. 27. ↑ 어둠의 귀신, 어두워서 사물을 제대로 분간하지 못하\n"
     ]
    }
   ],
   "source": [
    "print(docs[-20].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bbbde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4acfcbe1-cc26-4e87-8c41-d6fa7d461701",
   "metadata": {},
   "source": [
    "### Directory 내의 문서파일들 로딩\n",
    "- DirectoryLoader 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b8eb4d8-3c1d-418d-a499-ee181d54b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "  5%|▍         | 1/21 [00:00<00:18,  1.06it/s]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 10%|▉         | 2/21 [00:01<00:15,  1.20it/s]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 14%|█▍        | 3/21 [00:02<00:16,  1.11it/s]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 19%|█▉        | 4/21 [00:03<00:17,  1.01s/it]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 24%|██▍       | 5/21 [00:05<00:17,  1.06s/it]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 29%|██▊       | 6/21 [00:06<00:16,  1.09s/it]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 33%|███▎      | 7/21 [00:07<00:14,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 9/21 [00:38<01:30,  7.50s/it]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 48%|████▊     | 10/21 [00:40<01:01,  5.55s/it]WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 52%|█████▏    | 11/21 [00:41<00:42,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 12/21 [00:44<00:33,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 13/21 [00:47<00:30,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 14/21 [00:57<00:39,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P6' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P8' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P9' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P10' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P14' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P14' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P15' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P15' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P21' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P21' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P22' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P22' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P23' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P23' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P5' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "WARNING: Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "WARNING: Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      " 71%|███████▏  | 15/21 [00:58<00:25,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 16/21 [00:59<00:15,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 17/21 [01:00<00:10,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 18/21 [01:02<00:07,  2.46s/it]WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      " 95%|█████████▌| 20/21 [01:02<00:01,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|██████████| 21/21 [01:03<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# Unstructured 기반 - 관련 lib가 설치되 있어야 한다.\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"./data\", # 문서파일들을 찾을 root directory\n",
    "    glob=[\"*.docx\", \"*.pdf\", \"*.txt\"], # 찾을 문서 파일 명의 패턴을 glob 패턴으로 지정. (생략: 모든 파일)\n",
    "    recursive=True, # False: path 경로에서만 찾는다. True: path의 하위 경로도 모두 찾는다.\n",
    "    show_progress=True, #진행 프로그래스바가 나온다. \n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04a1e8eb-2569-43f3-a458-dd020a322c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d324eab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\novel\\\\금_따는_콩밭_김유정.pdf'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6154fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "금 따는 콩밭\n",
      "\n",
      "Exported from Wikisource on 2024년 11월 24일\n",
      "\n",
      "2\n",
      "\n",
      "위키백과에 이 글 과 관련된 자료가 있습니다. 금 따는 콩밭\n",
      "\n",
      "🙝🙟 땅속 저 밑은 늘 음침하 다.\n",
      "\n",
      "위키백과\n",
      "\n",
      "고달픈 간드렛불, 맥없이 푸르끼하다.\n",
      "\n",
      "밤과 달라서 낮엔 되우 흐릿하였다.\n",
      "\n",
      "겉으로 황토 장벽으로 앞뒤좌우가 콕 막힌 좁직한 구뎅이. 흡사히 무덤 속같이 귀중중하다. 싸늘한 침묵, 쿠더브레한 흙내와 징그러운 냉기만이 그 속에 자욱하다.\n",
      "\n",
      "곡괭이는 뻔질 흙을 이르집는다. 암팡스러이 내려쪼며,\n",
      "\n",
      "퍽 퍽 퍼억.\n",
      "\n",
      "이렇게 메떨어진 소리뿐. 그러나 간간 우수수 하고 벽이 헐 린다.\n",
      "\n",
      "영식이는 일손을 놓고 소맷자락을 끌어당기어 얼굴의 땀을 훑는다. 이놈의 줄이 언제나 잡힐는지 기가 찼다. 흙 한줌을 집어 코밑에 바짝 들여대고 손가락으로 샅샅이 뒤져본다. 완 연히 버력은 좀 변한 듯싶다. 그러나 불통버력이 아주 다 풀 린 것도 아니었다. 밀똥버력이라야 금이 온다는데 왜 이리 안 나오는지.\n",
      "\n",
      "곡괭이를 다시 집어든다. 땅에 무릎을 꿇고 궁뎅이를 번쩍 든 채 식식거린다. 곡괭이는 무작정 내려찍는다. 바닥에서\n",
      "\n",
      "3\n",
      "\n",
      "물이 스미어 무르팍이 흔건히 젖었다. 굿엎은 천판에서 흙방 울은 내리며 목덜미로 굴러든다. 어떤 때에는 웃벽의 한쪽이 떨어지며 등을 탕 때리고 부서진다.\n",
      "\n",
      "그러나 그는 눈도 하나 깜짝하지 않는다. 금을 캔다고 콩밭 하나를 다 잡쳤다. 약이 올라서 죽을둥 살둥 눈이 뒤집힌 이 판이다. 손바닥에 침을 탁 뱉고 곡괭이 자루를 한번 꼰아잡 더니 쉴 줄 모른다.\n",
      "\n",
      "등뒤에서는 흙 긁는 소리가 드윽드윽 난다. 아직도 버력을 다 못 친 모양. 이 자식이 일을 하나 시졸 하나. 남은 속이 바 직바직 타는데 웬 뱃심이 이리도 좋아.\n",
      "\n",
      "영식이는 살기 띤 시선으로 고개를 돌렸다. 암 말 없이 수재 를 노려본다. 그제야 꾸물꾸물 바지게에 흙을 담고 등에 메 고 사다리를 올라간다.\n",
      "\n",
      "굿이 풀리는지 벽이 우찔하였다. 흙이 부서져 내린다. 전날 이라면 이곳에서 아내 한번 못하고 생죽음이나 안 할까 털끝 까지 쭈볏할 게다. 그러나 이젠 그렇게 되고도 싶다. 수재란 놈하고 흙더미에 묻히어 한껍에 죽는다면 그게 오히려 날 게 다.\n",
      "\n",
      "이렇게까지 몹시 몹시 미웠다.\n",
      "\n",
      "이놈 풍치는 바람에 애꿎은 콩밭 하나만 결딴을 냈다. 뿐만 아니라 모두가 낭패다. 세 벌 논도 못 맸다. 논둑의 풀은 성 큼 자란 채 어지러이 널려 있다. 이 기미를 알고 지주는 대로 하였다. 내년부터는 농사질 생각을 말라고 발을 굴렀다. 땅 은 암만을 파도 지수가 없다.\n",
      "\n",
      "4\n",
      "\n",
      "이만해도 다섯 길은 훨썩 넘었으리라. 좀더 지펴야 옳을지 혹은 북으로 밀어야 옳을지, 우두머니 망설거린다. 금점 일 에는 푸뜸이다. 입때껏 수재의 지휘를 받아 일을 하여왔고, 앞으로도 역 그러해야 금을 딸 것이다. 그러나 그런 칙칙한 짓은 안 한다.\n",
      "\n",
      "“이리 와 이것 좀 파게.”\n",
      "\n",
      "그는 어쓴 위풍을 보이며 이렇게 분부하였다. 그리고 저는 일어나 손을 털며 뒤로 물러선다. 수재는 군말 없이 고분하 였다. 시키는 대로 땅에 무릎을 꿇고 벽채로 군버력을 긁어 낸 다음 다시 파기 시작한다.\n",
      "\n",
      "영식이는 치다 나머지 버력을 짊어진다. 커단 걸대를 뒤툭거 리며 사다리로 기어오른다. 굿문을 나와 버력더미에 흙을 마 악 내칠려 할 제,\n",
      "\n",
      "“왜 또 파. 이것들이 미쳤나 그래!”\n",
      "\n",
      "산에서 내려오는 마름과 맞닥뜨렸다. 정신이 떠름하여 그대 로 벙벙히 섰다. 오늘은 또 무슨 포악을 들을려는가.\n",
      "\n",
      "“말라니까 왜 또 파는 게야.” 하고 영식이의 바지게 뒤를 지 팡이로 콱 찌르더니,\n",
      "\n",
      "“갈아먹으라는 밭이지 흙 쓰고 들어가라는 거야, 이 미친것 들아. 콩밭에서 웬 금이 나온다구 이 지랄들이야 그래.” 하고 목에 핏대를 올린다. 밭을 버리면 간수 잘못한 자기 탓이다. 날마다 와서 그 북새를 피고 금하여도 담날 보면 또 여전히 파는 것이다.\n",
      "\n",
      "5\n",
      "\n",
      "“오늘로 이 구뎅이를 도로 묻어놔야지 낼로 당장 징역 갈 줄 알게.”\n",
      "\n",
      "너무 감정에 격하여 말도 잘 안 나오고 떠듬떠듬거린다. 주 먹은 곧 날아들 듯이 허구리게서 불불 떤다.\n",
      "\n",
      "“오늘만 좀 해보고 고만두겠어유.”\n",
      "\n",
      "영식이는 낯이 붉어지며 가까스로 한마디하였다. 그리고 무 턱대고 빌었다. 마름은 들은 척도 안하고 가버린다. 그 뒷모 양을 영식이는 멀거니 배웅하였다. 그러나 콩밭 낯짝을 들여 다보니 무던히 애통 터진다. 멀쩡한 밭에가 구멍이 사면 풍 풍 뚫렸다.\n",
      "\n",
      "예제없이 버력은 무데기 무데기 쌓였다. 마치 사태 만난 공 동 묘지와도 같이 귀살쩍고 되우 을씨년스럽다. 그다지 잘되 었던 콩 포기는 거반 버력더미에 다아 깔려버리고 군데군데 어쩌다 남은 놈들만이 고개를 나풀거린다. 그 꼴을 보는 것 도 자식 죽는 걸 보는 게 낫지 차마 못할 경상이었다.\n",
      "\n",
      "🙝🙟 농토는 모조리 떨어질 것이다. 그러나 대관절 올 밭도지 벼 두 섬 반은 뭘로 해내야 좋을지. 게다 밭을 망쳤으니 자칫하 면 징역을 갈는지도 모른다. 영식이가 구뎅이 안으로 들어왔 을 때 동무는 땅에 주저앉아 쉬고 있었다. 태연무심히 담배 만 뻑뻑 피는 것이다.\n",
      "\n",
      "“언제나 줄을 잡는 거야.”\n",
      "\n",
      "6\n",
      "\n",
      "“인제 차차 나오겠지.”\n",
      "\n",
      "“인제 나온다.” 하고 코웃음치고 엇먹더니 조금 지나매,\n",
      "\n",
      "“이 새끼.”\n",
      "\n",
      "흙덩이를 집어들고 골통을 내려친다.\n",
      "\n",
      "수재는 어쿠 하고 그대로 폭 엎드린다. 그러다 벌떡 일어선 다. 눈에 띄는 대로 곡괭이를 잡자 대뜸 달겨들었다. 그러나 강약이 부동. 왁살스러운 팔뚝에 튕겨져 벽에 가서 쿵 하고 떨어졌다. 그 순간에 제가 빼앗긴 곡괭이가 정백이를 겨누고 날아드는 걸 보았다. 고개를 홱 돌린다. 곡괭이는 흙벽을 퍽 찍고 다시 나간다.\n",
      "\n",
      "수재 이름만 들어도 영식이는 이가 갈렸다. 분명히 홀딱 속 은 것이다.\n",
      "\n",
      "영식이는 본디 금전에 이력이 없었다. 그리고 흥미도 없었 다. 다만 밭고랑에 웅크리고 앉아서 땀을 흘려가며 꾸벅꾸벅 일만 하였다. 올엔 콩도 뜻밖에 잘 열리고 맘이 좀 놓였다. 하루는 홀로 김을 매고 있노라니까,\n",
      "\n",
      "“여보게, 덥지 않은가. 좀 쉬었다 하게.”\n",
      "\n",
      "고개를 들어보니 수재다. 농사는 안 짓고 금전으로만 돌아다 니더니 무슨 바람에 또 왔는지 싱글벙글한다. 좋은 수나 걸 렸나 하고,\n",
      "\n",
      "“돈 좀 많이 벌었나. 나 좀 주게.”\n",
      "\n",
      "7\n",
      "\n",
      "“벌구 말구, 맘껏 먹고 맘껏 쓰고 했네.”\n",
      "\n",
      "술에 거나한 얼굴로 신껏 주적거린다. 그리고 밭머리에 쭈그 리고 앉아 한참 객설을 부리더니,\n",
      "\n",
      "“자네, 돈벌이 좀 안할려나. 이 밭에 금이 묻혔네 금이.”\n",
      "\n",
      "“뭐?” 하니까,\n",
      "\n",
      "바로 이 산 너머 큰골에 광산이 있다. 광부를 삼백여 명이나 부리는 노다지판인데 매일 소출되는 금이 칠십 냥을 넘는다. 돈으로 치면 칠천 원. 그 줄맥이 큰 산허리를 뚫고 이 콩밭으 로 뻗어나왔다는 것이다. 둘이서 파면 불과 열흘 안에 줄을 잡을 게고, 적어도 하루 서너 돈씩은 따리라.\n",
      "\n",
      "우선 삼십만 원만 해도 얼마냐. 소를 산대도 만 필이 아니냐 고. 그러나 영식이는 귀담아듣지 않았다. 금점이란 칼 물고 뜀뛰기다, 잘되면이어니와 못되면 신세만 조핀다, 이렇게 전 일부터 들은 소리가 있어서였다. 그 담날도 와서 꾀송거리다 갔다.\n",
      "\n",
      "셋째 번에는 집으로 찾아왔는데 막걸리 한 병을 손에 떡 들 고 영을 피운다. 몸이 달아서 또 온 것이었다. 봉당에 걸터앉 아서 저녁상을 물끄러미 바라보더니 조당수는 몸을 훑는다 는 둥 일꾼은 든든히 먹어야 한다는 둥 남들은 논을 사느니 밭을 사느니 떠드는데 요렇게 지내다 그만둘 테냐는 둥 일쩌 웁게 지껄인다.\n",
      "\n",
      "“아주머니, 이것 좀 먹게 해주시게유.”\n",
      "\n",
      "8\n",
      "\n",
      "그리고 비로소 영식이 아내에게 술병을 내놓는다. 그들은 밥 상을 끼고 앉아서 즐거웁게 술을 마셨다. 몇 잔이 들어가고 보니 영식이의 생각도 저으기 돌아섰다. 딴은 일년 고생하고 끽 콩 몇 섬 얻어먹느니보다는 금을 캐는 것이 슬기로운 짓 이다.\n",
      "\n",
      "하루에 잘만 캔다면 한 해 줄곧 공들인 그 수확보다 훨썩 이 익이다. 올 봄 보낼 제 비료값, 품삯, 빚해 빚진 칠 원 까닭에 나날이 졸리는 이판이다. 이렇게 지지하게 살고 말 바에는 차라리 가로지나 세로지나 사내자식이 한번 해볼 것이다.\n",
      "\n",
      "“내일부터 우리 파보세. 돈만 있으면이야 그까진 콩은…”\n",
      "\n",
      "수재가 안달스리 재우쳐 보채일 제 선뜻 응낙하였다.\n",
      "\n",
      "“그래 보세. 빌어먹을 거 안됨 고만이지.”\n",
      "\n",
      "그러나 꽁무니에서 죽을 마시고 있던 아내가 허구리를 쿡쿡 찔렀게 망정이지 그렇지 않았더면 좀 주저할 뻔도 하였다.\n",
      "\n",
      "아내는 아내대로의 심이 빨랐다. 시체는 금점이 판을 잡았 다. 섣부르게 농사만 짓고 있다간 결국 비렁뱅이밖에는 더 못된다. 얼마 안 있으면 산이고 논이고 밭이고 할 것 없이 다 금쟁이 손에 구멍이 뚫리고 뒤집히고 뒤죽박죽이 될 것이다. 그때는 뭘 파먹고 사나.\n",
      "\n",
      "자, 보아라. 머슴들은 짜위나 한 듯이 일하다 말고 후딱하면 금점으로들 내빼지 않는가. 일꾼이 없어서 올엔 농사를 질 수 없느니 마느니 하고 동리에서는 떠들썩하다. 그리고 번동 포농이 쫓아 호미를 내어던지고 강변으로 개울로 사금을 캐\n",
      "\n",
      "9\n",
      "\n",
      "러 달아난다. 그러나 며칠 뒤에는 다비신에다 옥당목을 떨치 고 히짜를 뽑는 것이 아닌가.\n",
      "\n",
      "🙝🙟 아내는 콩밭에서 금이 날 줄은 아주 꿈밖이었다. 놀라고도 또 기뻤다. 올해는 노냥 침만 삼키던 그놈 코다리(명태)를 짜 장 먹어보겠구나, 만 하여도 속이 메질 듯이 짜릿하였다. 뒷 집 양근댁은 금점 덕택에 남편이 사다준 흰 고무신을 신고 나릿나릿 걷는 것이 무척 부러웠다. 저도 얼른 금이나 펑펑 쏟아지면 흰 고무신도 신고 얼굴에 분도 바르고 하리라.\n",
      "\n",
      "“그렇게 해보지 뭐. 저 양반 하잔 대로만 하면 어련히 잘될라 구.”\n",
      "\n",
      "얼뚤하여 앉았는 남편을 이렇게 추겼던 것이다.\n",
      "\n",
      "동이 트기 무섭게 콩밭으로 모였다. 수재는 진언이나 하는 듯 이리대고 중얼거리고 저리대고 중얼거리고 하였다. 그리 고 덤벙거리며 이리 왔다가 저리 왔다가 하였다. 제 딴은 땅 속에 누운 줄맥을 어림하여 보는 맥이었다.\n",
      "\n",
      "한참을 밭을 헤매다가 산 쪽으로 붙은 한구석에 딱 서며 손 가락을 펴들고 설명한다. 큰 줄이란 본시 산운 산을 끼고 도 는 법이다. 이 줄이 노다지임에는 필시 이켠으로 버듬히 누 웠으리라. 그러니 여기서부터 파 들어가자는 것이었다.\n",
      "\n",
      "영식이는 그 말이 무슨 소린지 새기지는 못했다. 마는 금점 에는 난다는 수재이니 그 말대로 하기만 하면 영낙없이 금퇴\n",
      "\n",
      "10\n",
      "\n",
      "야 나겠지 하고 그것만 꼭 믿었다. 군말 없이 지시해 받은 곳 에다 삽을 폭 꽂고 파헤치기 시작하였다.\n",
      "\n",
      "금도 금이면 애써 키워온 콩도 콩이었다. 거진 다 자란 허울 멀쑥한 놈들이 삽 끝에 으스러지고 흙에 묻히고 하는 것이 다. 그걸 보는 것은 썩 속이 아팠다. 애틋한 생각이 물밀 때 가끔 삽을 놓고 허리를 구부려서 콩잎의 흙을 털어주기도 하 였다.\n",
      "\n",
      "“아, 이 사람아, 맥적게 그건 봐 뭘해, 금을 캐자니깐.”\n",
      "\n",
      "“아니야, 허리가 좀 아파서!”\n",
      "\n",
      "핀잔을 얻어먹고는 좀 열쩍었다. 하기는 금만 잘 터져나오면 이까진 콩밭쯤이야. 이 밭을 풀어 논도 만들 수 있을 것이다. 눈을 감아버리고 삽의 흙을 아무렇게나 콩잎 위로 홱홱 내어 던진다.\n",
      "\n",
      "“구구루 땅이나 파먹지 이게 무슨 지랄들이야!”\n",
      "\n",
      "동리 노인은 뻔질 찾아와서 귀 거친 소리를 하고 하였다.\n",
      "\n",
      "밭에 구멍을 셋이나 뚫었다. 그리고 대구 뚫는 길이었다. 금 인가 난장을 맞을 건가 그것 때문에 농꾼은 버렸다. 이게 필 연코 세상이 망하려는 징조이리라. 그 소중한 밭에다 구멍을 뚫고 이 지랄이니 그놈이 온전할 겐가.\n",
      "\n",
      "노인은 제물 화에 지팡이를 들어 삿대질을 아니할 수 없었 다.\n",
      "\n",
      "11\n",
      "\n",
      "“벼락맞느니 벼락맞어.”\n",
      "\n",
      "“염려 말아유. 누가 알래지유.”\n",
      "\n",
      "영식이는 그럴 적마다 데퉁스리 쏘았다. 골김에 흙을 되는대 로 내꼰지고는 침을 탁 뱉고 구뎅이로 들어간다. 그러나 마 음 한구석에는 언제나 끄은하였다. 줄을 찾는다고 콩밭을 통 히 뒤집어놓았다. 그리고 줄이 언제나 나올지 아직 까맣다. 논도 못 매고 물도 못 보고 벼가 어이 되었는지 그것조차 모 른다. 밤에는 잠이 안 와 멀뚱하니 애를 태웠다.\n",
      "\n",
      "수재는 낙담하는 기색도 없이 늘 하냥이었다. 땅에 웅숭그리 고 시적시적 노량으로 땅만 판다.\n",
      "\n",
      "“줄이 꼭 나오겠나?” 하고 목이 말라서 물으면,\n",
      "\n",
      "“이번에 안 나오거든 내 목을 비게.” 서슴지 않고 장담을 하 고는 꿋꿋하였다.\n",
      "\n",
      "이걸 보면 영식이도 마음이 좀 뇌는 듯싶었다. 전들 금이 없 다면 무슨 멋으로 이 고생을 하랴. 반드시 금은 나올 것이다. 그제서는 이왕 손해는 하릴없거니와 고만두리라는 절망이 스스로 사라지고 다시금 주먹이 쥐어지는 것이었다.\n",
      "\n",
      "캄캄하게 밤은 어두웠다. 어디선가 뭇개가 요란히 짖어대인 다.\n",
      "\n",
      "남편은 진흙투성이를 하고 산에서 내려왔다. 풀이 죽어서 몸 을 잘 가누지도 못하고 아랫묵에 축 늘어진다.\n",
      "\n",
      "12\n",
      "\n",
      "이 꼴을 보니 아내는 맥이 다시 풀린다. 오늘도 또 글렀구나. 금이 터지며는 집을 한 채 사간다고 자랑을 하고 왔더니 이 내 헛일이었다. 인제 좌지가 나서 낯을 들고 나아갈 염의조 차 없어졌다.\n",
      "\n",
      "남편에게 저녁을 갖다주고 딱하게 바라본다.\n",
      "\n",
      "“인젠 꿔온 양식도 다 먹었는데…”\n",
      "\n",
      "“새벽에 산제를 좀 지낼 텐데 한번만 더 꿔와.”\n",
      "\n",
      "남의 말에는 대답 없고 유하게 흘개늦은 소리뿐 그리고 드러 누운 채 눈을 지그시 감아버린다.\n",
      "\n",
      "“죽거리두 없는데 산제는 무슨…”\n",
      "\n",
      "“듣기 싫어, 요망맞은 년 같으니.”\n",
      "\n",
      "이 호통에 아내는 고만 멈씰하였다. 요즘 와서는 무턱대고 공연스리 골만 내는 남편이 역 딱하였다. 환장을 하는지 밤 잠도 아니 자고 소리만 뻑뻑 지르며 덤벼들려고 든다. 심지 어 어린것이 좀 울어도 이 자식 갖다 내꾼지라고 북새를 피 는 것이다.\n",
      "\n",
      "저녁을 아니 먹으므로 그냥 치워버렸다. 남편의 영을 거역키 어려워 양근댁한테로 또다시 안 갈 수 없다. 그간 양식은 줄 곧 꾸어다먹고 갚지도 못하였는데 또 무슨 면목으로 입을 벌 릴지 난처한 노릇이었다.\n",
      "\n",
      "🙝🙟\n",
      "\n",
      "13\n",
      "\n",
      "그는 생각다 끝에 있는 염치를 보째 쏟아던지고 다시 한번 찾아가는 것이다. 마는 딱 맞닥뜨리어 입을 열고,\n",
      "\n",
      "“낼 산제를 지낸다는데 쌀이 있어야지유.” 하자니 역 낯이 화끈하고 모닥불이 날아든다.\n",
      "\n",
      "그러나 그들은 어지간히 착한 사람이었다.\n",
      "\n",
      "“암 그렇지요. 산신이 벗나면 죽도 글릅니다.” 하고 말을 받 으며 그 남편은 빙그레 웃는다. 워낙 이 금점에 장구 닳아난 몸인 만치 이런 일에는 적잖이 속이 틔었다. 손수 쌀 닷 되를 떠다주며,\n",
      "\n",
      "“산제란 안 지냄 몰라두 이왕 지낼려면 아주 정성껏 해야 됩 니다. 산신이란 노하길 잘하니까유.”\n",
      "\n",
      "하고 그 비방까지 깨쳐 보낸다.\n",
      "\n",
      "쌀을 받아들고 나오며 영식이 처는 고마움보다 먼저 미안에 질리어 얼굴이 다시 빨갰다. 그리고 그들 부부 살아가는 살 림이 참으로 참으로 몹시 부러웠다. 양근댁 남편은 날마다 금점으로 감돌며 버력더미를 뒤지고 토록을 줏어온다.\n",
      "\n",
      "그걸 온종일 장판돌에다 갈면 수가 좋으면 이삼 원, 옥아도 칠팔십 전 꼴은 매일 심이 되는 것이었다. 그러면 쌀을 산다, 피륙을 끊는다, 떡을 한다, 장리를 놓는다 - 그런데 우리는 왜 늘 요 꼴인지 생각만 하여도 가슴이 메이는 듯 맥맥한 한 숨이 연발을 하는 것이었다.\n",
      "\n",
      "14\n",
      "\n",
      "아내는 집에 돌아와 떡쌀을 담그었다. 낼은 뭘로 죽을 쑤어 먹을는지. 웃목에 웅크리고 앉아서 맞은쪽에 자빠져 있는 남 편을 곁눈으로 살짝 할퀴어본다. 남들은 돌아다니며 잘두 금 을 줏어오련만 저 망나니 제 밭 하나를 다 버려도 금 한 톨 못 줏어오나. 에에, 변변치도 못한 사나이. 저도 모르게 얕은 한숨이 거푸 두 번을 터진다.\n",
      "\n",
      "밤이 이슥하여 그들 양주는 떡을 하러 나왔다. 남편은 절구 에 쿵쿵 빻았다. 그러나 체가 없다. 동네로 돌아다니며 빌려 오느라고 아내는 다리에 불풍이 났다.\n",
      "\n",
      "“왜 이리 앉었수, 불 좀 지피지.”\n",
      "\n",
      "떡을 찧다가 얼이 빠져서 멍하니 앉았는 남편이 밉쌀스럽다. 남은 이래저래 애를 죄는데 저건 무슨 생각을 하고 저리 있 는 건지. 낫으로 삭정이를 탁탁 조겨서 던져주며 아내는 은 근히 훅닥이었다. 닭이 두 홰를 치고 나서야 떡은 되었다. 아 내는 시루를 이고 남편은 겨드랑이에 자리때기를 꼈다. 그리 고 캄캄한 산길을 올라간다.\n",
      "\n",
      "비탈길을 얼마 올라가서야 콩밭은 놓였다. 전면이 우뚝한 검 은 산에 둘리어 막힌 곳이었다. 가생이로 느티 대추나무들은 머리를 풀었다. 밭머리 조금 못미처 남편은 걸음을 멈추자 뒤의 아내를 돌아본다.\n",
      "\n",
      "“인내, 그리구 여기 가만히 섰어.”\n",
      "\n",
      "시루를 받아 한 팔로 껴안고 그는 혼자서 콩밭으로 올라섰 다. 앞에 쌓인 것이 모두 흙더미, 그 흙더미를 마악 돌아설려\n",
      "\n",
      "15\n",
      "\n",
      "할 제 아마 돌을 찼나보다. 몸이 쓰러지려고 우찔끈하니 아 내가 기겁을 하여 뛰어오르며 그를 부축하였다.\n",
      "\n",
      "“부정 타라구 왜 올라와, 요망맞은 년.”\n",
      "\n",
      "남편은 몸을 고루잡자 소리를 뻑 지르며 아내 얼뺨을 붙인 다. 가뜩이나 죽으라 죽으라 하는데 불길하게도 계집년이. 그는 마뜩지 않게 두덜거리며 밭으로 들어간다. 밭 한가운데 다 자리를 펴고 그 위에 시루를 놓았다. 그리고 시루 앞에다 공손하고 정성스레 재배를 커다랗게 한다.\n",
      "\n",
      "“우리를 살려줍시사. 산신께서 거들어주지 않으면 저희는 죽을 밖에 꼼짝 수 없읍니다유.”\n",
      "\n",
      "그는 손을 모으고 이렇게 축원하였다.\n",
      "\n",
      "아내는 이 꼴을 바라보며 독이 뾰록 같이 올랐다. 금점을 합 네 하고 금 한 톨 못 캐는 것이 버릇만 점점 글러간다. 그전 에는 없더니 요새로 건듯하면 탕탕 때리는 못된 버릇이 생긴 것이다. 금을 캐랬지 뺨을 치랬나. 제발 덕분에 고놈의 금 좀 나오지 말았으면. 그는 뺨 맞은 앙심으로 맘껏 방자하였다.\n",
      "\n",
      "하긴 아내의 말 고대로 되었다. 열흘이 썩 넘어도 산신은 깜 깜 무소식이었다. 남편은 밤낮으로 눈을 까뒤집고 구덩이에 묻혀 있었다. 어쩌다 집엘 내려오는 때이면 얼굴이 헐떡하고 어깨가 축 늘어지고 거반 병객이었다. 그리고서 잠자코 커단 몸집을 방고래에다 큉, 하고 내던지고 하는 것이다.\n",
      "\n",
      "“제이미 붙을, 죽어나 버렸으면.”\n",
      "\n",
      "16\n",
      "\n",
      "혹은 이렇게 탄식하기도 하였다.\n",
      "\n",
      "아내는 바가지에 점심을 이고서 집을 나섰다. 젖먹이는 등을 두드리며 좋다고 끽끽거린다.\n",
      "\n",
      "이젠 흰 고무신이고 코다리고 생각조차 물렸다. 그리고 금 하는 소리만 들어도 입에 신물이 날 만큼 되었다. 그건 고사 하고 꿔다먹은 양식에 졸리지나 말았으면 그만도 좋으리마 는.\n",
      "\n",
      "가을은 논으로 밭으로 누으렇게 내리었다. 농꾼들은 기꺼운 낯을 하고 서로 만나면 흥겨운 농담, 그러나 남편은 앰한 밭 만 망치고 논조차 건살 못하였으니 이 가을에는 뭘 거둬들이 고 뭘 즐겨할는지. 그는 동리 사람의 이목이 부끄러워 산길 로 돌았다.\n",
      "\n",
      "🙝🙟 솔숲을 나서서 멀리 밖에를 바라보니 둘이 다 나와 있다. 오 늘도 또 싸운 모양. 하나는 이쪽 흙더미에 앉았고 하나는 저 쪽에 앉았고. 서로들 외면하여 담배만 뻑뻑 피운다.\n",
      "\n",
      "“점심들 잡숫게유.”\n",
      "\n",
      "남편 앞에 바가지를 내려놓으며 가만히 맥을 보았다.\n",
      "\n",
      "남편은 적삼이 찢어지고 얼굴에 생채기를 내었다. 그리고 두 팔을 걷고 먼 산을 향하여 묵묵히 앉았다.\n",
      "\n",
      "17\n",
      "\n",
      "수재는 흙에 박혔다 나왔는지 얼굴은커녕 귓속드리 흙투성 이다. 코밑에는 피딱지가 말라붙었고 아직도 조금씩 피가 흘 러내린다. 영식이 처를 보더니 열쩍은 모양. 고개를 돌리어 모로 떨어치며 입맛만 쩍쩍 다신다.\n",
      "\n",
      "금을 캐라니까 밤낮 피만 내다 말라는가. 빚에 졸리어 남은 속을 볶는데 무슨 호강에 이지랄들인구. 아내는 못마땅하여 눈가에 살을 모았다.\n",
      "\n",
      "“산제 지낸다구 꿔온 것은 은제나 갚는다지유?”\n",
      "\n",
      "뚱하고 있는 남편을 향하여 말끝을 꼬부린다. 그러나 남편은 눈썹 하나 까딱하지 않는다. 이번에는 어조를 좀 돋으며,\n",
      "\n",
      "“갚지도 못할 걸 왜 꿔오라 했지유!” 하고 얼추 호령이었다.\n",
      "\n",
      "이 말은 남편의 채 가라앉지도 못한 분통을 다시 건드린다. 그는 벌떡 일어서며 황밤주먹을 쥐어 창낭할 만치 아내의 골 통을 후렸다.\n",
      "\n",
      "“계집년이 방정맞게.”\n",
      "\n",
      "다른 것은 모르나 주먹에는 아찔이었다. 멋없이 덤비다간 골 통이 부서진다. 암상을 참고 바르르 하다가 이윽고 아내는 등에 업은 언내를 끌러들었다. 남편에게로 그대로 밀어던지 니 아이는 까르륵 하고 숨 모는 소리를 친다. 그리고 아내는 돌아서서 혼잣말로,\n",
      "\n",
      "“콩밭에서 금을 딴다는 숭맥도 있담.” 하고 빗대놓고 비양거 린다.\n",
      "\n",
      "18\n",
      "\n",
      "“이년아, 뭐!”\n",
      "\n",
      "남편은 대뜸 달겨들며 그 볼치에다 다시 올찬 황밤을 주었 다. 저그나면 계집이니 위로도 하여주련만 요건 분만 폭폭 질러놓려나. 예이, 빌어먹을 거, 이판새판이다.\n",
      "\n",
      "“너허구 안 산다. 오늘루 가거라.”\n",
      "\n",
      "아내를 와락 떠다밀어 논뚝에 제켜놓고 그 허구리를 발길로 퍽 질렀다.\n",
      "\n",
      "아내는 입을 헉 하고 벌린다.\n",
      "\n",
      "“네가 허라구 옆구리를 쿡쿡 찌를 제는 은제냐, 요 집안 망할 년.”\n",
      "\n",
      "그리고 다시 퍽 질렀다. 연하여 또 퍽.\n",
      "\n",
      "이 꼴들을 보니 수재는 조바심이 일었다. 저러다가 그 분풀 이가 다시 제게로 슬그머니 옮아올 것을 지르채었다. 인제 걸리면 죽는다. 그는 비슬비슬하다 어느 틈엔가 구뎅이 속으 로 시나브로 없어져버린다. 볕은 다스로운 가을 향취를 풍긴 다. 주인을 잃고 콩은 무거운 열매를 둥글둥글 흙에 굴린다. 맞은쪽 산밑에서 벼들을 베며 기뻐하는 농꾼의 노래.\n",
      "\n",
      "“터졌네, 터져.”\n",
      "\n",
      "수재는 눈이 휘둥그렇게 굿문을 뛰어나오며 소리를 친다. 손 에는 흙 한줌이 잔뜩 쥐었다.\n",
      "\n",
      "19\n",
      "\n",
      "“뭐?” 하다가,\n",
      "\n",
      "“금줄 잡았어, 금줄.”\n",
      "\n",
      "“응!” 하고 외마디를 뒤남기자 영식이는 수재 앞으로 살같이 달려들었다. 허겁지겁 그 흙을 받아들고 샅샅이 헤쳐보니 딴 은 재래에 보지 못하던 불그죽죽한 황토이었다. 그는 눈에 눈물이 핑 돌며,\n",
      "\n",
      "“이게 원줄인가?”\n",
      "\n",
      "“그럼 이것이 곱색줄이라네. 한 포에 댓 돈씩은 넉넉잡히 대.”\n",
      "\n",
      "영식이는 기쁨보다 먼지 기가 탁 막혔다. 웃어야 옳을지 울 어야 옳을지. 다만 입을 반쯤 벌린 채 수재의 얼굴만 멍하니 바라본다.\n",
      "\n",
      "“이리 와봐. 이게 금이래.”\n",
      "\n",
      "이윽고 남편은 아내를 부른다. 그리고 내 뭐랬어, 그러게 해 보라고 그랬지, 하고 설면설면 덤벼오는 아내가 한결 어여뻤 다. 그는 엄지가락으로 아내의 눈물을 지워주고 그리고 나서 껑충거리며 구뎅이로 들어간다.\n",
      "\n",
      "“그 흙 속에 금이 있지요?”\n",
      "\n",
      "영식이처가 너무 기뻐서 코다리에 고래등 같은 집까지 연상 할 제 수재는 시원스러이,\n",
      "\n",
      "20\n",
      "\n",
      "“네, 한 포대에 오십 원씩 나와유.” 하고 대답하고 오늘밤에 는 꼭 정녕코 꼭 달아나리라 생각하였다.\n",
      "\n",
      "거짓말이란 오래 못 간다. 봉이 나서 뼉다귀도 못 추리기 전 에 훨훨 벗어나는 게 상책이겠다.\n",
      "\n",
      "라이선스\n",
      "\n",
      "21\n",
      "\n",
      "이 저작물은 저자가 사망한 지 70년이 넘었으므 로, 저자가 사망한 후 70년(또는 그 이하)이 지나 면 저작권이 소멸하는 국가에서 퍼블릭 도메인입 니다.\n",
      "\n",
      "1923년에서 1977년 사이에 출판되었다면 미국에서 퍼블 릭 도메인이 아닐 수 있습니다. 미국에서 퍼블릭 도메인인 저작물에는 {{PD-1996}}를 사용하십시오.\n",
      "\n",
      "주의\n",
      "\n",
      "22\n",
      "\n",
      "About this digital edition\n",
      "\n",
      "This e-book comes from the online library Wikisource[1]. This multilingual digital library, built by volunteers, is committed to developing a free accessible collection of publications of every kind: novels, poems, magazines, letters...\n",
      "\n",
      "We distribute our books for free, starting from works not copyrighted or published under a free license. You are free to use our e-books for any purpose (including commercial exploitation), under the terms of the Creative Commons Attribution-ShareAlike 3.0 Unported[2] license or, at your choice, those of the GNU FDL[3].\n",
      "\n",
      "Wikisource is constantly looking for new members. During the realization of this book, it's possible that we made some errors. You can report them at this page[4].\n",
      "\n",
      "The following users contributed to this book:\n",
      "\n",
      "Salamander724 Sotiale Caﬀelice~kowikisource Hibm98 Mineralsab Sjsws1078\n",
      "\n",
      "23\n",
      "\n",
      "Kwamikagami Tene~commonswiki Rocket000 Fleshgrinder Bastique Andux Amgine Boris23 KABALINI Bromskloss AzaToth Bender235 PatríciaR Vanished user 24kwjf10h32h\n",
      "\n",
      "1. ↑ https://wikisource.org 2. ↑ https://www.creativecommons.org/licenses/by-sa/3.0 3. ↑ https://www.gnu.org/copyleft/fdl.html 4. ↑ https://wikisource.org/wiki/Wikisource:Scriptorium\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba581046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "300bddc2",
   "metadata": {},
   "source": [
    "# Chunking (문서 분할)\n",
    "\n",
    "![rag_split](figures/rag_split.png)\n",
    "\n",
    "- Load 한 문서를 지정한 기준의 덩어리(chunk)로 나누는 작업을 진행한다.\n",
    "\n",
    "## 나누는 이유\n",
    "1. **임베딩 모델의 컨텍스트 길이 제한**\n",
    "    - 대부분의 언어 모델은 한 번에 처리할 수 있는 토큰 수에 제한이 있다. 전체 문서를 통째로 입력하면 이 제한을 초과할 수 있어 처리가 불가능해진다.\n",
    "2. **검색 정확도 향상**\n",
    "    - 큰 문서 전체보다는 특정 주제나 내용을 다루는 작은 chunk가 사용자 질문과 더 정확하게 매칭된다. 예를 들어, 100페이지 매뉴얼에서 특정 기능에 대한 질문이 있을 때, 해당 기능을 설명하는 몇 개의 문단만 검색되는 것이 더 효과적이다.\n",
    "    - 사용자 질문에 대해 문서의 모든 내용이 다 관련있는 것은 아니다. Chunking을 통해 가장 관련성 높은 부분만 선별적으로 활용할 수 있어 답변의 품질이 향상된다.\n",
    "    - 전체 문서에는 질문과 무관한 내용들이 많이 포함되어 있어 모델이 혼란을 겪을 수 있다. 적절한 크기의 chunk는 이런 노이즈를 줄여준다.\n",
    "3. **계산 효율성**\n",
    "    - 벡터 유사도 계산, 임베딩 생성 등의 작업이 작은 chunk 단위로 수행될 때 더 빠르고 효율적이다. 메모리 사용량도 줄일 수 있다.\n",
    "\n",
    "## 주요 Splitter\n",
    "- **Splitter**는 문서를 분할(chunking)을 처리해주는 도구들이다. Langchain은 분할 대상, 방법에 따라 다양한 splitter를 제공한다.\n",
    "- **Splitter 의 목표**\n",
    "  - 가능한 한 **의미 있는 덩어리를 유지**하면서, **최대 길이(chunk_size)**를 넘지 않도록 나누기.\n",
    "- https://reference.langchain.com/python/langchain_text_splitters/\n",
    "\n",
    "### CharacterTextSplitter\n",
    "가장  기본적인 Text spliter\n",
    "- 한개의 구분자를 기준으로 분리한다. (default: \"\\n\\n\")\n",
    "    - 분리된 조각이 chunk size 보다 작으면 다음 조각과 합칠 수 있다.\n",
    "        - 합쳤을때 chuck_size 보다 크면 안 합친다. chuck_size 이내면 합친다.\n",
    "    - 나누는 기준은 구분자이기 때문에 chunk_size 보다 글자수가 많을 수 있다.\n",
    "- chunk size: 분리된 문서(chunk) 글자수 이내에서 분리되도록 한다.\n",
    "    -  구분자를 기준으로 분리한다. 구분자를 기준으로 분리한 문서 조각이 chunk size 보다 크더라도 그대로 유지한다. 즉 chunk_size가 우선이 아니라 **seperator** 가 우선이다.\n",
    "- 주요 파라미터\n",
    "    - chunk_size: 각 조각의 최대 길이를 지정.\n",
    "    - seperator: 구분 문자열을 지정. (default: '\\n\\n')\n",
    "- CharacterTextSplitter는 단순 스플리터로 overlap기능을 지원하지는 않는다. 단 seperator가 빈문자열(\"\") 일 경우에는 overlap 기능을 지원한다. overlap이란 각 이전 청크의 뒷부분의 문자열을 앞에 붙여 문맥을 유지하는 것을 말한다.\n",
    "  \n",
    "### RecursiveCharacterTextSplitter\n",
    "- RecursiveCharacterTextSplitter는 **긴 텍스트를 지정된 최대 길이(chunk_size) 이하로 나누는 데 효과적인 텍스트 분할기**(splitter)이다.\n",
    "- 여러 **구분자(separators)를 순차적으로 적용**하여, 가능한 한 자연스러운 문단/문장/단어 단위로 분할하고, 최종적으로는 크기 제한을 만족시킨다.\n",
    "- 분할 기준 문자\n",
    "    1. 두 개의 줄바꿈 문자 (\"\\n\\n\")\n",
    "    2. 한 개의 줄바꿈 문자 (\"\\n\")\n",
    "    3. 공백 문자 (\" \")\n",
    "    4. 빈 문자열 (\"\")\n",
    "- 작동 방식\n",
    "    1. 먼저 가장 높은 우선순위의 구분자(\"\\n\\n\")를 기준으로 분리한다.\n",
    "    2. 분할된 조각 중 **chunk_size를 초과하는 조각**에 대해 다음 우선순위 구분자(\"\\n\" → \" \" → \"\")로 재귀적으로 재분할한다.\n",
    "    3. 이 과정을 통해 모든 조각(chunk)이 chunk_size를 초과하지 않도록 만든다.  \n",
    "- 주요 파라미터\n",
    "    - chunk_size: 각 조각의 최대 길이를 지정.\n",
    "    - chunk_overlap: 연속된 청크들 간의 겹치는 문자 수를 설정. 새로운 청크 생성 시 이전 청크의 마지막 부분에서 지정된 수만큼의 문자를 가져와서 새 청크의 앞부분에 포함시켜, 청크 경계에서 문맥의 연속성을 유지한다.\n",
    "      - 구분자에 의해 청크가 나눠지면 정상적인 분리이므로 overlap이 적용되지 않는다.\n",
    "      - 정상적 구분자로 나눌 수 없어 chunk_size에 맞춰 잘라진 경우 문맥의 연결성을 위애 overlap을 적용한다.\n",
    "    - separators(list): 구분자를 지정한다. 지정하면 기본 구분자가 지정한 것으로 변경된다.\n",
    "\n",
    "#### 메소드\n",
    "- `split_documents(Iterable[Document]) : List[Document]`\n",
    "    - Document 목록을 받아 split 처리한다.\n",
    "- `split_text(str) : List[str]`\n",
    "    - string text를 받아서 split 처리한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a08d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 69, which is longer than the specified 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"123456789012345678901234567890123456789012345678901234567890123456789\n",
    "\n",
    "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "가나다라마바사아자차카타파하\n",
    "\n",
    "아야어여오요우유으이\n",
    "\n",
    "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\"\"\"\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=60,\n",
    "    chunk_overlap=10,  # default: 200, chunk_size보다 chunk_overlap이 크면 안됨.\n",
    "    # separator=\"\" # chunk_size기준으로 나누기. => chunk_overlap 적용\n",
    ")\n",
    "result = splitter.split_text(text)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3725f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69-123456789012345678901234567890123456789012345678901234567890123456789\n",
      "-----------------------------------\n",
      "52-abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "-----------------------------------\n",
      "26-가나다라마바사아자차카타파하\n",
      "\n",
      "아야어여오요우유으이\n",
      "-----------------------------------\n",
      "52-abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for txt in result:\n",
    "    print(len(txt), txt, sep=\"-\")\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77fdc66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Created a chunk of size 69, which is longer than the specified 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str -> Document 객체로 변환.\n",
    "doc = Document(page_content=text, metadata={\"category\":\"split\"})\n",
    "\n",
    "docs2 = splitter.split_documents([doc])\n",
    "len(docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea642033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 123456789012345678901234567890123456789012345678901234567890123456789\n",
      "52 abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "26 가나다라마바사아자차카타파하\n",
      "\n",
      "아야어여오요우유으이\n",
      "52 abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
     ]
    }
   ],
   "source": [
    "for doc in docs2:\n",
    "    print(len(doc.page_content), doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c8840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4b659be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\"\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQ RSTUVWXYZ\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ae7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40-1234567890123456789012345678901234567890\n",
      "-------------------------------\n",
      "29-12345678901234567890123456789\n",
      "-------------------------------\n",
      "49-abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVW\n",
      "-------------------------------\n",
      "13-NOPQRSTUVWXYZ\n",
      "-------------------------------\n",
      "26-가나다라마바사아자차카타파하\n",
      "\n",
      "아야어여오요우유으이\n",
      "-------------------------------\n",
      "43-abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQ\n",
      "-------------------------------\n",
      "9-RSTUVWXYZ\n",
      "-------------------------------\n",
      "49-abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVW\n",
      "-------------------------------\n",
      "13-NOPQRSTUVWXYZ\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text2 = \"\"\"1234567890123456789012345678901234567890\n",
    "12345678901234567890123456789\n",
    "\n",
    "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "가나다라마바사아자차카타파하\n",
    "\n",
    "아야어여오요우유으이\n",
    "\n",
    "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQ RSTUVWXYZ\n",
    "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\"\"\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10\n",
    "    seperators=[\"\\n\\n\", '\\n', '[.?!,]', ' ', ''],\n",
    "    is_separator_regex=True # seperator가 정규 표현식\n",
    ")\n",
    "result2 = splitter.split_text(text2)\n",
    "\n",
    "for txt in result2:\n",
    "    print(len(txt), txt, sep=\"-\")\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a027ed82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "path = \"data/olympic.txt\"\n",
    "\n",
    "# Loading -> Split\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=20\n",
    ")\n",
    "\n",
    "load_docs = loader.load()\n",
    "docs = splitter.split_documents(load_docs)\n",
    "docs = [doc for doc in docs if len(doc.page_content) > 10]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf93f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5b25cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb96813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load_and_split(splitter) # splitter를 이용해서 load 와 split을 한번에 처리.\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8206f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed87439d",
   "metadata": {},
   "source": [
    "## Token 수 기준으로 나누기\n",
    "\n",
    "- LLM 언어 모델들은 입력 토큰 수 제한이 있어서 요청시 제한 토큰수 이상의 프롬프트는 전송할 수 없다.\n",
    "- 따라서 텍스트를 chunk로 분할할 때는 글자수 보다 **토큰 수를 기준으로 크기를 지정하는 것**이 좋다.  \n",
    "- 토큰기반 분할은 텍스트의 의미를 유지하면서 분할하는 방식이므로 문자 기반 분할과 같이 단어가 중간잘리는 것들을 방지할 수 있다. \n",
    "- 토큰 수 계산할 때는 사용하는 언어 모델에 사용된 것과 동일한 tokenizer를 사용하는 것이 좋다.\n",
    "  - 예를 들어 OpenAI의 GPT 모델을 사용할 경우 tiktoken 라이브러리를 활용하여 토큰 수를 정확하게 계산할 수 있다.\n",
    "\n",
    "### [tiktoken](https://github.com/openai/tiktoken) tokenizer 기반 분할\n",
    "- OpenAI에서 GPT 모델을 학습할 때 사용한 `BPE` 방식의 tokenizer. **OpenAI 언어모델을 사용할 경우 이것을 사용하는 것이 좀 더 정확하게  토큰을 계산할 수 있다.**\n",
    "- Splitter.from_tiktoken_encoder() 메소드를 이용해 생성\n",
    "  - `RecursiveCharacterTextSplitter.from_tiktoken_encoder()`\n",
    "  - `CharacterTextSplitter.from_tiktoken_encoder()`\n",
    "- 파라미터\n",
    "  - encode_name: 인코딩 방식(토큰화 규칙)을 지정. OpenAI는 GPT 모델들 마다 다른 방식을 사용했다. 그래서 사용하려는 모델에 맞는 인코딩 방식을 지정해야 한다.\n",
    "    - `cl100k_base`: GPT-4 및 GPT-3.5-Turbo 모델에서 사용된 방식.\n",
    "    - `r50k_base:` GPT-3 모델에서 사용된 방식 \n",
    "  - chunk_size, chunk_overlap, separators 파라미터 (위와 동일)\n",
    "- tiktoken 설치\n",
    "  - `pip install tiktoken`\n",
    "\n",
    "### HuggingFace Tokenizer\n",
    "- HuggingFace 모델을 사용할 경우 그 모델이 사용한 tokenizer를 이용해 토큰 기반으로 분할 한다.\n",
    "  - 다른 tokenizer를 이용해 분할 할 경우 토큰 수 계산이 다르게 될 수있다.\n",
    "- `from_huggingface_tokenizer()` 메소드를 이용.\n",
    "  - 파라미터\n",
    "    - tokenizer: HuggingFace tokenizer 객체\n",
    "    - chunk_size, chunk_overlap, separators 파라미터 (위와 동일)\n",
    "- `transformers` 라이브러리를 설치해야 한다.\n",
    "  - `pip install transformers` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7b8b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip show tiktoken\n",
    "# !uv pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "299ceb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "path = \"data/olympic.txt\"\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "     model_name=\"gpt-5-mini\",  # gpt-5-mini 에서 사용한 tokenizer 기준으로 한다.\n",
    "     chunk_size=500,\n",
    "     chunk_overlap=20\n",
    ")\n",
    "docs = loader.load_and_split(splitter)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d7b34cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽\n",
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다. 대부분의 인기있는 종목들이나 일상에서 쉽게 접하고 즐길 수 있는 생활스포츠 종목들이 올림픽이라는 한 대회에서 동시에 열리고, 전 세계 대부분의 국가 출신의 선수들이 참여하는 만큼 전 세계 스포츠 팬들이 가장 많이 시청하는 이벤트이다. 2008 베이징 올림픽의 모든 종목 누적 시청자 수만 47억 명에 달하며, 이는 인류 역사상 가장 많은 수의 인구가 시청한 이벤트였다.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99796ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bee43b8e0034e3c8573214d63dcef10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\SKN21_inst\\10_langchain\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Playdata\\.cache\\huggingface\\hub\\models--google--gemma-3-4b-it. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8df1c910224338919c2fb65544694e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1bc3608b534f0e8d8e7802d0306793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6abe3bdd1d4497a1986d68ddb1b32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faaed33872b44cbd884bf7e6d448f923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "# huggingface tokenizer 이용\n",
    "from transformers import AutoTokenizer\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cfe6573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter2 = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "docs = loader.load_and_split(splitter2)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9ddbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a15cd4",
   "metadata": {},
   "source": [
    "## MarkdownHeaderTextSplitter\n",
    "- Markdown Header 기준으로 Splitter\n",
    "- Loading한 문서가 Markdown 문서이고 Header를 기준으로 문서의 내용이 나눠질때 사용.\n",
    "- https://reference.langchain.com/python/langchain_text_splitters/#langchain_text_splitters.MarkdownTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe3b1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "# 대주제1\n",
    "- 동물\n",
    "\n",
    "## 중주제1\n",
    "- 포유류\n",
    "\n",
    "- 조류\n",
    "\n",
    "### 소주제1\n",
    "- 개\n",
    "- 고양이\n",
    "- 까치\n",
    "- 독수리\n",
    "\n",
    "# 대주제2\n",
    "## 중주제2\n",
    "- 기차\n",
    "- 배\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30c15132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <h1> ~ <h6> # ~ #*6\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "# header 정보는 metadata에 저장. 내용은 page_content에 저장.\n",
    "headers_to_split = [\n",
    "    (\"#\", \"header1\"),\n",
    "    (\"##\", \"header2\"),\n",
    "    (\"###\", \"header3\")\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split, # 어떤 header를 기준으로 나눌지.\n",
    "    strip_headers=True, # default: True - Header(#)을 내용에 포함시킬지 여부. True: 포함안시킴\n",
    "    return_each_line=False # True: 각 라인을 별도의 Document로 생성.\n",
    ")\n",
    "# MarkdownHeaderTextSplitter는 split_documents() 메소드가 없다. split_text(str)\n",
    "docs = splitter.split_text(text)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4583b342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'header1': '대주제1'}\n",
      "- 동물\n",
      "======================================\n",
      "{'header1': '대주제1', 'header2': '중주제1'}\n",
      "- 포유류  \n",
      "- 조류\n",
      "======================================\n",
      "{'header1': '대주제1', 'header2': '중주제1', 'header3': '소주제1'}\n",
      "- 개\n",
      "- 고양이\n",
      "- 까치\n",
      "- 독수리\n",
      "======================================\n",
      "{'header1': '대주제2', 'header2': '중주제2'}\n",
      "- 기차\n",
      "- 배\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content)\n",
    "    print(\"======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f528de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "path = \"data/olympic_wiki.md\"\n",
    "# load - # 기준으로 split\n",
    "\n",
    "# with open(path, 'rt', encoding='utf-8') as fr:\n",
    "#     content = fr.read()\n",
    "# content\n",
    "\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"h1\"),\n",
    "    (\"##\", \"h2\"),\n",
    "    (\"###\", \"h3\")\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9b483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load -> split\n",
    "docs = loader.load() # [Document, Document, ..]\n",
    "doc_txt = '\\n'.join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b72219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs = splitter.split_text(doc_txt)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67c03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'h1': '올림픽'}, page_content='올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다. 대부분의 인기있는 종목들이나 일상에서 쉽게 접하고 즐길 수 있는 생활스포츠 종목들이 올림픽이라는 한 대회에서 동시에 열리고, 전 세계 대부분의 국가 출신의 선수들이 참여하는 만큼 전 세계 스포츠 팬들이 가장 많이 시청하는 이벤트이다. 2008 베이징 올림픽의 모든 종목 누적 시청자 수만 47억 명에 달하며, 이는 인류 역사상 가장 많은 수의 인구가 시청한 이벤트였다.  \\n또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다.  \\n올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다.  \\n올림픽은 거의 모든 국가가 참여할 정도로 규모가 커졌다. 하계 올림픽은 33개의 종목과 약 400개의 세부종목에서 13,000명이 넘는 선수들이 겨루고 그중 각 종목별 1, 2, 3위는 각각 금/은/동을 수여받는다. 전 세계 언론에서 각각 4년마다 열리는 올림픽 경기를 중계하기 때문에 이름 없는 선수가 개인적, 국가적, 세계적으로 명성을 얻을 수 있는 기회가 된다. 이와 더불어 올림픽 경기는 개최지와 개최국에게도 전 세계에 그 이름을 널리 알리는 좋은 기회가 된다.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
