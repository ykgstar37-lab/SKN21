{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907e923a-af5e-48c3-9664-58bd640efb20",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "![rag_embedding](figures/rag_embedding.png)\n",
    "\n",
    "- 분할된 텍스트를 벡터 표현(임베딩 벡터)으로 변환한다.\n",
    "- LangChain은 OpenAI, HuggingFace 등 다양한 임베딩 모델을 지원하며, 동일한 인터페이스로 사용할 수 있다.\n",
    "- [임베딩모델의 메서드](https://reference.langchain.com/python/langchain/embeddings/#langchain.embeddings.init_embeddings)\n",
    "\n",
    "    - **`embed_documents(texts: List[str])`**\n",
    "        - 여러 문서를 받아 벡터화(임베딩)한다.\n",
    "        - Context를 벡터화 할 때 사용한다.\n",
    "    - **`embed_query(text: str)`**\n",
    "        - 하나의 문자열(문서)을 받아 벡터화한다.\n",
    "        - Query를 벡터화 할 때 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff941301-56f5-4219-89e8-6b54d5afd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "        \"나는 고양이와 개 중 반려동물로 개를 키우고 싶습니다.\",\n",
    "        \"이 강아지 품종은 진도개 입니다. 국제 표준으로 중대형견으로 분류되며 다리가 길어 체고가 높은 편에 속합니다.\",\n",
    "        \"日本の市内バスの運賃は主に距離によって決まり、地域やバス会社によって異なる場合があります\",                 # 일본의 시내버스 요금은 주로 거리에 따라 결정되며, 지역 및 버스 회사에 따라 다를 수 있습니다.\n",
    "        \"Bus fares in the United States vary from city to city, but are generally around $2.90 for a regular bus.\", # 미국의 버스 요금은 도시마다 다르지만, 일반적으로 정기 버스의 경우 2.90달러 정도입니다.\n",
    "        \"광역버스 요금은 일반 3000원, 청소년은 1800원, 어린이 1500원 입니다.\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3ba75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 Embedding Model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = \"text-embedding-3-small\" # text-embedding-3-large\n",
    "e_model1 = OpenAIEmbeddings(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d387375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m30 packages\u001b[0m \u001b[2min 306ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 184ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 461ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentence-transformers\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface Embedding 모델 -> hub: task - NLP > sentence-similarity\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "e_model1 = HuggingFaceEmbeddings(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9c8e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama 제공 Embedding 모델 -> 검색에서 embedding 선택\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "model_name = \"bge-m3\"\n",
    "e_model1 = OllamaEmbeddings(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cca4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9f2308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_docs = e_model1.embed_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806163c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 5\n",
      "<class 'list'> 1024\n"
     ]
    }
   ],
   "source": [
    "print(type(embeded_docs), len(embeded_docs))\n",
    "print(type(embeded_docs[0]), len(embeded_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be3c0614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.041572433,\n",
       " 0.022668164,\n",
       " -0.05686543,\n",
       " 0.034415167,\n",
       " -0.015305063,\n",
       " -0.0115357265,\n",
       " -0.008570938,\n",
       " -0.022301462,\n",
       " -0.007863548,\n",
       " -0.037318137]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_docs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a05940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 유사한 문서를 찾기.\n",
    "# 유사도 체크를 위한 방법: 방향기반-코사인 유사도, 거리기반-유클리디안(L2), 맨하탄(L1) 거리계산.\n",
    "import numpy as np\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    \"\"\"코사인 유사도 계산\n",
    "    -1 ~ 1 사이 값을 반환\n",
    "    -1: 정 반대의 의미\n",
    "    0: 관계 없음\n",
    "    1: 완벽히 같은 의미\"\"\"\n",
    "    v1 = np.array(vector1)\n",
    "    v2 = np.array(vector2)\n",
    "    return (v1 @ v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# np.linalg.norm(v1)\n",
    "# sqrt(sum(v1**2))  # 원소들의 제곱의 합의 제곱근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d40397fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"개와 고양이 중 뭘 더 좋아하나요?\" # 질문\n",
    "query = \"요새 버스요금 얼마야?\"\n",
    "query = \"어떤 개를 키우나요?\"\n",
    "embedded_query = e_model1.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2e15f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.7203117558334239\n",
      "2. 0.5548696205207466\n",
      "3. 0.21188046293856108\n",
      "4. 0.21158856598401468\n",
      "5. 0.22694379820199395\n"
     ]
    }
   ],
   "source": [
    "for i, embedded_doc in enumerate(embeded_docs): # 각 문서들의 embedding vector\n",
    "    print(f\"{i+1}. {cosine_similarity(embedded_query, embedded_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702aae4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d02707-99d9-4d48-826f-ae446a405fc6",
   "metadata": {},
   "source": [
    "# 벡터 데이터베이스(Vector Database)\n",
    "\n",
    "![rag_vector_store](figures/rag_vector_store.png)\n",
    "\n",
    "- **벡터 데이터베이스란**\n",
    "-  벡터 데이터베이스는 데이터를 고차원 벡터(임베딩)로 변환하여 저장하고, 벡터 간의 유사도를 기반으로 검색과 관리를 수행하는 특수한 형태의 데이터베이스이다.\n",
    "\n",
    "- **주요 특징**\n",
    "  - 텍스트, 이미지, 오디오 등의 비정형 데이터를 수치 벡터로 변환하여 저장\n",
    "   - 코사인 유사도, 유클리드 거리 등을 이용한 벡터 간 유사도 계산을 통한 검색\n",
    "   - 근사 최근접 이웃(Approximate Nearest Neighbor, ANN) 알고리즘을 통한 빠른 검색을 지원.\n",
    "\n",
    "## 벡터 데이터베이스와 딥러닝\n",
    "- 벡터 데이터베이스는 딥러닝 기술의 발전과 깊은 관련이 있다.\n",
    "- 딥러닝 모델은 학습 과정에서 데이터의 특징을 추출하는 방법을 함께 학습한다. 충분한 데이터를 학습한 딥러닝 모델은 **데이터의 특성을 설명하는 특성 벡터(feature vector)를 효과적으로 생성**할 수 있다.\n",
    "- 이때 추출된 특성 벡터는 고차원 데이터(RAW Data)를 저차원 공간에서 표현한 **임베딩 벡터**다.\n",
    "    - > **임베딩**은 고차원 데이터를 저차원 공간으로 변환하여 표현하는 방법으로, 정보 손실을 최소화하면서 데이터 간의 의미 있는 관계를 벡터 공간에서 유지한다.\n",
    "- 딥러닝 모델로 추출한 데이터의 특징(feature vector)을 임베딩 공간에 배치하면, 비슷한 데이터는 가까이, 그렇지 않은 데이터는 멀리 배치된다.\n",
    "- 이러한 특성을 활용하면 임베딩 벡터 간의 거리를 계산해 유사한 데이터를 효과적으로 검색할 수 있다. 벡터 데이터베이스는 이러한 임베딩 벡터의 특성을 기반으로 개발되었다.\n",
    "- 딥러닝 기술의 발전과 폭넓은 활용으로 임베딩 데이터의 사용이 증가하면서, 이를 저장하고 관리하는 기능에 특화된 데이터베이스에 대한 수요도 증가해 다양한 벡터 데이터베이스가 등장했다.\n",
    "\n",
    "## LLM과 벡터 데이터베이스\n",
    "- ChatGPT(LLM)의 등장 이후 벡터 데이터베이스는 폭발적인 주목을 받았다.\n",
    "- 임베딩 벡터의 유사도를 기반으로 문서를 검색하는 RAG(Relevant Augmented Generation) 기술은 LLM의 환각(할루시네이션) 현상을 줄이고, LLM을 추가 학습하지 않고도 최신 정보를 효율적으로 활용할 수 있는 핵심 기법으로 자리 잡았다.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65063-9482-4fdb-9ada-941eb08fb3b2",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 종류\n",
    "![img](figures/vector_database.png)\n",
    "\n",
    "<<https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c>>\n",
    "\n",
    "### 주요 벡터 데이터베이스 종류\n",
    "- **Qdrant**\n",
    "    - Rust로 개발된 고성능 벡터 검색 엔진으로, 실시간 근사 최근접 이웃 검색을 제공한다.  \n",
    "    - 추천 시스템에 특화되어 있으며, 벡터 임베딩 저장과 유사도 쿼리를 효율적으로 수행한다.\n",
    "- **Pinecone**\n",
    "    - 클라우드 기반의 완전 관리형 벡터 데이터베이스 서비스로, 간단한 API를 통해 벡터 데이터를 관리할 수 있다.  \n",
    "    - 자동 확장성과 고가용성을 제공하며, 실시간 데이터 수집과 유사성 검색에 최적화되어 있다.\n",
    "    - 가장 쉽게 시작할 수 있는 관리형 서비스를 제공한다.\n",
    "- **Chroma**\n",
    "    - 벡터 임베딩을 효율적으로 저장하고 검색할 수 있는 오픈소스 데이터베이스로, AI 및 머신러닝 애플리케이션에 최적화되어 있다.\n",
    "    - 대규모 임베딩 저장에 최적화되어 있다.\n",
    "- **FAISS**\n",
    "    - Facebook AI에서 개발한 고성능 벡터 검색 라이브러리로, 고차원 벡터의 효율적인 유사성 검색을 위해 최적화되어 있다.\n",
    "    - GPU를 활용해 계산 성능을 높이며, 벡터 양자화 기술을 활용하여 메모리 사용을 최적화한다.\n",
    "    - 근사 최근접 이웃 검색(ANNS)에 최적화되어 있다.\n",
    "- **Milvus**\n",
    "    - 오픈소스 벡터 데이터베이스로, 대규모 벡터 데이터를 효율적으로 저장하고 검색할 수 있다.  \n",
    "    - 분산 아키텍처를 채택하여 확장성이 뛰어나며, IVF_PQ, DiskANN 등 다양한 인덱싱 알고리즘을 지원한다.\n",
    "    - 대규모 데이터셋 처리에 가장 적합한 솔루션이다.\n",
    "- **Weaviate**\n",
    "    - 오픈소스 벡터 데이터베이스로, 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 저장하고 검색할 수 있다.  \n",
    "    - GraphQL API를 통해 접근 가능하며, 내장된 머신러닝 모듈을 통해 가장 강력한 의미론적 검색 기능을 제공한다.\n",
    "- **Elasticsearch**\n",
    "    - HNSW 알고리즘을 사용하여 벡터 검색을 구현하는 검색 엔진이다.\n",
    "    - 전통적인 검색 기능과 벡터 검색을 효과적으로 결합할 수 있어, 하이브리드 검색에 가장 적합하다.\n",
    "- **PGVector**\n",
    "    - PostgreSQL의 확장 모듈로, 벡터 데이터를 저장하고 유사성 검색을 수행할 수 있게 해준다.  \n",
    "    - SQL과 통합된 벡터 연산이 가능하며, L2 거리, 코사인 거리, 내적 등 다양한 거리 측정 방식을 지원한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3f6fe-c5e2-4c4f-9ef8-2cf5850f1bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1336f523-0b76-419c-8e46-fa96bdbcbdd6",
   "metadata": {},
   "source": [
    "# Langchain - Vector Store 연동 \n",
    "- Langchain은 다양한 벡터 데이터베이스와 연동할 수 있다.\n",
    "- 벡터 데이터베이스 마다 API가 다르기 때문에, Langchain을 사용하면 동일한 interface로 사용할 수 있다.\n",
    "\n",
    "## **VectorStore**\n",
    "- Langchain이 지원하는 모든 벡터 데이터베이스는 **VectorStore** 인터페이스를 구현한다.\n",
    "- 그래서 Langchain에서는 벡터 데이터베이스를 **Vector Store** 라고 한다.\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "### Vector Store 연결\n",
    "- Vector DB와 연결하는 메소드\n",
    "- `VectorStore.from_documents()`\n",
    "  - Document들을 insert 하면서 연결.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - documents: insert할 문서들을 list[Document]로 전달.\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "- `VectorStore()`\n",
    "  - vector db와 연결만 한다.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "## InMemoryVectorStore\n",
    "- langchain에서 제공하는 메모리 기반 벡터 데이터베이스이다.\n",
    "- Data들을 Dictionary를 사용해 메모리에 저장하며, 검색 할 때 코사인 유사도(cosine similarity)를 계산하여 조회한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7fcddfb-0fd3-4cb8-a4f0-b72d1988d6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1092d6e3-2c41-426d-ac58-5f4ba1201ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Embedding Model 생성\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# VectorStore 생성 -> Embedding 모델을 넣어서 생성.\n",
    "vectorstore = InMemoryVectorStore(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0696220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "d1 = Document(id=1, page_content=\"Apple, Pear, Watermelon\", metadata={\"category\":\"fruit\"})\n",
    "d2 = Document(id=2, page_content=\"Python, C++, Java\", metadata={\"category\":\"it\"})\n",
    "d3 = Document(id=3, page_content=\"Football, Baseball, Basketball\", metadata={\"category\":\"sports\"})\n",
    "\n",
    "# VectorStore에 데이터를 넣기. - add_documents() 리스트로 묶어서 전달.\n",
    "vectorstore.add_documents(documents=[d1, d2, d3]) # embedding_vector - 문서\n",
    "\n",
    "# VectorStore를 생성(연결) 하면서 문서들을 넣기(upsert)\n",
    "# InMemoryVectorStore.from_documents(\n",
    "#     documents=[d1, d2, d3],\n",
    "#     embedding=embedding_model\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12ac9b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Apple, Pear, Watermelon\n",
      "2. Python, C++, Java\n",
      "3. Football, Baseball, Basketball\n"
     ]
    }
   ],
   "source": [
    "# 검색 - 유사도 기반 검색\n",
    "query = \"SQL\"\n",
    "query = \"Rust\"\n",
    "query = \"Running\"\n",
    "query = \"Orange\"\n",
    "query = \"IPhone\"\n",
    "result = vectorstore.similarity_search(query=query, k=3) # k: 유사도 높은 순서대로 문서 k개를 반환.\n",
    "# result\n",
    "for i, r in enumerate(result):\n",
    "    print(f\"{i+1}. {r.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb46e40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football, Baseball, Basketball 0.31760192110415725\n",
      "Python, C++, Java 0.25312504788245027\n",
      "Apple, Pear, Watermelon 0.16853818216914074\n"
     ]
    }
   ],
   "source": [
    "query = \"SQL\"\n",
    "query = \"Rust\"\n",
    "query = \"Running\"\n",
    "# query = \"Orange\"\n",
    "# query = \"IPhone\"\n",
    "\n",
    "result = vectorstore.similarity_search_with_score(query=query, k=3) # 유사도 점수까지 반환\n",
    "# tuple - (검색한 Document, 유사도 점수) \n",
    "for doc, score in result:\n",
    "    print(doc.page_content, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc4641-857c-47c1-80ff-5f4c2651a4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0da7c8f-c1be-4ddf-a935-90b22eac1f11",
   "metadata": {},
   "source": [
    "# 실습\n",
    "1. text loading\n",
    "2. text split\n",
    "3. embedding + vector store(InMemoryVectorStore)에 저장\n",
    "4. query(질의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349be3ce-539e-4d18-bc2b-67e8100ebcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "path = \"data/olympic.txt\"\n",
    "# 1. 문서 로드 + Split\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "# 2. splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600, chunk_overlap=50\n",
    ")\n",
    "\n",
    "docs = loader.load_and_split(splitter)\n",
    "docs = [doc for doc in docs if len(doc.page_content) >= 10] # 10글자 이내는 제거\n",
    "\n",
    "# 3. vectorstore에 연결 + 저장\n",
    "## 1. embedding model \n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "## 2. VectorStore 생성\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd1a80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의\n",
    "# query = \"IOC는 어떤 기관인가요?\"\n",
    "# query = \"올림픽과 관련된 논란에는 무엇이 있나요?\"\n",
    "query = \"올림픽이 취소된 경우가 있어? 있다면 몇 년도에 어떤 이유로 취소됬는지 알려줘.\"\n",
    "result_docs = vectorstore.similarity_search_with_score(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d35b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>|||0.5053943836954357|||page_content='쿠베르탱의 생각과는 달리, 올림픽이 세계에 완벽한 평화를 가져다주지는 못했다. 실제로 제1차 세계대전으로 인해 독일 베를린에서 열리기로 했던 제6회 1916년 하계 올림픽이 취소되었고, 제2차 세계대전 때는 일본 도쿄에서 열리기로 했던 제12회 1940년 하계 올림픽, 삿포로에서 열리기로 했던 1940년 동계 올림픽, 영국 런던에서 열리기로 했던 제13회 1944년 하계 올림픽, 이탈리아 코르티나담페초에서 열릴 예정인 1944년 동계 올림픽이 취소되었다. 베이징에서 열린 2008년 하계 올림픽 개막식날 조지아와 러시아 간의 2008년 남오세티아 전쟁이 일어나기도 했다. 부시 대통령과 푸틴 대통령이 이 올림픽을 보러 왔으며 중국 주석인 후진타오가 주최한 오찬에 참석해서 이 현안에 대해 논의하기도 했다. 조지아 대표인 니노 살루크바체와 러시아 대표인 나탈리야 파데리나가 여자 10m 공기권총 경기에서 각각 동메달과 은메달을 땄을 때 이 일은 베이징 올림픽의 유명한 사건 중 하나로 남게 되었다. 살루크바체와 파데리나는 시상식이 끝난 뒤 서로 포옹을 하며 국적에 상관없이 기쁨을 나누었다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.457269118913022|||page_content='올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.44733130004214067|||page_content='쿠베르탱이 말했던 원래 이념과는 반대로 올림픽이 정치 혹은 체제 선전의 장으로 이용되는 경우가 있었다. 1936년 하계 올림픽을 개최할 때 당시의 나치독일은 나치는 자비롭고 평화를 위한다는 것을 설명하고 싶어했다. 또 이 올림픽에서 아리안족의 우월함을 보여줄 생각이었으나 이는 흑인이었던 제시 오언스가 금메달을 4개나 따내면서 실현되지는 못했다. 소련은 헬싱키에서 열린 1952년 하계 올림픽 때 처음으로 참가했다. 그 전에는 소련이 조직한 스파르타키아다라는 대회에 1928년부터 참가했었다. 다른 공산주의 국가들은 1920년대와 1930년대의 전쟁 기간 사이에 노동자 올림픽(Socialist Workers' Sport International)을 조직했는데, 이는 올림픽을 자본가와 귀족들의 대회로 여기고 그에 대한 대안으로 고안된 대회였다. 그 이후 소련은 1956년 하계 올림픽부터 1988년 하계 올림픽까지 엄청난 스포츠강국의 면모를 보여주며 올림픽에서의 명성을 드높였다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.44120709955410137|||page_content='올림피아 경기는 기원전 6세기~기원전 5세기에 절정에 이르렀으나, 그 후 로마가 패권을 잡은 뒤 그리스에 영향력을 행사하면서 서서히 쇠퇴하게 된다. 고대 올림픽이 공식적으로 끝난 해는 확실히 알 수 없으나, 대부분 테오도시우스 1세 황제가 모든 이단 숭배 및 예배를 금지했던 393년을 고대 올림픽의 마지막이라고 추정한다. 다른 설에 따르면 테오도시우스의 후계자인 테오도시우스 2세가 모든 그리스 신전을 파괴하라고 명령한 426년이라고도 한다. 이렇게 올림픽이 사라진 이후로 이보다 한참 뒤인 19세기에 이르러서야 비로소 다시 올림픽 경기가 열리게 된다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.4367387071934235|||page_content='동계올림픽\n",
      "동계 올림픽은 눈과 얼음을 이용하는 스포츠들을 모아 이루어졌으며 하계 올림픽 때 실행하기 불가능한 종목들로 구성되어 있다. 피겨스케이팅, 아이스하키는 각각 1908년과 1920년에 하계올림픽 종목으로 들어가 있었다. IOC는 다른 동계 스포츠로 구성된 새로운 대회를 만들고 싶어 했고, 로잔에서 열린 1921년 올림픽 의회에서 겨울판 올림픽을 열기로 합의했다. 1회 동계올림픽은 1924년, 프랑스의 샤모니에서 11일간 진행되었고, 16개 종목의 경기가 치러졌다. IOC는 동계 올림픽이 4년 주기로 하계 올림픽과 같은 년도에 열리도록 했다. 이 전통은 프랑스의 알베르빌에서 열린 1992년 올림픽 때까지 지속되었으나, 노르웨이의 릴레함메르에서 열린 1994년 올림픽부터 동계 올림픽은 하계 올림픽이 끝난지 2년후에 개최하였다.' metadata={'source': 'data/olympic.txt'}\n"
     ]
    }
   ],
   "source": [
    "for doc, score in result_docs:\n",
    "    print(\">>>\", score, doc, sep=\"|||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565d402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "645370c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 + 검색한 결과 context 로 LLM에게 질의\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"\"\"# instruction\n",
    "당신은 QA 전문 assistant입니다.\n",
    "질문에 대해 주어진 context를 기반으로 답을 해주세요.\n",
    "context에 질문과 관련된 내용이 없을 경우 '주어진 정보로는 답을 알 수 없습니다.' 라고 답을 하세요\n",
    "context에 없는 내용으로 답변을 만들지 마세요.\n",
    "\n",
    "# context\n",
    "{context}\n",
    "\n",
    "# 질문\n",
    "{query}\n",
    "\n",
    "# Output indicator\n",
    "- 답변을 context 어느부분을 참조하였는지 각주를 달아주세요.\n",
    "\n",
    "예)\n",
    "# 답변\n",
    "최종답변내용\n",
    "\n",
    "#참조내용\n",
    "context에서 참조한 내용\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2889eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorDB에서 조회한 결과중 page_content값만 추출 -> prompt의 context 주입\n",
    "context = '\\n\\n'.join(doc[0].page_content for doc in result_docs)\n",
    "# context\n",
    "result = chain.invoke({\"query\":query, \"context\":context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "152a3ac6-6f56-41ea-9c60-6a982226eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 답변\n",
      "있다. 다음 대회들이 취소되었다.\n",
      "- 1916년 하계 올림픽(베를린) — 제1차 세계대전으로 취소[1].\n",
      "- 1940년 하계 올림픽(도쿄) — 제2차 세계대전으로 취소[1].\n",
      "- 1940년 동계 올림픽(삿포로) — 제2차 세계대전으로 취소[1].\n",
      "- 1944년 하계 올림픽(런던) — 제2차 세계대전으로 취소[1].\n",
      "- 1944년 동계 올림픽(코르티나담페초) — 제2차 세계대전으로 취소[1].\n",
      "\n",
      "#참조내용\n",
      "[1] \"실제로 제1차 세계대전으로 인해 독일 베를린에서 열리기로 했던 제6회 1916년 하계 올림픽이 취소되었고, 제2차 세계대전 때는 일본 도쿄에서 열리기로 했던 제12회 1940년 하계 올림픽, 삿포로에서 열리기로 했던 1940년 동계 올림픽, 영국 런던에서 열리기로 했던 제13회 1944년 하계 올림픽, 이탈리아 코르티나담페초에서 열릴 예정인 1944년 동계 올림픽이 취소되었다.\"\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d01f0-2fd7-4795-85a1-4ce9ea26a00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c15ed2-e9d6-4361-9d9e-0dfaf650de41",
   "metadata": {},
   "source": [
    "## MMR(최대 한계 관련성-Maximal Marginal Relevance) 알고리즘 적용\n",
    "최대 한계 관련성(Maximal Marginal Relevance, MMR) 알고리즘은 정보 검색 및 요약에서 검색 결과의 **관련성**과 **다양성**을 동시에 고려하여 최적의 결과를 제공하는 방법이다. \n",
    "이 알고리즘은 사용자 쿼리와의 관련성을 최대화하면서도 중복 정보를 최소화하여 다양한 정보를 제공하는 것을 목표로 한다.\n",
    "\n",
    "1. **관련성과 다양성의 균형 조절**: MMR은 사용자 쿼리와 문서 간의 유사성 점수와 이미 선택된 문서들과의 다양성 점수를 조합하여 각 문서의 최종 점수를 계산한다. 이를 통해 관련성이 높으면서도 중복되지 않는 문서를 선택한다.\n",
    "\n",
    "2. **수학적 정의**\n",
    "   $$\n",
    "   \\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')\n",
    "   $$\n",
    "\n",
    "   - $\\text{Sim}(d, Q)$: 문서 $d$와 쿼리 $\\text{Q}$ 사이의 유사성. (문서 유사성 계산)\n",
    "   - $\\max_{d' \\in D'} \\text{Sim}(d, d')$: 문서 $d$와 이미 선택된 문서 집합 $D'$ 중 가장 유사한 문서와의 유사성. (문서 다양성 계산)\n",
    "   - $\\lambda$: 유사성과 다양성의 중요도를 조절하는 매개변수(parameter)\n",
    "3. **적용 분야**: MMR은 정보 검색, 추천 시스템, 문서 요약 등에서 활용된다. 특히 LLM 검색에서 성능 향상이 입증되었다.\n",
    "\n",
    "### `vectorStore.max_marginal_relevance_search()` 메소드\n",
    "  - MMR 알고리즘을 적용한 검색을 수행한다.\n",
    "  - **파라미터**\n",
    "    - **query**: 사용자로부터 입력받은 검색 쿼리\n",
    "    - **k**: 최종적으로 선택할 문서의 수\n",
    "    - **fetch\\_k**: MMR 알고리즘 적용 시 고려할 상위 문서의 수\n",
    "    - **lambda_mult**: 쿼리와의 유사성과 선택된 문서 간의 다양성 사이의 균형을 조절하는 매개변수. $\\lambda = 1$이면 유사성만 고려하고, $\\lambda = 0$이면 다양성만을 최대화한다.\n",
    "    - **filter**: 검색 결과를 필터링할 조건을 지정한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f92a398d-f0f6-416f-aad8-4c97ced68992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국제 올림픽 위원회\n",
      "올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파\n",
      "--------------------------------------------------\n",
      "이 언행이 많은 IOC위원들이 시온에 대해 언짢게 생각하게 되고 토리노가 개최지로 선정되도\n",
      "--------------------------------------------------\n",
      "1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑\n",
      "--------------------------------------------------\n",
      "2004년 10월과 11월에 IOC는 '올림픽 프로그램 위원회'(Olympic Progra\n",
      "--------------------------------------------------\n",
      "후보도시로 선택되면 그 도시들은 IOC에 보내는 후보도시에 관한 문서에 그들의 계획을 더욱\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"IOC는 어떤 기구입니까?\"\n",
    "\n",
    "mmr_result = vectorstore.max_marginal_relevance_search(\n",
    "    query=query,\n",
    "    k=5,\n",
    "    fetch_k=10,     # 다양성 계산을 위해 상위 몇개의 문서를 볼지.\n",
    "    lambda_mult=0.5 # 관련성, 다양성을 반반씩.\n",
    ")\n",
    "\n",
    "for doc in mmr_result:\n",
    "    print(doc.page_content[:50])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b3c9c-8f56-48fd-a952-9f79f0b75f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab46f5a-14b4-4b0d-a6ea-4dd855a452c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
