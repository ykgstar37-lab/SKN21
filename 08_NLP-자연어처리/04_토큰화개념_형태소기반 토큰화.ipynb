{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee251a30",
   "metadata": {},
   "source": [
    "# 토큰화\n",
    "\n",
    "토큰화(tokenization)는 자연어를 **모델이 이해할 수 있는 또는 모델이 다룰 수있는 기본 단위(Token)** 분할하는 과정을 말한다.   \n",
    "토큰으로 나누는 단위는 설계에 따라 문장, 어절, 형태소, 서브워드, 문자, 자모/알파벳 등 다양한 방식으로 나눌 수 있다.   \n",
    "- 예\n",
    "```bash\n",
    "원문: \"자연어 처리는 재미있다\"\n",
    "토큰화: [\"자연어\", \"처리\", \"는\", \"재미있다\"]\n",
    "```\n",
    "\n",
    "## 토큰화 방식\n",
    "- **단어 기반 토큰화(Word-Level Tokenization)**\n",
    "    - 어절(공백으로 구분) 또는 형태소 단위로 단어를 나누는 전통적인 방식이다.\n",
    "    - **한국어**는 교착어로 하나의 단어에 다양한 조사/어미가 결합된다. 그래서 어절단위로 토큰화할 경우 어휘사전의 크기가 기하급수적으로 늘어나는 문제가 있다.\n",
    "      - 예) \"학교\", \"학교가\", \"학교를\", \"학교에\", \"학교에서\", \"학교로\", \"학교의\", ...\n",
    "    - 이로 인해 미등록어휘(OOV - Out of Vocabulary)의 증가, 같은 의미를 가지는 단어들이 Vocab에 중복 등록, 메모리 낭비, 학습효율성 저하 등 다양한 문제가 생긴다.\n",
    "    - 그래서 **한국어의 경우 형태소 단위 토큰화**가 필요하다.\n",
    "\n",
    "- **서브워드 기반(Subword-level) — BPE, WordPiece, Unigram**\n",
    "    - Transformer 기반 모델(BERT, GPT, LLaMA 등)에서 표준으로 사용하는 방식.\n",
    "    - 단어를 기준으로 토큰화하지 않고 **문자(character)와 단어(word)의 중간 수준인 서브워드(subword) 단위로 토큰화**한다.\n",
    "    - **동작 원리**:\n",
    "        - 자주 등장하는 문자열 조합(서브워드)을 하나의 토큰으로 구성한다.\n",
    "        - 빈도가 높은 단어는 하나의 토큰으로, 빈도가 낮거나 희귀한 단어는 여러 서브워드로 분할한다.\n",
    "    - **예시**:\n",
    "        ```bash\n",
    "        입력: \"나는 밥을 먹었습니다. 나는 어제 밥을 했습니다.\"\n",
    "        \n",
    "        서브워드 토큰화 결과 (예시):\n",
    "        [\"나는\", \"밥\", \"을\", \"먹\", \"었\", \"습니다\", \".\", \"나는\", \"어제\", \"밥\", \"을\", \"하\", \"었\", \"습니다\", \".\"]\n",
    "        ```\n",
    "    - **장점**:\n",
    "        - **미등록 단어(OOV) 문제 해결**: 모든 단어를 서브워드 조합으로 표현 가능\n",
    "        - **어휘 사전 크기 최적화**: 단어 단위보다 작고, 문자 단위보다 효율적\n",
    "        - **다국어 지원**: 언어에 구애받지 않는 범용적 토큰화\n",
    "        - **형태론적 의미 포착**: 접두사, 접미사 등의 의미를 학습 가능\n",
    "    - **주요 알고리즘**:\n",
    "        - **BPE (Byte Pair Encoding)**: 가장 빈번한 연속 바이트/문자 쌍을 반복적으로 병합\n",
    "        - **WordPiece**: BERT에서 사용, BPE와 유사하지만 likelihood 기반으로 병합\n",
    "        - **Unigram**: 확률 모델 기반으로 최적의 서브워드 분할 선택\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1a834",
   "metadata": {},
   "source": [
    "# 한국어 형태소 분석기\n",
    "\n",
    "- kiwipiepy와 konlpy 는 대표적인 한국어 형태소 분석기이다.\n",
    "\n",
    "## kiwipiepy\n",
    "**kiwipiepy**는 C++로 구현된 한국어 형태소 분석기 Kiwi(Korean Intelligent Word Identifier)를 Python 환경에서 사용할 수 있도록 한 라이브러리이다. \n",
    "\n",
    "- 빠른 속도  \n",
    "- 최신 품사 체계 지원  \n",
    "- 사용자 사전 확장 용이  \n",
    "- 최근 가장 널리 쓰이는 한국어 토크나이저 중 하나이다.\n",
    "- https://github.com/bab2min/kiwipiepy\n",
    "  \n",
    "### 설치 방법\n",
    "\n",
    "```bash\n",
    "pip install kiwipiepy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87abcc",
   "metadata": {},
   "source": [
    "### 주요 클래스 및 함수\n",
    "\n",
    "#### Kiwi 클래스\n",
    "- Kiwi의 핵심 클래스이며, 형태소 분석과 토큰화 기능을 모두 제공한다.\n",
    "- Kiwi 품사는 세종 말뭉치를 기반으로 한다.\n",
    "  - 품사 시작 글자\n",
    "  - 체언(명사, 대명사): `N`, 용언(동사, 형용사): `V`, 수식언(관형사, 부사): `M`,  관계언(조사):`J`, 어미: `E`, 기호: `S`\n",
    "    - https://github.com/bab2min/kiwipiepy?tab=readme-ov-file#%ED%92%88%EC%82%AC-%ED%83%9C%EA%B7%B8\n",
    "- 메소드\n",
    "  - `tokenzie(text)`: 형태소 분석 기반 토큰화 수행\n",
    "  - `analyze(text)`: tokenize보다 좀 더 상세한 분석을 진행한다. 여러 분석결과를 조회할 수있다.\n",
    "  - `add_user_word(word, pos, score)`: 사전에 직접 단어 등록\n",
    "  - `space(text)`: 띄어 쓰기 교정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd597bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b5064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d348d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877f1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be9aee9d",
   "metadata": {},
   "source": [
    "## KoNLPy(코엔엘파이)\n",
    "- KoNLPY는 한국어 자연어 처리(Natural Language Processing) 파이썬 라이브러리이다.  한국어 처리를 위한 tokenize, 형태소 분석, 어간추출, 품사부착(POS Tagging) 등의 기능을 제공한다. \n",
    "- http://KoNLPy.org/ko/latest/\n",
    "- 기존의 개발된 다양한 형태소 분석기를 통합해서 동일한 interface로 호출 할 수 있게 해준다.\n",
    "\n",
    "### KoNLPy 설치\n",
    "- 설치 순서\n",
    "  1. Java 실행환경 설치\n",
    "  2. JPype1 설치\n",
    "  3. koNLPy 설치\n",
    "\n",
    "1. **Java 설치**\n",
    "  - https://www.oracle.com/java/technologies/downloads/\n",
    "    - OS에 맞는 설치 버전을 다운받아 설치한다.\n",
    "    - MAC: ARM일 경우: **ARM64 CPU** - ARM64 DMG Installer, **Intel CPU**: x64 DMG Installer\n",
    "  - 시스템 환경변수 설정\n",
    "      - `JAVA_HOME` : 설치 경로 지정\n",
    "      - `Path` : `설치경로\\bin` 경로 지정\n",
    "\n",
    "2. **JPype1 설치**\n",
    "   - 파이썬에서 자바 모듈을 호출하기 위한 연동 패키지\n",
    "   - 설치: `pip install JPype1`\n",
    "\n",
    "3. **KoNLPy 설치**\n",
    "- `pip install konlpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a21250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c7d17",
   "metadata": {},
   "source": [
    "### 형태소 분석기/사전\n",
    "- 형태소 사전을 내장하고 있으며 형태소 분석 함수들을 제공하는 모듈\n",
    "\n",
    "#### KoNLPy 제공 형태소 분석기\n",
    "- Open Korean Text\n",
    "    - 트위터에서 개발\n",
    "    - https://github.com/open-korean-text/open-korean-text\n",
    "- Hannanum(한나눔)\n",
    "    - KAIST Semantic Web Research Center 에서 개발\n",
    "    - http://semanticweb.kaist.ac.kr/hannanum/\n",
    "- Kkma(꼬꼬마)\n",
    "    - 서울대학교 IDS(Intelligent Data Systems) 연구실 개발.\n",
    "    - http://kkma.snu.ac.kr/\n",
    "- Komoran(코모란)\n",
    "    - Shineware에서 개발.\n",
    "    - 오픈소스버전과 유료버전이 있음\n",
    "    - https://github.com/shin285/KOMORAN\n",
    "- Mecab(메카브) \n",
    "    - 일본어용 형태소 분석기를 한국에서 사용할 수 있도록 수정\n",
    "    - windows에서는 설치가 안됨\n",
    "    - https://bitbucket.org/eunjeon/mecab-ko\n",
    "\n",
    "\n",
    "### 형태소 분석기 공통 메소드\n",
    "- `morphs(string)` : 형태소 단위로 토큰화(tokenize)\n",
    "- `nouns(string)` : 명사만 추출하여 토큰화(tokenize)    \n",
    "- `pos(string)`: 품사 부착\n",
    "    - 형태소 분석기 마다 사용하는 품사태그가 다르다.\n",
    "        - https://konlpy-ko.readthedocs.io/ko/v0.5.2/morph/\n",
    "- `tagset`: 형태소 분석기가 사용하는 품사태그 설명하는 속성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a9426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a80e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471ba77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd51d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d66f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d26e26ee",
   "metadata": {},
   "source": [
    "# WordCloud\n",
    "\n",
    "WordCloud는 텍스트 데이터에서 단어의 등장 빈도를 시각적으로 표현한 그래픽이다.\n",
    "- 특징\n",
    "  - 자주 등장하는 단어일수록 글자 크기가 커진다.\n",
    "  - 텍스트 전체의 주제를 직관적으로 파악할 수 있다.\n",
    "  - 문서의 핵심키워드를 빠르게 파악할 수 있어 텍스트 분석에서 탐색적 데이터 분석(EDA) 단계에서 자주 활용된다.\n",
    "- 설치\n",
    "  - `pip install wordcloud`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b8a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088404c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9932a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81bd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
