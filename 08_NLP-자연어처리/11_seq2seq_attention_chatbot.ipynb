{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eebda4f9-a2f4-4af2-b1fb-36c01c48d8f0",
   "metadata": {
    "id": "eebda4f9-a2f4-4af2-b1fb-36c01c48d8f0"
   },
   "source": [
    "# Attention mechanism\n",
    "\n",
    "- Seq2Seq 모델의 문제점\n",
    "    - Seq2Seq 모델은 Encoder에서 입력 시퀀스에 대한 특성을 **하나의 고정된 context vector**에 압축하여 Decoder로 전달 한다. Decoder는 이 context vector를 이용해서 출력 시퀀스를 만든다.\n",
    "    1. 고정된 크기의 하나의 vector에 모든 입력 시퀀스의 정보를 넣다보니 정보 손실이 발생한다.\n",
    "    2. Decoder에서는 동일한 context vector를 기반으로 출력 시퀀스를 생성한다. 그러나 각 생성 토큰마다 입력 시퀀스에서 참조해야 할 중요도가 다를 수 있다. seq2seq는 encoder의 마지막 hidden state를 context로 받은 뒤 그것을 이용해 모든 출력 단어들을 생성하므로 그 중요도에 대한 반영이 안된다.\n",
    "\n",
    "## Attention Mechanism 아이디어\n",
    "-  Decoder에서 출력 단어를 예측하는 매 시점(time step)마다, Encoder의 입력 문장(context vector)을 다시 참고 하자는 것. 이때 전체 입력 문장의 단어들을 동일한 비율로 참고하는 것이 아니라, Decoder가 해당 시점(time step)에서 예측해야할 단어와 연관이 있는 입력 부분을 좀 더 집중(attention)해서 참고 할 수 있도록 하자는 것이 기본 아이디어이다.\n",
    "- 다양한 Attention 종류들이 있다.\n",
    "    -  Decoder에서 출력 단어를 예측하는 매 시점(time step)마다 Encoder의 입력 문장의 어느 부분에 더 집중(attention) 할지를 계산하는 방식에 따라 다양한 attention 기법이 있다.\n",
    "    -  `dot attention - Luong`, `scaled dot attention - Vaswani`, `general  attention - Luong`, `concat  attention - Bahdanau` 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ab8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f90ca7ae-e57f-4d14-a3de-19c26436f371",
   "metadata": {
    "id": "f90ca7ae-e57f-4d14-a3de-19c26436f371"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d5b90a",
   "metadata": {
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1748520205256,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "a9d5b90a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(f\"불러오지 못함: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db6fe689",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1748520205374,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "db6fe689",
    "outputId": "8f8193aa-1f3d-474a-fd1d-87319ec6dc60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12시 땡!   하루가 또 가네요.\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "4          PPL 심하네   눈살이 찌푸려지죠."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/chatbot_data.csv')\n",
    "df.drop(columns='label', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa1a1c-b942-4cad-948e-80c1bd768690",
   "metadata": {
    "id": "0aaa1a1c-b942-4cad-948e-80c1bd768690"
   },
   "source": [
    "# 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d23c37-f609-411b-aba2-17b081259cdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1748520205385,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "41d23c37-f609-411b-aba2-17b081259cdb",
    "outputId": "b8a2c779-40a5-4234-f4fc-3e87bdb1bf54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823, 11823)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_texts = df['Q']\n",
    "answer_texts = df['A']\n",
    "all_texts = list(question_texts + \" \"+answer_texts)\n",
    "len(question_texts), len(answer_texts), len(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ee480-100c-431c-8abd-1a63373b9950",
   "metadata": {
    "id": "c65ee480-100c-431c-8abd-1a63373b9950"
   },
   "source": [
    "## Tokenizer 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7704dca6-ec9e-48a7-8ad2-495c08aa9753",
   "metadata": {
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1748520206119,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "7704dca6-ec9e-48a7-8ad2-495c08aa9753"
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "vocab_size = 10_000\n",
    "min_frequency = 5\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=min_frequency,\n",
    "    continuing_subword_prefix='##',\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\", \"[EOS]\"]\n",
    "    # [SOS]: 문장의 시작을 의미하는 토큰. [EOS]: 문장이 끝난 것을 표시.\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0097d1d-7d62-4c81-9c09-db61741ffefc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748520206127,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "a0097d1d-7d62-4c81-9c09-db61741ffefc",
    "outputId": "a7874e00-a4ae-440d-f7c1-8cc965bd0989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘수: 7041\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e8d72-a052-46a3-8396-e4b4c480de31",
   "metadata": {
    "id": "175e8d72-a052-46a3-8396-e4b4c480de31"
   },
   "source": [
    "## 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fac5977-edbe-4c64-b0dc-0c1ee0bb4ec3",
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1748520206128,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "2fac5977-edbe-4c64-b0dc-0c1ee0bb4ec3"
   },
   "outputs": [],
   "source": [
    "dir_path = \"saved_model/chatbot_attn\"\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "vocab_path = os.path.join(dir_path, \"chatbot_attn_bpe.json\")\n",
    "tokenizer.save(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cf727-4a41-4e09-8bf2-74f599d86ddc",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748520206130,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "835cf727-4a41-4e09-8bf2-74f599d86ddc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dc1557b-9a3a-4c34-b19b-7d4106fe2132",
   "metadata": {
    "id": "4dc1557b-9a3a-4c34-b19b-7d4106fe2132"
   },
   "source": [
    "# Dataset 생성\n",
    "- 한문장 단위로 학습시킬 것이므로 DataLoader를 생성하지 않고 Dataset에서 index로 조회한 질문-답변을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd3ef9-4ad8-434d-9792-10d1ff75b53f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 4930,
     "status": "ok",
     "timestamp": 1748520211061,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "21fd3ef9-4ad8-434d-9792-10d1ff75b53f",
    "outputId": "51f60516-37ae-43a9-ecd5-e3fac6c1f504"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227ada0-16f7-43cd-8d2f-17bd6b03b260",
   "metadata": {
    "id": "9227ada0-16f7-43cd-8d2f-17bd6b03b260"
   },
   "source": [
    "### Dataset 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02b67e-6be9-42ea-ba21-c8d669e8101b",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748520211075,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "9a02b67e-6be9-42ea-ba21-c8d669e8101b"
   },
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    Attribute\n",
    "        max_length\n",
    "        tokenizer: Tokenizer\n",
    "        vocab_size: int - Tokenizer에 등록된 총 어휘수\n",
    "        SOS: int - [SOS] 문장의 시작 토큰 id\n",
    "        EOS: int = [EOS] 문장의 끝 토큰 id\n",
    "        question_squences: list - 모든 질문 str을 token_id_list(token sequence) 로 변환하여 저장한 list\n",
    "        answser_sequences: list - 모든 답변 str을 token_id_list(token sequence) 로 변환하여 저장한 list.\n",
    "    \"\"\"\n",
    "    def __init__(self, question_texts, answer_texts, tokenizer, min_length=2, max_length=20):\n",
    "        \"\"\"\n",
    "        question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "        answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\",   \"답2\",   ...]\n",
    "        tokenizer: Tokenizer\n",
    "        min_length=2: int - 최소 토큰 개수. 질문과 답변의 token수가 min_length 이상인 것만 학습한다.\n",
    "        max_length=20:int 개별 댓글의 token 개수. 모든 댓글의 토큰수를 max_length에 맞춘다.\n",
    "        \"\"\"\n",
    "        self.min_length = min_length\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.vocab_size = tokenizer.get_vocab_size()\n",
    "        self.SOS = self.tokenizer.token_to_id('[SOS]')\n",
    "        self.EOS = self.tokenizer.token_to_id('[EOS]')\n",
    "\n",
    "        self.question_sequences = []\n",
    "        self.answer_sequences = []\n",
    "        for q, a in zip(question_texts, answer_texts):\n",
    "            q_token = self.__process_sequence(q)\n",
    "            a_token = self.__process_sequence(a)\n",
    "            \n",
    "            if len(q_token) > min_length and len(a_token) > min_length:\n",
    "                self.question_sequences.append(q_token)\n",
    "                self.answer_sequences.append(a_token)\n",
    "\n",
    "    def __add_special_tokens(self, token_sequence):\n",
    "        \"\"\"\n",
    "        질문/답변 토큰 리스트 맨 뒤에 문장의 끝을 표시하는 [EOS] 토큰 추가.\n",
    "        [EOS] Token을 붙이고 max_length 보다 토큰수가 많으면 안된다.\n",
    "        Args:\n",
    "            token_sequence (list[str]) - EOS 토큰을 추가할 문서 token sequence\n",
    "        \"\"\"\n",
    "\n",
    "        token_id_list = token_sequence[:self.max_length-1]\n",
    "        token_id_list.append(self.EOS)\n",
    "\n",
    "        return token_id_list\n",
    "\n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한 문장 string을 받아서 encoding 한 뒤 [EOS] token을 추가한 token_id 리스트(list)를 생성 해서 반환한다.\n",
    "        Args:\n",
    "            text (str) - token id 리스트로 변환할 대상 String.\n",
    "        \"\"\"\n",
    "\n",
    "        encode = self.tokenizer.encode(text)\n",
    "        token_ids = self.__add_special_tokens(encode.ids)\n",
    "        return token_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.question_sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        q = torch.tensor(self.question_sequences[index], dtype=torch.int64).unsqueeze(1)\n",
    "        a = torch.tensor(self.answer_sequences[index], dtype=torch.int64).unsqueeze(1)\n",
    "        return q, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2221b-bd39-4fc1-8d2a-2b3bd9ef5718",
   "metadata": {
    "id": "99f2221b-bd39-4fc1-8d2a-2b3bd9ef5718"
   },
   "source": [
    "### Dataset 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c277360c-705b-42b1-8ea2-e9f9aaca4d75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1748520211557,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "c277360c-705b-42b1-8ea2-e9f9aaca4d75",
    "outputId": "c0e8d628-fbe6-4792-dbf5-e9433add1a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11713\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 20\n",
    "MIN_LENGTH = 2\n",
    "dataset = ChatbotDataset(question_texts, answer_texts, tokenizer, MIN_LENGTH, MAX_LENGTH)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c9392-001c-49a9-9b5b-7252531aa713",
   "metadata": {
    "id": "920c9392-001c-49a9-9b5b-7252531aa713"
   },
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8af63e-d915-4832-840e-44a07a53cdad",
   "metadata": {
    "id": "4e8af63e-d915-4832-840e-44a07a53cdad"
   },
   "source": [
    "## Encoder\n",
    "- seq2seq 모델과 동일 한 구조\n",
    "    - 이전 코드(seq2seq)와 비교해서 forward()에서 입력 처리는 token 하나씩 하나씩 처리한다.\n",
    "\n",
    "![encoder](figures/attn_encoder-network_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a20f4-aab2-4ab0-a271-f23063d7ea30",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1748520211574,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "c07a20f4-aab2-4ab0-a271-f23063d7ea30"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_vocabs: int - 총 어휘수\n",
    "            hidden_size: int - GRU의 hidden size\n",
    "            embedding_dim: int - Embedding vector의 차원수\n",
    "            num_layers: int - GRU의 layer수\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_vocabs = num_vocabs\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        질문의 token한개의 토큰 id를 입력받아 hidden state를 출력\n",
    "\n",
    "        Args:\n",
    "            x: 한개 토큰. shape-[1]\n",
    "            hidden: hidden state (이전 처리결과). shape: [1, 1, hidden_size]\n",
    "        Returns\n",
    "            tuple: (output, hidden) - output: [1, 1, hidden_size],  hidden: [1, 1, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        embedded = self.embedding(x).unsqueeze(0) # (1: batch, embedding_dim)-> (1: batch, 1:seq_len, embedding_dim)\n",
    "        out, hidden = self.gru(embedded, hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, device):\n",
    "        \"\"\"\n",
    "        처음 timestep에서 입력할 hidden_state.\n",
    "        값: 0\n",
    "        shape: (Bidirectional(1) x number of layers(1), batch_size: 1, hidden_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53312985",
   "metadata": {
    "id": "53312985"
   },
   "source": [
    "## Attention 적용 Decoder\n",
    "![seq2seq attention outline](figures/attn_seq2seq_attention_outline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8d821-0c0d-4089-b0a8-88f0d37cf014",
   "metadata": {
    "id": "75f8d821-0c0d-4089-b0a8-88f0d37cf014"
   },
   "source": [
    "- Attention은 Decoder 네트워크가 순차적으로 다음 단어를 생성하는 자기 출력의 모든 단계에서 인코더 출력 중 연관있는 부분에 **집중(attention)** 할 수 있게 한다.\n",
    "- 다양한 어텐션 기법중에 **Luong attention** 방법은 다음과 같다.\n",
    "  \n",
    "![attention decoder](figures/attn_decoder-network_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b7ddf-6e4d-4358-82f3-375d89544ce0",
   "metadata": {
    "id": "5c8b7ddf-6e4d-4358-82f3-375d89544ce0"
   },
   "source": [
    "### Attention Weight\n",
    "- Decoder가 현재 timestep의 단어(token)을 생성할 때 Encoder의 output 들 중 어떤 단어에 좀더 집중해야 하는지 계산하기 위한 가중치값.\n",
    "  \n",
    "![Attention Weight](figures/attn_attention_weight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349ed00-d090-49c3-bcf5-9792e28efdf8",
   "metadata": {
    "id": "4349ed00-d090-49c3-bcf5-9792e28efdf8"
   },
   "source": [
    "### Attention Value\n",
    "- Decoder에서 현재 timestep의 단어를 추출할 때 사용할 Context Vector.\n",
    "    - Encoder의 output 들에 Attention Weight를 곱한다.\n",
    "    - Attention Value는 Decoder에서 단어를 생성할 때 encoder output의 어떤 단어에 더 집중하고 덜 집중할지를 가지는 값이다.\n",
    "\n",
    "![attention value](figures/attn_attention_value.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29166d33-991d-406a-85d1-ce6575f78146",
   "metadata": {
    "id": "29166d33-991d-406a-85d1-ce6575f78146"
   },
   "source": [
    "### Feature Extraction\n",
    "- Decoder의 embedding vector와 Attention Value 를 합쳐 RNN(GRU)의 입력을 만든다.\n",
    "    - **단어를 생성하기 위해 이전 timestep에서 추론한 단어(현재 timestep의 input)** 와 **Encoder output에 attention이 적용된 값** 이 둘을 합쳐 입력한다.\n",
    "    - 이 값을 Linear Layer함수+ReLU를 이용해 RNN input_size에 맞춰 준다. (어떻게 input_size에 맞출지도 학습시키기 위해 Linear Layer이용)\n",
    "\n",
    "![rnn](figures/att_attention_combine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e7805-2809-48d8-a9b7-547c3f571c68",
   "metadata": {
    "id": "db2e7805-2809-48d8-a9b7-547c3f571c68"
   },
   "source": [
    "### 단어 예측(생성)\n",
    "- RNN에서 찾은 Feature를 총 단어개수의 units을 출력하는 Linear에 입력해 **다음 단어를 추론한다.**\n",
    "- 추론한 단어는 다음 timestep의 입력($X_t$)으로 RNN의 hidden은 다음 timestep 의 hidden state ($h_{t-1}$) 로 입력된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653c5e5-bf2f-47ac-aa2e-63363a131e57",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1748520211607,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "9653c5e5-bf2f-47ac-aa2e-63363a131e57"
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, dropout_p, max_length):\n",
    "       \n",
    "        super().__init__()\n",
    "        self.num_vocabs = num_vocabs\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        self.attn = nn.Linear(hidden_size+embedding_dim, max_length)\n",
    "        self.attn_combine = nn.Linear(embedding_dim+hidden_size, hidden_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_vocabs)\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        Parameter\n",
    "            x: 현재 timestep의 입력 토큰(단어) id\n",
    "            hidden: 이전 timestep 처리결과 hidden state\n",
    "            encoder_outputs: Encoder output들.\n",
    "        Return\n",
    "            tupe: (output, hidden, attention_weight)\n",
    "                output: 단어별 다음 단어일 확률.  shape: [vocab_size]\n",
    "                hidden: hidden_state. shape: [1, 1, hidden_size]\n",
    "                atttention_weight: Encoder output 중 어느 단어에 집중해야하는 지 가중치값. shape: [1, max_length]\n",
    "\n",
    "        현재 timestep 입력과 이전 timestep 처리결과를 기준으로 encoder_output와 계산해서  encoder_output에서 집중(attention)해야할 attention value를 계산한다.\n",
    "        attention value와 현재 timestep 입력을 기준으로 단어를 추론(생성) 한다.\n",
    "        \"\"\"\n",
    "\n",
    "        embedding = self.embedding(x).unsqueeze(0)\n",
    "        embedding = self.dropout(embedding)\n",
    "\n",
    "        attn_in = torch.concat((embedding[0], hidden[0]), dim=1)\n",
    "        attn_score = self.attn(attn_in)\n",
    "\n",
    "        attn_weight = nn.Softmax(dim=-1)(attn_score)\n",
    "\n",
    "        attn_value = torch.bmm(\n",
    "            attn_weight.unsqueeze(0),\n",
    "            encoder_outputs.unsqueeze(0),\n",
    "        )\n",
    "        \n",
    "        attn_combine_in = torch.concat(\n",
    "            [attn_value[0], embedding[0]], \n",
    "            dim=1\n",
    "        )\n",
    "        gru_in = self.attn_combine(attn_combine_in)\n",
    "        gru_in = gru_in.unsqueeze(0)\n",
    "        gru_in = nn.ReLU()(gru_in)\n",
    "        \n",
    "        out, hidden_state = self.gru(gru_in, hidden)\n",
    "\n",
    "        last_out = self.classifier(out[0])\n",
    "        \n",
    "        return last_out[0], hidden_state, attn_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598b81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab7c43d-3691-4723-8051-7bc0a8a4a37e",
   "metadata": {
    "id": "fab7c43d-3691-4723-8051-7bc0a8a4a37e"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75080eb6-da0e-4c86-998e-2dd8405e5a8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748520213121,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "75080eb6-da0e-4c86-998e-2dd8405e5a8c",
    "outputId": "b5fe1c70-dabf-441a-de3b-6999d9ec6522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "SOS_TOKEN = dataset.tokenizer.token_to_id(\"[SOS]\")\n",
    "EOS_TOKEN = dataset.tokenizer.token_to_id(\"[EOS]\")\n",
    "print(SOS_TOKEN, EOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53184448-56e5-4c3c-8d6c-3f8f93d45076",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748520213122,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "53184448-56e5-4c3c-8d6c-3f8f93d45076"
   },
   "outputs": [],
   "source": [
    "# 한개 question-answer 쌍을 받아서 학습\n",
    "def train(\n",
    "        input_tensor,\n",
    "        target_tensor,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        encoder_optimizer,\n",
    "        decoder_optimizer,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        max_length,\n",
    "        teacher_forcing_ratio=0.9):\n",
    "\n",
    "\n",
    "    input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
    "    loss = 0.0 # loss값 저장할 변수.\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Encoder 처리\n",
    "    encoder_hidden = encoder.init_hidden(device)\n",
    "\n",
    "    # 질문/답변의 length(토큰수)를 조회\n",
    "    input_length = input_tensor.shape[0]\n",
    "    output_length = target_tensor.shape[0]\n",
    "\n",
    "    # encoder hidden state들을 저장할 tensor를 정의\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    for e_idx in range(input_length):\n",
    "        encoder_out, encoder_hidden = encoder(input_tensor[e_idx], encoder_hidden)\n",
    "        encoder_outputs[e_idx] = encoder_out\n",
    "\n",
    "\n",
    "    decoder_input = torch.tensor([SOS_TOKEN], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # teacher_forcing 여부\n",
    "    teacher_forcing = True if teacher_forcing_ratio > random.random() else False\n",
    "\n",
    "    for d_idx in range(output_length):\n",
    "        decoder_out, decoder_hidden, attn_weight = decoder(decoder_input,\n",
    "                                                           decoder_hidden,\n",
    "                                                           encoder_outputs)\n",
    "        \n",
    "        loss += loss_fn(decoder_out.unsqueeze(0), target_tensor[d_idx])\n",
    "\n",
    "        if teacher_forcing:\n",
    "            decoder_input = target_tensor[d_idx]\n",
    "        else:\n",
    "            output_token = decoder_out.argmax(dim=-1).unsqueeze(0)\n",
    "            decoder_input = output_token.detach() # Tensor.detach(): gradient 계산그래프에서 제외.\n",
    "\n",
    "        teacher_forcing_ratio *= 0.99\n",
    "\n",
    "        if decoder_input == EOS_TOKEN:\n",
    "            break\n",
    "    \n",
    "    # 순전파가 완료 (질문 -> 답변) ==> 역전파 gradient 계산->파라미터 업데이트\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # loss 평균 반환\n",
    "    return loss.item() / output_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824a9fb-1592-44f4-8a74-6c5098bd5776",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748520213135,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "6824a9fb-1592-44f4-8a74-6c5098bd5776"
   },
   "outputs": [],
   "source": [
    "def train_iterations(\n",
    "        encoder, decoder, n_iters,\n",
    "        dataset, device, log_interval=1000, learning_rate=0.001):\n",
    "        \n",
    "        # encoder/decoder 모델을 train 모드로 변환\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        print_loss = 0.0\n",
    "\n",
    "        # 옵티마이저 생성\n",
    "        encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "        decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "        \n",
    "        #loss 함수\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # 학습 시킬 데이터를 sampling\n",
    "        data_length = len(dataset)\n",
    "        train_data = [dataset[random.randint(0, data_length-1)]   for i in range(n_iters)]\n",
    "\n",
    "        # 학습-train\n",
    "        s = time.time()\n",
    "        for idx in range(n_iters):\n",
    "            input_tensor, target_tensor = train_data[idx]\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                         encoder_optimizer, decoder_optimizer, loss_fn,\n",
    "                         device, max_length=MAX_LENGTH\n",
    "                        )\n",
    "            print_loss += loss\n",
    "            if (idx+1) % log_interval == 0:\n",
    "                print(f\"{idx+1}개 QA상 학습: loss - {print_loss/log_interval:.5f}\")\n",
    "                print_loss = 0.0\n",
    "\n",
    "        e = time.time()\n",
    "        print(f'학습에 걸린 시간: {e-s}초')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "619381e8",
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1748520213191,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "619381e8"
   },
   "outputs": [],
   "source": [
    "NUM_VOCABS = tokenizer.get_vocab_size()\n",
    "HIDDEN_SIZE = 200\n",
    "EMBEDDING_DIM = 256\n",
    "DROPOUT_P = 0.2\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "encoder = Encoder(NUM_VOCABS, HIDDEN_SIZE, EMBEDDING_DIM, 1)\n",
    "decoder = AttentionDecoder(NUM_VOCABS, HIDDEN_SIZE, EMBEDDING_DIM, DROPOUT_P, MAX_LENGTH)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f0b92dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559954,
     "status": "ok",
     "timestamp": 1748523006835,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "0f0b92dd",
    "outputId": "113cbe94-64bf-4e68-fd93-533f787d3a12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000개 QA상 학습: loss - 5.42293\n",
      "10000개 QA상 학습: loss - 4.63801\n",
      "15000개 QA상 학습: loss - 4.08139\n",
      "20000개 QA상 학습: loss - 3.63192\n",
      "25000개 QA상 학습: loss - 3.34507\n",
      "30000개 QA상 학습: loss - 3.09353\n",
      "35000개 QA상 학습: loss - 2.87331\n",
      "40000개 QA상 학습: loss - 2.71091\n",
      "45000개 QA상 학습: loss - 2.60181\n",
      "50000개 QA상 학습: loss - 2.45977\n",
      "55000개 QA상 학습: loss - 2.31914\n",
      "60000개 QA상 학습: loss - 2.18458\n",
      "65000개 QA상 학습: loss - 2.20216\n",
      "70000개 QA상 학습: loss - 2.08174\n",
      "75000개 QA상 학습: loss - 2.03243\n",
      "80000개 QA상 학습: loss - 1.95812\n",
      "85000개 QA상 학습: loss - 1.91129\n",
      "90000개 QA상 학습: loss - 1.83171\n",
      "95000개 QA상 학습: loss - 1.80591\n",
      "100000개 QA상 학습: loss - 1.77724\n",
      "105000개 QA상 학습: loss - 1.72594\n",
      "110000개 QA상 학습: loss - 1.67589\n",
      "학습에 걸린 시간: 2758.285502910614초\n"
     ]
    }
   ],
   "source": [
    "n_iters = 110_000\n",
    "log_interval = 5000\n",
    "train_iterations(encoder, decoder, n_iters, dataset, device, log_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564cd1f5-0f7f-4271-9143-87b978d8e376",
   "metadata": {
    "id": "564cd1f5-0f7f-4271-9143-87b978d8e376"
   },
   "source": [
    "## Model 생성, 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f416fa1-0a38-4a60-9c02-41261fab6cb0",
   "metadata": {
    "id": "2f416fa1-0a38-4a60-9c02-41261fab6cb0"
   },
   "source": [
    "## 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b436b71-3cf4-45e2-9418-00555e55d82a",
   "metadata": {
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1748523007688,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "7b436b71-3cf4-45e2-9418-00555e55d82a"
   },
   "outputs": [],
   "source": [
    "#토크나이저, 인코더, 디코더 저장\n",
    "root_path = \"saved_model/chatbot_attn\"\n",
    "# root_path = r\"/content/drive/MyDrive/deeplearning/saved_model/chatbot_attn\"\n",
    "os.makedirs(root_path,  exist_ok=True)\n",
    "\n",
    "tokenizer_path = os.path.join(root_path, \"tokenizer.json\")\n",
    "encoder_path = os.path.join(root_path, \"encoder_model.pt\")\n",
    "decoder_path = os.path.join(root_path, \"decoder_model.pt\")\n",
    "\n",
    "tokenizer.save(tokenizer_path)\n",
    "torch.save(encoder, encoder_path)\n",
    "torch.save(decoder, decoder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae49d34-7308-493d-95a4-eef87c361d33",
   "metadata": {
    "id": "6ae49d34-7308-493d-95a4-eef87c361d33"
   },
   "source": [
    "## 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e95558-b4ed-4676-a23a-796cf0cfa27e",
   "metadata": {
    "id": "d5e95558-b4ed-4676-a23a-796cf0cfa27e"
   },
   "outputs": [],
   "source": [
    "# root_path = \"saved_model/chatbot_attn\"\n",
    "root_path = r\"/content/drive/MyDrive/deeplearning/saved_model/chatbot_attn\"\n",
    "\n",
    "# os.makedirs(root_path,  exist_ok=True)\n",
    "\n",
    "tokenizer_path = os.path.join(root_path, \"tokenizer.json\")\n",
    "encoder_path = os.path.join(root_path, \"encoder_model.pt\")\n",
    "decoder_path = os.path.join(root_path, \"decoder_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8038aca1-7a9e-464a-8558-957a498248a9",
   "metadata": {
    "id": "8038aca1-7a9e-464a-8558-957a498248a9"
   },
   "outputs": [],
   "source": [
    "# 저장된 모델 Load\n",
    "tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "encoder = torch.load(encoder_path, weights_only=False, map_location=device)\n",
    "decoder = torch.load(decoder_path, weights_only=False, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b25ff9-0854-4583-b4f2-0dbc84e63e09",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1748523049987,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "52b25ff9-0854-4583-b4f2-0dbc84e63e09"
   },
   "outputs": [],
   "source": [
    "SOS_TOKEN = tokenizer.token_to_id('[SOS]')\n",
    "EOS_TOKEN = tokenizer.token_to_id('[EOS]')\n",
    "def evaluate(encoder, decoder, input_tensor, dataset, device, max_length):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.shape[0]\n",
    "        encoder_hidden = encoder.init_hidden(device)\n",
    "\n",
    "        # encoder의 hidden state들을 모을 텐서 생성\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        # encoder 실행\n",
    "        for e_index in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[e_index], encoder_hidden)\n",
    "            encoder_outputs[e_index] = encoder_output[0, 0]\n",
    "\n",
    "        # decoder 실행\n",
    "        decoder_input = torch.tensor([SOS_TOKEN], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # 결과를 저장할 리스트\n",
    "        decoded_words = []\n",
    "        decoder_attn_weights = []\n",
    "\n",
    "        for d_index in range(max_length):\n",
    "            decoder_output, decoder_hidden, attn_weight = decoder(decoder_input,\n",
    "                                                                  decoder_hidden,\n",
    "                                                                  encoder_outputs)\n",
    "            decoder_attn_weights.append(attn_weight.data)\n",
    "\n",
    "            topv, topi  = decoder_output.data.topk(1)\n",
    "\n",
    "            if topi.item() == EOS_TOKEN:\n",
    "                decoded_words.append('[EOS]')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(dataset.tokenizer.id_to_token(topi.item()))\n",
    "            decoder_input = topi.detach()\n",
    "\n",
    "    return decoded_words, decoder_attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33d28a-5414-4d8e-8919-730109adfd77",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748523051233,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "6e33d28a-5414-4d8e-8919-730109adfd77"
   },
   "outputs": [],
   "source": [
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('##')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 ##는 내 ##꺼 #야\" ==> \"이 기회는 내꺼야\"\n",
    "\n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열.\n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = decoded_string.split()\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"):\n",
    "            if new_tokens:\n",
    "                \n",
    "                new_tokens[-1] += token[2:]\n",
    "            else:\n",
    "                new_tokens.append(token[2:])\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "\n",
    "    return \" \".join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9451766-9127-47ed-b844-db9c71d1b47b",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748523053099,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "c9451766-9127-47ed-b844-db9c71d1b47b"
   },
   "outputs": [],
   "source": [
    "def evaluate_randomly(encoder, decoder, dataset, device, n=10):\n",
    "    # n개 확인.\n",
    "    for i in range(n):\n",
    "        idx = random.randint(0, len(dataset))\n",
    "        x, y = dataset[idx]\n",
    "        q = dataset.tokenizer.decode(x.flatten().tolist())\n",
    "        a = dataset.tokenizer.decode(y.flatten().tolist())\n",
    "        print(\"질문(정답):\", handle_special_tokens(q))\n",
    "        print(\"답변(정답):\", handle_special_tokens(a))\n",
    "\n",
    "        # 추론\n",
    "        output_words, atten_weights = evaluate(encoder, decoder,\n",
    "                                              x.to(device),\n",
    "                                              dataset, device, MAX_LENGTH)\n",
    "        \n",
    "        output_sentence = ' '.join(output_words[:-1])\n",
    "        print(\"답변(예측):\", handle_special_tokens(output_sentence))\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41a6557b-7b69-4e2f-93af-9eb38621b158",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1748523100742,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "41a6557b-7b69-4e2f-93af-9eb38621b158",
    "outputId": "c99ffa0f-b0ba-4baf-dc80-88c5b67d60c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문(정답): 먼저 고백하는 게 좋을까\n",
      "답변(정답): 고백하는 게 좋지만 슬쩍 호감을 표현해보세요 .\n",
      "답변(예측): 항상 너무나 있다는 확신 .\n",
      "==================================================\n",
      "질문(정답): 나한테 관심 있는게 맞을까 ?\n",
      "답변(정답): 직접적이든 간접적이든 의사를 확실히 밝혀보세요 .\n",
      "답변(예측): 직접 물어보는 게 거 같아요 .\n",
      "==================================================\n",
      "질문(정답): 잘 살겠지 라고 생각하자\n",
      "답변(정답): 더 잘 살 수 있을 거예요 .\n",
      "답변(예측): 다 잘 될 거예요 .\n",
      "==================================================\n",
      "질문(정답): 군인이라 슬프네 .\n",
      "답변(정답): 전역해서 더 좋은 사람 만날 수 있을 거예요 .\n",
      "답변(예측): 무셔망 수 있을 거예요 .\n",
      "==================================================\n",
      "질문(정답): 계속 생각나는 사람 .\n",
      "답변(정답): 사랑했던 만큼 생각나겠죠 .\n",
      "답변(예측): 그게 진짜 사랑했나봐요 .\n",
      "==================================================\n",
      "질문(정답): 사표 낼까 ?\n",
      "답변(정답): 뒷감당은 준비하세요 .\n",
      "답변(예측): 안 그럴 수도 있을 거예요 .\n",
      "==================================================\n",
      "질문(정답): 남자친구랑 말이 안 통해\n",
      "답변(정답): 답답하겠네요 .\n",
      "답변(예측): 무슨 말을 할 수 있을 거예요 .\n",
      "==================================================\n",
      "질문(정답): 그녀의 남자사진을 봤습니다\n",
      "답변(정답): 원하던게 아니었을텐데 씁쓸했겠어요 .\n",
      "답변(예측): 마음의 정리가 아직이야 봐요 .\n",
      "==================================================\n",
      "질문(정답): 돈 가지고 유세부려\n",
      "답변(정답): 없다가 있어서 그런가봐요 .\n",
      "답변(예측): 의지쪽 아니라 제가 있잖아요 .\n",
      "==================================================\n",
      "질문(정답): 기다리는 것도 지쳐\n",
      "답변(정답): 기다리지 마세요 .\n",
      "답변(예측): 잘 생각해보세요 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(encoder, decoder, dataset, device, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e2587-ed54-4b58-b8d3-9c3b1dd4b60e",
   "metadata": {
    "id": "f08e2587-ed54-4b58-b8d3-9c3b1dd4b60e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
