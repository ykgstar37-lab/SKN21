{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11d06f2",
   "metadata": {},
   "source": [
    "# 전처리의 개념과 필요성\n",
    "\n",
    "## 전처리의 정의\n",
    "\n",
    "자연어 처리에서 전처리(preprocessing) 란, 현실에서 수집한 원시 텍스트 데이터를 기계 학습 알고리즘이나 언어 모델이 다루기 좋은 형태로 변환하는 일련의 과정을 의미한다.\n",
    "\n",
    "원시 텍스트에는 다음과 같은 요소가 섞여 있는 경우가 많다.\n",
    "- 오타, 반복 문자, 과도한 이모티콘\n",
    "  - 예: ㅋㅋㅋㅋㅋㅋ, ㅠㅠㅠㅠ, 대박이에요요요\n",
    "- HTML이나 XML 태그\n",
    "- URL, 이메일, 전화번호, @아이디, 해시태그\n",
    "  - 예: https://..., user@example.com, @someone, #자연어처리\n",
    "- 광고성 문구나 메타 정보\n",
    "- 띄어쓰기 오류와 중복 공백\n",
    "\t-\t예: \"안녕하세요오늘날씨좋네요\"\n",
    "\n",
    "전처리는 이러한 요소들 중 분석에 불필요하거나 방해가 되는 부분을 제거 또는 치환하면서도, 텍스트가 가지는 의미 정보는 최대한 보존하는 것을 목표로 한다.\n",
    "\n",
    "\n",
    "## 전처리의 주요 단계\n",
    "\n",
    "실제 한국어 텍스트를 다룰 때 자주 사용되는 전처리 단계는 다음과 같이 정리할 수 있다.\n",
    "1. 기본적인 정규화(Basic normalization)\n",
    "   - **정규화 란 텍스트를 일관된 형태로 통일하는 모든 작업**\n",
    "   - 문자열 양쪽 공백 제거, 중복 공백 축소\n",
    "     - \"안녕&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;하세요\" → \"안녕 하세요\"\n",
    "   - 필요 시 대소문자 통일(영어 포함 시)\n",
    "   - 반복 문자 정규화\n",
    "     - \"ㅋㅋㅋㅋㅋㅋ\" → \"ㅋㅋㅋ\" 또는 제거\n",
    "     - \"!!!!!\" → \"!\"\n",
    "   - 숫자 표현 통일\n",
    "     - \"1,000원\", \"1000원\"을 통일.\n",
    "    - 어간/표제어 추출(stemming/lemmatization): \"가다, 가고, 갔다\"를 \"가\"로 통일하는 작업이다.\n",
    "      > - 표제어(lemma): 기본 사전형 형태\n",
    "      > - 어간: 활용어가 활용할 때 변하지 않는 부분. (보다, 보니, 보고 에서 **보**)\n",
    "2. 패턴 기반 노이즈 제거\n",
    "   - HTML 태그 제거\n",
    "   - URL, 이메일, 전화번호 패턴 제거 혹은 <URL>, <EMAIL> 등으로 치환\n",
    "   - 광고성 문구나 메타 데이터 제거\n",
    "3. 띄어쓰기 교정\n",
    "   - 한국어에서는 띄어쓰기 오류가 잦으므로, 자동 교정기를 이용해 띄어쓰기를 보정.\n",
    "4. 문장 분리(sentence segmentation)\n",
    "    - 문단 혹은 문서 전체를 문장 단위로 분리한다.\n",
    "    - 구두점 기반으로 분리하거나 형태소 정보와 규칙을 활용하는 한국어 전용 문장 분리기를 사용할 수 있다.\n",
    "5. 토큰화(tokenization)\n",
    "   - 전처리된 각 문장을 토큰(token)의 시퀀스으로 변환한다.\n",
    "      - 토큰(Token)은 **텍스트를 의미 있는 최소 단위로 쪼갠 조각**을 말한다. 쉽게 말해 문장을 분석 가능한 작은 단위로 나눈 것\n",
    "   - **토큰 단위**는 단어, 형태소, 서브워드, 문자, 자모(字母) 등 다양한 단위를 가질 수 있다.\n",
    "   - 한국어에서는 텍스트 이해를 위한 문제 영역에서는 보통 **형태소 단위 토큰화**가 널리 사용되고 있다. \n",
    "   - 텍스트 생성 영역에서는 **서브워드 방식의 토큰화**가 보통 사용된다.\n",
    "6. 추가 전처리 작업\n",
    "   - 불용어(stopwords) 제거: 조사, 접속사 등 **자주 등장하지만 의미 분석에는 크게 기여하지 않는 단어**를 제거.\n",
    "   - 품사 기반 필터링: 명사, 동사, 형용사와 같이 주요 품사만 남기고 나머지를 제거하는 전략.\n",
    "\n",
    "\n",
    "### 전처리의 주요 도구\n",
    "- **정규표현식(regular expression)** 은 전처리 과정에서 패턴 기반 정제, 토큰화 작업을 진행하는 데 유용하게 사용할 수 있다.\n",
    "- 정규 표현식만으로는 텍스트 전처리에 한계가 있기 때문에 다양한 전문 라이브러리가 함께 사용된다.\n",
    "  - 한글\n",
    "    - [KoNLPy](https://konlpy.org/ko/latest/)\n",
    "    - [KiwiPiePy](https://github.com/bab2min/kiwipiepy)\n",
    "    - [soynlp](https://github.com/lovit/soynlp)\n",
    "  \n",
    "  - 영문\n",
    "    - [NLTK](https://www.nltk.org/)\n",
    "    - [spaCy](https://spacy.io/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
