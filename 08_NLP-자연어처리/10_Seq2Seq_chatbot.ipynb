{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {},
   "source": [
    "# Encoder–Decoder 구조\n",
    "\n",
    "- Encoder–Decoder 구조는 어떤 형태의 입력 시퀀스를 받아 **의미를 해석**한 뒤, 새로운 **출력 시퀀스를 생성**해야 하는 거의 모든 AI 문제를 해결하는 딥러닝 모델 구조다.\n",
    "- 이 구조는 Encoder와 Decoder 두개의 딥러닝 모델을 연결한 구조로 **입력 데이터를 하나의 표현으로 압축한 뒤, 이를 다시 출력 데이터로 변환하는 방식**으로 동작한다.\n",
    "\n",
    "- **Encoder Network**\n",
    "  - 입력 데이터를 해석(이해)하는 역할을 수행한다.\n",
    "  - 입력 시퀀스에 담긴 의미적 정보를 하나의 고정된 벡터 형태로 요약한다.\n",
    "\n",
    "- **Decoder Network**\n",
    "  - Encoder가 생성한 요약 정보를 바탕으로 최종 출력을 생성한다.\n",
    "  - 즉, Encoder의 “이해 결과”를 이용해 새로운 시퀀스를 만들어낸다.\n",
    "\n",
    "## Seq2Seq (Sequence-to-Sequence)\n",
    "\n",
    "Seq2Seq 모델은 **Encoder–Decoder 구조를 RNN(Recurrent Neural Network) 계열에 적용한 대표적인 시퀀스 변환 모델**이다.  \n",
    "입력과 출력이 모두 “시퀀스(sequence)” 형태라는 점에서 *Sequence-to-Sequence*라는 이름이 붙었다.\n",
    "\n",
    "### Encoder의 역할: 입력 시퀀스 이해 및 Context Vector 생성\n",
    "\n",
    "Encoder는 입력으로 들어온 **전체 시퀀스**(sequence)를 순차적으로 처리한 뒤,  그 의미를 **하나의 고정 길이 벡터**(Vector)로 압축하여 출력한다.  \n",
    "이 벡터를 **Context Vector**(컨텍스트 벡터)라고 한다.\n",
    "- **Context Vector란?**  \n",
    "  - 입력 시퀀스 전체의 의미, 문맥, 핵심 정보를 요약해 담고 있는 벡터 표현이다.\n",
    "  - **기계 번역**(Machine Translation)의 경우  \n",
    "    - 번역할 원문 문장에서 **번역 결과를 생성하는 데 필요한 핵심 의미 정보**(feature)\n",
    "  - **챗봇**(Chatbot)의 경우  \n",
    "    - 사용자가 입력한 질문에서 **적절한 답변을 생성하는 데 필요한 의미 정보**(feature)\n",
    "\n",
    "### Decoder의 역할: Context Vector를 바탕으로 출력 시퀀스 생성\n",
    "\n",
    "Decoder는 Encoder가 출력한 **Context Vector를 입력으로 받아**, 이를 바탕으로 **목표 출력 시퀀스**를 한 토큰(token)씩 순차적으로 생성한다.\n",
    "\n",
    "- **기계 번역**(Machine Translation)의 경우  \n",
    "  - 입력 문장의 의미를 반영한 **번역 문장**을 생성한다.\n",
    "- **챗봇**(Chatbot)  \n",
    "  - 질문에 대한 **자연스러운 답변 문장**을 생성한다.\n",
    "\n",
    "Decoder는 매 시점(time step)마다\n",
    "  - 이전에 생성한 단어\n",
    "  - 그리고 Context Vector에 담긴 입력 문맥\n",
    "을 함께 고려하여 다음 단어를 예측한다.\n",
    "\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {},
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {},
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {},
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {},
   "source": [
    "## 데이터셋 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876b85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(\"다운실패:\", res.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395565ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/chatbot_data.csv\", encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b640e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e75bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7288146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A\n",
       "0                   12시 땡!          하루가 또 가네요.\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56432716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n",
       "      <td>사랑하기 힘든 관계인가봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n",
       "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
       "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>후회 없이 사랑하고 싶어</td>\n",
       "      <td>진심으로 다가가 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                                            A\n",
       "11813   회사에 좋아하는 남자가 생겼어 어떡하지?                              사랑하기 힘든 관계인가봐요.\n",
       "11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐.                      눈 마주치는 게 우연인지 잘 살펴 보세요.\n",
       "11815      회식 중이라고 하는데 연락이 안돼.  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.\n",
       "11816        회식하는데 나만 챙겨줘. 썸임?          호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n",
       "11817            후회 없이 사랑하고 싶어                                진심으로 다가가 보세요.\n",
       "11818           훔쳐보는 것도 눈치 보임.                           티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.                                훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                                       설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?                     잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐                           도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf714bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7578036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화를 위해서 문장을 q + a 형식으로 만든다.\n",
    "# 어휘사전을 만들때 Q와 A에 있는 모든 단어들이 다 들어가게 하기 위해.\n",
    "question_texts = df['Q'] # Series (str)\n",
    "answer_texts = df['A'] # Series (str)\n",
    "\n",
    "all_texts = list(question_texts+\" \"+answer_texts)  # series + 문자열 + series  (원소단위 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71395ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.',\n",
       " 'SD카드 망가졌어 다시 새로 사는 게 마음 편해요.',\n",
       " 'SD카드 안돼 다시 새로 사는 게 마음 편해요.',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ 잘 모르고 있을 수도 있어요.',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중 시간을 정하고 해보세요.',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨 시간을 정하고 해보세요.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67feeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    BPE(unk_token=\"<unk>\")\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=10_000, # 최대 어휘수\n",
    "    min_frequency=5,   # 어휘사전에 등록할 단어의 최소 빈도수. (5회 이상은 나와야 등록.)\n",
    "    continuing_subword_prefix='##', # 연결 subword 앞에 붙일 접두어. cowork : co + ##work\n",
    "    special_tokens=[\"<pad>\",\"<unk>\",\"<sos>\"] # <sos> 문장의 시작을 의미하는 특수토큰.\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1990cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘수: 7040\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0dd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 이런 날씨에 뭘 하면 좋을까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3256c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '날씨가', '너무', '좋습니다', '.', '이런', '날씨', '##에', '뭘', '하면', '좋을까요', '?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c673c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2290, 3852, 2258, 5913, 8, 2752, 2841, 1267, 527, 2530, 5532, 20]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dfc867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(1500)  # id로 토큰문자열 조회\n",
    "tokenizer.token_to_id(\"하면\")# 토큰 문자열로 id(정수)를 조회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {},
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a8eea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d3e5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tokenizer = Tokenizer.from_file(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나의 batch로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92338cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6418051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question_texts (list[str]): 질문 text 리스트. [\"질문1\", \"질문2\", ..]\n",
    "            answer_texts (list[str]): 답변 text 리스트. [\"답변1\", \"답변2\", ...]\n",
    "            max_length (int): 개별 문장의 최대 토큰 수\n",
    "            tokenizer (Tokenzier)\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        # \"질문\" -> Tensor(토큰 id)\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        token_sequence를 self.max_length 길이에 맞추는 메소드.\n",
    "        max_length보다 적으면 <pad>를 추가, 크면 잘라낸다.\n",
    "        Args:\n",
    "            token_sequence (list[int]): 한 문장의 토큰 id 리스트. [2334, 7100, 257, ..]\n",
    "        Returns:\n",
    "            list[int]: 길이를 max_length에 맞춘 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_length = len(token_sequence)\n",
    "        if seq_length > self.max_length: #잘라내기\n",
    "            result = token_sequence[:self.max_length]\n",
    "        else: # <pad> 추가 (padding 처리)\n",
    "            result = token_sequence + [pad_token] * (self.max_length - seq_length)\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한 문장(text-str)을 받아서 token화 한 뒤 max_length에 개수를 맞춰서 반환.\n",
    "        max_length에 맞추는 작업은 __pad_token_sequence() 를 이용\n",
    "        Args:\n",
    "            text (str): 토큰화할 문장\n",
    "        Returns:\n",
    "            torch.Tensor[int64]: 토큰화한 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        encode = self.tokenizer.encode(text)\n",
    "        token_ids = encode.ids # \"나는 학생이다.\" -> [4020, 1003, 3932]\n",
    "        # [4020, 1003, 3932] -> [4020, 1003, 3932, 0, 0, 0 ] 패딩 처리.\n",
    "        return torch.tensor(self.__pad_token_sequence(token_ids), dtype=torch.int64)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        index의 (question, answer) 쌍을 반환.\n",
    "        Args:\n",
    "            index (int) : 몇번 질문-답변 쌍인지 index\n",
    "        Return:\n",
    "            tuple[Tensor(int64), Tensor(int64)]\n",
    "        \"\"\"\n",
    "        q = self.question_texts[index]\n",
    "        a = self.answer_texts[index]\n",
    "        return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f92a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length. 가장 긴 문장의 토큰 수\n",
    "max([len(tokenizer.encode(sent).ids) for sent in question_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7145b9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(sent).ids) for sent in answer_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db4f6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 29\n",
    "dataset = ChatbotDataset(\n",
    "    list(question_texts),\n",
    "    list(answer_texts),\n",
    "    max_length,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18d34e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79631e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  10, 1747, 1400,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]),\n",
       " tensor([6119,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25b20de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {},
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 0.95 : 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c0c8fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.95)\n",
    "test_size = len(dataset) - train_size\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b5d84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df50fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.ChatbotDataset, torch.utils.data.dataset.Subset)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset), type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "208d5e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {},
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1ad8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a596315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b21002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = nn.Embedding(100, 5, padding_idx=2)\n",
    "# a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477135dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            vocab_size: int, # 총 어휘수\n",
    "            embedding_dim: int, # Embedding Vector의 차원\n",
    "            hidden_size: int,   # GRU의 HIDDEN 개수\n",
    "            bidirectional: bool = True, # GRU의 양방향 여부\n",
    "            num_layers: int = 1, # GRU의 layer stack 수\n",
    "            dropout: float = 0.2   # dropout 비율\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        # X -> (Embedding Model) -> (GRU) -> Context Vector -> (Decoder)\n",
    "        # Encoder의 목적은 (질문의) Context Vector 를 추출하는 것이 목적.\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim, # (vocab_size x embedding_dim)\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shpae [batch, seq_length]\n",
    "        embedding_vector = self.embedding(X) # [batch, seq_length, emb_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0) # [seq_length, batch, emb_dim]\n",
    "        out, hidden = self.gru(embedding_vector) \n",
    "        # out: 모든 timestep의 hidden state, hidden: 마지막 timestep의 hidden state\n",
    "        return out, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c565ebb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [20, 64, 40]              --\n",
       "├─Embedding: 1-1                         [64, 20, 100]             100,000\n",
       "├─GRU: 1-2                               [20, 64, 40]              14,640\n",
       "==========================================================================================\n",
       "Total params: 114,640\n",
       "Trainable params: 114,640\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 25.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.43\n",
       "Params size (MB): 0.46\n",
       "Estimated Total Size (MB): 1.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "dummy_input = torch.randint(10, size=(64, 20), dtype=torch.int64)\n",
    "summary(Encoder(1000, 100, 20), input_data=dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10b3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, \n",
    "                 num_layers=1,\n",
    "                 bidirectional=False, # Decoder는 토큰을 하나씩 생성. 뒤에 토큰들을 알지 못하기 때문에 단방향 처리.\n",
    "                 dropout=0.2\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout = dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(\n",
    "            hidden_size,  # 입력 - gru의 마지막 hidden state값.\n",
    "            vocab_size    # 출력 - 다중분류: 어휘사전의 단어들 중 다음 단어 한개를 찾는 다중분류\n",
    "        )\n",
    "\n",
    "    def forward(self, X, hidden):\n",
    "        \"\"\"\n",
    "        X: 한 개 토큰. shape: [batch] \n",
    "        hidden: 이전 처리 hidden state. 첫번째 timestep: Encoder의 context vector\n",
    "                [seq_length: 1, batch, hidden_size]\n",
    "        \"\"\"\n",
    "        # [batch] -> [batch, 1]  1: seq_length\n",
    "        X = X.unsqueeze(1)\n",
    "        embedding_vector = self.embedding(X) # 입력: int64, [batch, seq_length(1)] \n",
    "        \n",
    "        # [batch, seq_length(1), embedding_dim] -> [seq_length(1), batch, embedding_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0)\n",
    "\n",
    "        # [seq_length(1), batch, embedding_dim] -> out, hidden\n",
    "        #  out(모든 timestep의 hidden state 모음): [seq_length(1), batch_size, hidden_size]\n",
    "        #  hidden(마지막 timestep의 hidden state): [num_layers, batch_size, hidden_size]\n",
    "        out, hidden = self.gru(embedding_vector)\n",
    "\n",
    "        # Linear(분류기) 넣어서 다음 단어를 예측\n",
    "        last_out = self.classifier(out[-1])\n",
    "\n",
    "        # last_out: 다음 단어일 확률. [batch, vocab_size]\n",
    "        # hidden: 다음 단어를 예측할 때 넣어줄 context vector(hidden state)\n",
    "        return last_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e27e9182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Decoder                                  [64, 10000]               --\n",
       "├─Embedding: 1-1                         [64, 1, 200]              2,000,000\n",
       "├─GRU: 1-2                               [1, 64, 256]              351,744\n",
       "├─Linear: 1-3                            [64, 10000]               2,570,000\n",
       "==========================================================================================\n",
       "Total params: 4,921,744\n",
       "Trainable params: 4,921,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 314.99\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 5.35\n",
       "Params size (MB): 19.69\n",
       "Estimated Total Size (MB): 25.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.ones([64], dtype=torch.int64)  # 64: batch\n",
    "dummy_hidden = torch.ones((1, 64, 200), dtype=torch.float32)\n",
    "# hidden shape: [1-gru layer 개수, 64: batch, 200: hidden_size]\n",
    "# gru layer 개수: num_layers * 2 if bidirectional else 1\n",
    "\n",
    "dummy_decoder = Decoder(10000, 200, 256, num_layers=1)\n",
    "summary(dummy_decoder, input_data=(dummy_input, dummy_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eff7b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word, hidden = dummy_decoder(dummy_input, dummy_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b1d95199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10000])\n",
      "torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "print(next_word.shape)\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550,\n",
       "        4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550,\n",
       "        4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550,\n",
       "        4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550,\n",
       "        4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550, 4550,\n",
       "        4550, 4550, 4550, 4550])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word.max(dim=-1).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성한다.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법이다.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습할 수있다.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id(\"<sos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4acaa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SOS_TOKEN = tokenizer.token_to_id(\"<sos>\")\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: 질문. (batch, seq_length)\n",
    "            outputs: 답변(정답). (batch, seq_length) -> teacher forcing 때 사용.\n",
    "            teacher_forcing_rate: teacher forcing은 random하게 적용. 적용될 확률.\n",
    "        \"\"\"\n",
    "        # 질문과 답변이 1차원일 경우 2차원으로 reshape\n",
    "        # if [seq_length] -> [batch(1), seq_length]\n",
    "        if inputs.dim() == 1:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        if outputs.dim() == 1:\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "\n",
    "        batch_size, output_length = outputs.shape # output_length: output의 max_length. 답변문장의 토큰수를 여기에 맞출것.\n",
    "        output_vocab_size = self.encoder.vocab_size\n",
    "\n",
    "        ######################################\n",
    "        # 생성된 문장을 저장할 tensor를 생성 (모델이 생성한 예측 문장)\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        # [나는, 학생, 이다.]\n",
    "        # [\n",
    "        #   vocab_size의 각 단어가 \"나는\"일 확률\n",
    "        #   vocab_size의 각 단어가 \"학생\"일 확률\n",
    "        #   vocab_size의 각 단어가 \"이다\"일 확률\n",
    "        # ]\n",
    "        ######################################\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "\n",
    "        ##################################################################\n",
    "        # 추론\n",
    "        #  1. encoder를 이용해서 context vector 추출(한번에 처리)\n",
    "        #  2. decoder를 이용해서 답변 문장을 생성(개별 토큰별로 생성.)\n",
    "        ##################################################################\n",
    "        # encoder를 이용해서 context vector 추출\n",
    "        encoder_out, _ = self.encoder(inputs) # encoder_out: 전체 hidden state 모음\n",
    "\n",
    "        # context vector == encoder_out[-1] => Decoder에 첫번째 timestep의 hidden으로 입력\n",
    "        decoder_hidden = encoder_out[-1].unsqueeze(0)\n",
    "        # decoder에 입력할 첫번째 timestep의 값: <sos> 토큰 id\n",
    "        decoder_input = torch.full([batch_size], fill_value=SOS_TOKEN, device=self.device)\n",
    "\n",
    "        ###########################################\n",
    "        # Decoder를 이용해서 한 단어(토큰)씩 생성\n",
    "        ###########################################\n",
    "        for t in range(output_length):\n",
    "            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            predicted_outputs[t] = decoder_out # t번째 예측 단어\n",
    "\n",
    "            # 다음 timestep의 input을 생성 (decoder_input값을 생성)\n",
    "            # teacher forcing 적용     -> t 번째 정답 토큰\n",
    "            #                 적용안함  -> Decoder 가 생성한 decoder_out의 token id값.\n",
    "            # teacher_forcing_rate 비율로 teacher forcing을 적용\n",
    "            teacher_forcing = teacher_forcing_rate > random.random()\n",
    "            teacher_forcing_rate *= 0.99 # 반복하면서 teacher forcing 적용 확률을 줄여나간다.\n",
    "\n",
    "            top1 = decoder_out.argmax(dim=-1) # 다음 단어일 확율이 가장 높은 단어의 토큰ID\n",
    "            decoder_input = outputs[:, t] if teacher_forcing else top1\n",
    "\n",
    "        return predicted_outputs.transpose(1, 0) # [seq_length <-> batch, vocab_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1aba84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 정의\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "encoder_bidirectional = True # 인코더는 양방향.\n",
    "encoder_hidden_size = 200\n",
    "\n",
    "# encoder의 hidden(context vector)과 decoder hidden을 맞춰준다.\n",
    "decoder_hidden_size = encoder_hidden_size * 2 if encoder_bidirectional else encoder_hidden_size\n",
    "\n",
    "embedding_dim = 256\n",
    "teacher_forcing_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1bce8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "encoder = Encoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=encoder_hidden_size,\n",
    "    num_layers=1, \n",
    "    bidirectional=encoder_bidirectional\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=decoder_hidden_size,\n",
    "    num_layers=1\n",
    ")\n",
    "seq2seq = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "43e09ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Seq2Seq                                  [64, 30, 7040]            --\n",
       "├─Encoder: 1-1                           [30, 64, 400]             --\n",
       "│    └─Embedding: 2-1                    [64, 30, 256]             1,802,240\n",
       "│    └─GRU: 2-2                          [30, 64, 400]             549,600\n",
       "├─Decoder: 1-2                           [64, 7040]                --\n",
       "│    └─Embedding: 2-3                    [64, 1, 256]              1,802,240\n",
       "│    └─GRU: 2-4                          [1, 64, 400]              789,600\n",
       "│    └─Linear: 2-5                       [64, 7040]                2,823,040\n",
       "├─Decoder: 1-3                           [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-6                    [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-7                          [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-8                       [64, 7040]                (recursive)\n",
       "├─Decoder: 1-4                           [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-9                    [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-10                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-11                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-5                           [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-12                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-13                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-14                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-6                           [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-15                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-16                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-17                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-7                           [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-18                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-19                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-20                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-8                           [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-21                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-22                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-23                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-9                           [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-24                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-25                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-26                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-10                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-27                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-28                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-29                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-11                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-30                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-31                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-32                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-12                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-33                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-34                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-35                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-13                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-36                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-37                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-38                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-14                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-39                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-40                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-41                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-15                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-42                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-43                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-44                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-16                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-45                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-46                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-47                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-17                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-48                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-49                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-50                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-18                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-51                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-52                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-53                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-19                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-54                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-55                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-56                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-20                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-57                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-58                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-59                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-21                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-60                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-61                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-62                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-22                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-63                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-64                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-65                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-23                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-66                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-67                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-68                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-24                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-69                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-70                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-71                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-25                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-72                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-73                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-74                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-26                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-75                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-76                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-77                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-27                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-78                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-79                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-80                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-28                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-81                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-82                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-83                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-29                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-84                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-85                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-86                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-30                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-87                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-88                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-89                      [64, 7040]                (recursive)\n",
       "├─Decoder: 1-31                          [64, 7040]                (recursive)\n",
       "│    └─Embedding: 2-90                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-91                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-92                      [64, 7040]                (recursive)\n",
       "==========================================================================================\n",
       "Total params: 7,766,720\n",
       "Trainable params: 7,766,720\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 11.57\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 128.29\n",
       "Params size (MB): 31.07\n",
       "Estimated Total Size (MB): 159.38\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_input = torch.zeros((64, 30), dtype=torch.int64)\n",
    "\n",
    "summary(seq2seq, input_data=(d_input, d_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {},
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e8000c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model = seq2seq.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {},
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c8d12a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, device, teacher_forcing_rate=0.9):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X, y, teacher_forcing_rate) # seq2seq\n",
    "        # pred: [batch, seq_length, vocab_size]\n",
    "        # pred: [batch * seq_length, vocab_size]\n",
    "        y_hat = pred.reshape(-1, pred.shape[2]) # loss 계산을 위해서 \n",
    "        y = y.reshape(-1)  # [batch, seq_length] -> [batch * seq_length]\n",
    "        # CrossEntropyLoss입력: 정답 - [batch,], 추론: [batch, class개수-vocab_size]\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {},
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab2c9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X, y, teacher_forcing_rate=0.0) # tearcher forcing 적용하면 안됨.\n",
    "        y_hat = pred.reshape(-1, pred.shape[-1])\n",
    "        y = y.reshape(-1)\n",
    "        eval_loss += loss_fn(y_hat, y).item()\n",
    "    \n",
    "    return eval_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b5b463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 에서 저장--------------\n",
      "1 4.545803670883179 1.6358345866203308\n",
      "2 1.286798962184361 1.7328847765922546\n",
      "3 1.130756915978023 1.7858333706855773\n",
      "4 0.9895671336991446 1.809503984451294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m best_loss = torch.inf\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     eval_loss = \u001b[38;5;28meval\u001b[39m(model, test_loader, loss_fn, device)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m best_loss > eval_loss: \u001b[38;5;66;03m# 성능개선\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optimizer, loss_fn, device, teacher_forcing_rate)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# CrossEntropyLoss입력: 정답 - [batch,], 추론: [batch, class개수-vocab_size]\u001b[39;00m\n\u001b[32m     13\u001b[39m loss = loss_fn(y_hat, y)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m optimizer.step()\n\u001b[32m     16\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Documents\\SKN21_inst\\08_NLP-자연어처리\\.venv\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Documents\\SKN21_inst\\08_NLP-자연어처리\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Documents\\SKN21_inst\\08_NLP-자연어처리\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "model_save_path = \"saved_models/chatbot_seq2seq.pth\"\n",
    "# 가장 validation loss 가 좋은 모델을 저장.\n",
    "best_loss = torch.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, \n",
    "                       device, teacher_forcing_rate)\n",
    "    eval_loss = eval(model, test_loader, loss_fn, device)\n",
    "\n",
    "    if best_loss > eval_loss: # 성능개선\n",
    "        torch.save(model, model_save_path)\n",
    "        print(epoch+1, \"에서 저장--------------\")\n",
    "        best_loss = eval_loss\n",
    "\n",
    "    print(epoch+1, train_loss, eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4627557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 저장 모델 Load\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# map_location=device : 다른 device에 학습/저장한 모델을 읽어올 때 현재 device를 지정해서  현재 device에 맞춰 load하도록한다.\n",
    "best_model = torch.load(model_save_path, weights_only=False, map_location=device)\n",
    "best_model.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894",
   "metadata": {},
   "source": [
    "- Sampler:\n",
    "    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n",
    "    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eff6bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('##')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 ##는 내 ##꺼 ##야\" ==> \"이 기회는 내꺼야\"\n",
    "    \n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열. \n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = decoded_string.split() # 공백기준으로 토큰화.\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"): # 연결 토큰\n",
    "            if new_tokens: # len(new_tokens) != 0 원소가 하나라도 있으면\n",
    "                # 토큰에서 ##을 제거하고 리스트의 마지막 원소(문자열) 뒤에 붙인다.\n",
    "                new_tokens[-1] += token[2:]\n",
    "            else: # new_tokens가 빈 리스트. 현재 token이 첫번째 단어. ##을 지우고 append\n",
    "                new_tokens.append(token[2:])\n",
    "        else: # 단어의 시작인 토큰. (##이 없는 토큰) -> list에 추가.\n",
    "            new_tokens.append(' '+token)\n",
    "        \n",
    "    return \"\".join(new_tokens) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a0822c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "# sampler는 “Dataset에서 어떤 순서로 index를 뽑을지 결정하는 객체”이다. DataLoader는 sampler가 제공하는 index를 이용해 Dataset에서 데이터를 추출한다.\n",
    "## shuffle=True 이면 RandomSampler가 사용된다. False이면 SequentialSampler가 사용된다.\n",
    "\n",
    "\n",
    "#  dataset에서 일부 데이터들을 가지고 확인\n",
    "def random_evaluation(model, dataset, device, n=10):\n",
    "    \"\"\"\n",
    "    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n",
    "    Parameter\n",
    "        model: 학습된 seq2seq 모델\n",
    "        dataset: 질문-답변 쌍울 추출할 dataset\n",
    "        device\n",
    "        n: int - 추출할 질문-답변 쌍 개수 default: 10\n",
    "    \"\"\"\n",
    "    ## 평가할 데이터셋을 만들기\n",
    "    n_samples = len(dataset)       # Dataset의 총 데이터개수\n",
    "    # index = list(range(n_samples)) # Dataset의 index만들기.  [0, 1, 2, ...., dataset_length]\n",
    "    # np.random.shuffle(index)       # 값들을 랜덤하게 섞어준다. [100, 23, 590, 10, ...] \n",
    "    # sample_index = index[ : n]     # 평가할 데이터 개수만큼 index 생성.\n",
    "\n",
    "\n",
    "    sample_index = torch.randint(0, n_samples, size=[n])\n",
    "    \n",
    "    # Dataloader 생성\n",
    "    # SubsetRandomSampler: 지정한 index들 안에서 random한 순서로 제공.\n",
    "    # sample_index=[1, 20, 4, 5, 100], dataset에서 [1, 20, 4, 5, 100] index의 값만 추출\n",
    "    sampler = SubsetRandomSampler(sample_index)\n",
    "    sample_loader = DataLoader(dataset, batch_size=n, sampler=sampler)\n",
    "    \n",
    "    ## 추론 후 확인\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in sample_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X, y, 0.0) # [batch, seq_len, vocab_size]\n",
    "\n",
    "            # torch.Tensor -> ndarray (tokenizer decode에 넣기 위해.)\n",
    "            ## tensor를 cpu로 이동후 변환가능.\n",
    "            ### tensor가 grad를 가지고 있으면(계산그래프에 포함되 있으면)\n",
    "            ####                               -> tensor.detach().cpu().ndarray()\n",
    "\n",
    "            pred = output.cpu().numpy()  # X.to(\"cpu\") # 모델추정 답변\n",
    "            X = X.cpu().numpy()   # 정답-질문\n",
    "            y = y.cpu().numpy()   # 정답-답변\n",
    "\n",
    "            for i in range(n):\n",
    "                q = handle_special_tokens(tokenizer.decode(X[i]))\n",
    "                a = handle_special_tokens(tokenizer.decode(y[i]))\n",
    "                p = handle_special_tokens(tokenizer.decode(pred[i].argmax(-1)))\n",
    "                print(f\"질문: {q}\")\n",
    "                print(f\"정답: {a}\")\n",
    "                print(f\"예측: {p}\")\n",
    "                print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:  뭐하냐고 계속 물어보면 좋아하는 거야 ?\n",
      "정답:  궁금하니까 그럴 가능성이 높겠죠 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  남자들은 좋아하는 여자한테 이럴 수 있어 ?\n",
      "정답:  어떤 행동이냐에 따라 다르겠지요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  할 수 있다면 그럴수 있다면 달라질까 ?\n",
      "정답:  자신을 믿어보세요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  게임 때문에 시간 다갔어\n",
      "정답:  게임할때는 시간이 더 빨리 가요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  어쩌죠\n",
      "정답:  어쩌면 좋을까요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  미용실 갔다왔는데 티가 안 나\n",
      "정답:  다시 방문해보세요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  돈 가지고 유세부려\n",
      "정답:  없다가 있어서 그런가봐요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  평일 저녁 데이트 장소 좀 추천해줘\n",
      "정답:  야경이 예쁜 곳이요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  짧게 만났다고 해서 안힘든게 아니네\n",
      "정답:  그것도 사랑이니까요 .\n",
      "예측:  잘 .\n",
      "==================================================\n",
      "질문:  시간 왤케 빨리감\n",
      "정답:  시간은 상대적으로 흘러갑니다 .\n",
      "예측:  잘 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_evaluation(model, train_set, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {},
   "source": [
    "# 학습모델을 이용한 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8f5dea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotInputDataset(Dataset):\n",
    "    \"\"\"\n",
    "    질문만 받아서 생성하는 Dataset\n",
    "    - 새로운 데이터 추론용.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "    \n",
    "    def __pad_token_sequence(self, token_sequence): \n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "        \n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "    \n",
    "    def __process_sequence(self, text): \n",
    "        \"\"\"\n",
    "        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length 크기에 맞춘다.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 질문만 반환.\n",
    "        q = self.question_texts[index]  # List\n",
    "        \n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다. \n",
    "        return torch.tensor(q, dtype=torch.int64) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5313038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    \"난 가족들과 주말에 여행갈 거야.\", \n",
    "    \"와! 내일 주말이다.\",\n",
    "    \"너무 피곤하네요. 좀 쉬었으면 좋겠어요.\",\n",
    "    \"지금 몇시에요.\",\n",
    "    \"여자 친구와 내일 저녁에 만나기로 했어.\"    \n",
    "]\n",
    "input_dataset = ChatbotInputDataset(input_data, max_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "55c89f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for X in dataset:  # Dataset에서 한 질문씩을 조회\n",
    "            X = X.to(device)\n",
    "            output = model(X.unsqueeze(0), X.unsqueeze(0), 0.0)\n",
    "            pred = output.cpu().numpy()\n",
    "            X = X.cpu().numpy()\n",
    "            q = handle_special_tokens(tokenizer.decode(X))\n",
    "            a = handle_special_tokens(tokenizer.decode(pred[0].argmax(-1)))\n",
    "            print(f\"질문: {q}\")\n",
    "            print(f\"예상답: {a}\")\n",
    "            print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f5c1150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:  난 가족들과 주말에 여행갈 거야 .\n",
      "예상답:  잘 .\n",
      "=========================================================\n",
      "질문:  와 ! 내일 주말이다 .\n",
      "예상답:  잘 .\n",
      "=========================================================\n",
      "질문:  너무 피곤하네요 . 좀 쉬었으면 좋겠어요 .\n",
      "예상답:  잘 .\n",
      "=========================================================\n",
      "질문:  지금 몇시에요 .\n",
      "예상답:  잘 .\n",
      "=========================================================\n",
      "질문:  여자 친구와 내일 저녁에 만나기로 했어 .\n",
      "예상답:  잘 .\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "predict(input_dataset, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
