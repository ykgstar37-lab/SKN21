{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {},
   "source": [
    "# Encoder–Decoder 구조\n",
    "\n",
    "- Encoder–Decoder 구조는 어떤 형태의 입력 시퀀스를 받아 **의미를 해석**한 뒤, 새로운 **출력 시퀀스를 생성**해야 하는 거의 모든 AI 문제를 해결하는 딥러닝 모델 구조다.\n",
    "- 이 구조는 Encoder와 Decoder 두개의 딥러닝 모델을 연결한 구조로 **입력 데이터를 하나의 표현으로 압축한 뒤, 이를 다시 출력 데이터로 변환하는 방식**으로 동작한다.\n",
    "\n",
    "- **Encoder Network**\n",
    "  - 입력 데이터를 해석(이해)하는 역할을 수행한다.\n",
    "  - 입력 시퀀스에 담긴 의미적 정보를 하나의 고정된 벡터 형태로 요약한다.\n",
    "\n",
    "- **Decoder Network**\n",
    "  - Encoder가 생성한 요약 정보를 바탕으로 최종 출력을 생성한다.\n",
    "  - 즉, Encoder의 “이해 결과”를 이용해 새로운 시퀀스를 만들어낸다.\n",
    "\n",
    "## Seq2Seq (Sequence-to-Sequence)\n",
    "\n",
    "Seq2Seq 모델은 **Encoder–Decoder 구조를 RNN(Recurrent Neural Network) 계열에 적용한 대표적인 시퀀스 변환 모델**이다.  \n",
    "입력과 출력이 모두 “시퀀스(sequence)” 형태라는 점에서 *Sequence-to-Sequence*라는 이름이 붙었다.\n",
    "\n",
    "### Encoder의 역할: 입력 시퀀스 이해 및 Context Vector 생성\n",
    "\n",
    "Encoder는 입력으로 들어온 **전체 시퀀스**(sequence)를 순차적으로 처리한 뒤,  그 의미를 **하나의 고정 길이 벡터**(Vector)로 압축하여 출력한다.  \n",
    "이 벡터를 **Context Vector**(컨텍스트 벡터)라고 한다.\n",
    "- **Context Vector란?**  \n",
    "  - 입력 시퀀스 전체의 의미, 문맥, 핵심 정보를 요약해 담고 있는 벡터 표현이다.\n",
    "  - **기계 번역**(Machine Translation)의 경우  \n",
    "    - 번역할 원문 문장에서 **번역 결과를 생성하는 데 필요한 핵심 의미 정보**(feature)\n",
    "  - **챗봇**(Chatbot)의 경우  \n",
    "    - 사용자가 입력한 질문에서 **적절한 답변을 생성하는 데 필요한 의미 정보**(feature)\n",
    "\n",
    "### Decoder의 역할: Context Vector를 바탕으로 출력 시퀀스 생성\n",
    "\n",
    "Decoder는 Encoder가 출력한 **Context Vector를 입력으로 받아**, 이를 바탕으로 **목표 출력 시퀀스**를 한 토큰(token)씩 순차적으로 생성한다.\n",
    "\n",
    "- **기계 번역**(Machine Translation)의 경우  \n",
    "  - 입력 문장의 의미를 반영한 **번역 문장**을 생성한다.\n",
    "- **챗봇**(Chatbot)  \n",
    "  - 질문에 대한 **자연스러운 답변 문장**을 생성한다.\n",
    "\n",
    "Decoder는 매 시점(time step)마다\n",
    "  - 이전에 생성한 단어\n",
    "  - 그리고 Context Vector에 담긴 입력 문맥\n",
    "을 함께 고려하여 다음 단어를 예측한다.\n",
    "\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {},
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {},
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {},
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {},
   "source": [
    "## 데이터셋 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876b85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(\"다운실패:\", res.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395565ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/chatbot_data.csv\", encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b640e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e75bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7288146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A\n",
       "0                   12시 땡!          하루가 또 가네요.\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56432716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n",
       "      <td>사랑하기 힘든 관계인가봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n",
       "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
       "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>후회 없이 사랑하고 싶어</td>\n",
       "      <td>진심으로 다가가 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                                            A\n",
       "11813   회사에 좋아하는 남자가 생겼어 어떡하지?                              사랑하기 힘든 관계인가봐요.\n",
       "11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐.                      눈 마주치는 게 우연인지 잘 살펴 보세요.\n",
       "11815      회식 중이라고 하는데 연락이 안돼.  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.\n",
       "11816        회식하는데 나만 챙겨줘. 썸임?          호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n",
       "11817            후회 없이 사랑하고 싶어                                진심으로 다가가 보세요.\n",
       "11818           훔쳐보는 것도 눈치 보임.                           티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.                                훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                                       설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?                     잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐                           도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf714bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7578036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화를 위해서 문장을 q + a 형식으로 만든다.\n",
    "# 어휘사전을 만들때 Q와 A에 있는 모든 단어들이 다 들어가게 하기 위해.\n",
    "question_texts = df['Q'] # Series (str)\n",
    "answer_texts = df['A'] # Series (str)\n",
    "\n",
    "all_texts = list(question_texts+\" \"+answer_texts)  # series + 문자열 + series  (원소단위 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71395ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.',\n",
       " 'SD카드 망가졌어 다시 새로 사는 게 마음 편해요.',\n",
       " 'SD카드 안돼 다시 새로 사는 게 마음 편해요.',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ 잘 모르고 있을 수도 있어요.',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중 시간을 정하고 해보세요.',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨 시간을 정하고 해보세요.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67feeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    BPE(unk_token=\"<unk>\")\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=10_000, # 최대 어휘수\n",
    "    min_frequency=5,   # 어휘사전에 등록할 단어의 최소 빈도수. (5회 이상은 나와야 등록.)\n",
    "    continuing_subword_prefix='##', # 연결 subword 앞에 붙일 접두어. cowork : co + ##work\n",
    "    special_tokens=[\"<pad>\",\"<unk>\",\"<sos>\"] # <sos> 문장의 시작을 의미하는 특수토큰.\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1990cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘수: 7040\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0dd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 이런 날씨에 뭘 하면 좋을까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3256c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '날씨가', '너무', '좋습니다', '.', '이런', '날씨', '##에', '뭘', '하면', '좋을까요', '?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c673c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2290, 3852, 2258, 5913, 8, 2752, 2841, 1267, 527, 2530, 5532, 20]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dfc867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(1500)  # id로 토큰문자열 조회\n",
    "tokenizer.token_to_id(\"하면\")# 토큰 문자열로 id(정수)를 조회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {},
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a8eea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d3e5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tokenizer = Tokenizer.from_file(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나의 batch로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92338cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6418051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question_texts (list[str]): 질문 text 리스트. [\"질문1\", \"질문2\", ..]\n",
    "            answer_texts (list[str]): 답변 text 리스트. [\"답변1\", \"답변2\", ...]\n",
    "            max_length (int): 개별 문장의 최대 토큰 수\n",
    "            tokenizer (Tokenzier)\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        # \"질문\" -> Tensor(토큰 id)\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        token_sequence를 self.max_length 길이에 맞추는 메소드.\n",
    "        max_length보다 적으면 <pad>를 추가, 크면 잘라낸다.\n",
    "        Args:\n",
    "            token_sequence (list[int]): 한 문장의 토큰 id 리스트. [2334, 7100, 257, ..]\n",
    "        Returns:\n",
    "            list[int]: 길이를 max_length에 맞춘 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_length = len(token_sequence)\n",
    "        if seq_length > self.max_length: #잘라내기\n",
    "            result = token_sequence[:self.max_length]\n",
    "        else: # <pad> 추가 (padding 처리)\n",
    "            result = token_sequence + [pad_token] * (self.max_length - seq_length)\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한 문장(text-str)을 받아서 token화 한 뒤 max_length에 개수를 맞춰서 반환.\n",
    "        max_length에 맞추는 작업은 __pad_token_sequence() 를 이용\n",
    "        Args:\n",
    "            text (str): 토큰화할 문장\n",
    "        Returns:\n",
    "            torch.Tensor[int64]: 토큰화한 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        encode = self.tokenizer.encode(text)\n",
    "        token_ids = encode.ids # \"나는 학생이다.\" -> [4020, 1003, 3932]\n",
    "        # [4020, 1003, 3932] -> [4020, 1003, 3932, 0, 0, 0 ] 패딩 처리.\n",
    "        return torch.tensor(self.__pad_token_sequence(token_ids), dtype=torch.int64)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        index의 (question, answer) 쌍을 반환.\n",
    "        Args:\n",
    "            index (int) : 몇번 질문-답변 쌍인지 index\n",
    "        Return:\n",
    "            tuple[Tensor(int64), Tensor(int64)]\n",
    "        \"\"\"\n",
    "        q = self.question_texts[index]\n",
    "        a = self.answer_texts[index]\n",
    "        return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f92a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length. 가장 긴 문장의 토큰 수\n",
    "max([len(tokenizer.encode(sent).ids) for sent in question_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7145b9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(sent).ids) for sent in answer_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db4f6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 29\n",
    "dataset = ChatbotDataset(\n",
    "    list(question_texts),\n",
    "    list(answer_texts),\n",
    "    max_length,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18d34e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79631e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  10, 1747, 1400,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]),\n",
       " tensor([6119,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25b20de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {},
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 0.95 : 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c0c8fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.95)\n",
    "test_size = len(dataset) - train_size\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b5d84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df50fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.ChatbotDataset, torch.utils.data.dataset.Subset)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset), type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "208d5e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {},
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1ad8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a596315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b21002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = nn.Embedding(100, 5, padding_idx=2)\n",
    "# a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "477135dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            vocab_size: int, # 총 어휘수\n",
    "            embedding_dim: int, # Embedding Vector의 차원\n",
    "            hidden_size: int,   # GRU의 HIDDEN 개수\n",
    "            bidirectional: bool = True, # GRU의 양방향 여부\n",
    "            num_layers: int = 1, # GRU의 layer stack 수\n",
    "            dropout: float = 0.2   # dropout 비율\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        # X -> (Embedding Model) -> (GRU) -> Context Vector -> (Decoder)\n",
    "        # Encoder의 목적은 (질문의) Context Vector 를 추출하는 것이 목적.\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim, # (vocab_size x embedding_dim)\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shpae [batch, seq_length]\n",
    "        embedding_vector = self.embedding(X) # [batch, seq_length, emb_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0) # [seq_length, batch, emb_dim]\n",
    "        out, hidden = self.gru(embedding_vector) \n",
    "        # out: 모든 timestep의 hidden state, hidden: 마지막 timestep의 hidden state\n",
    "        return out, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c565ebb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [20, 64, 40]              --\n",
       "├─Embedding: 1-1                         [64, 20, 100]             100,000\n",
       "├─GRU: 1-2                               [20, 64, 40]              14,640\n",
       "==========================================================================================\n",
       "Total params: 114,640\n",
       "Trainable params: 114,640\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 25.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.43\n",
       "Params size (MB): 0.46\n",
       "Estimated Total Size (MB): 1.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "dummy_input = torch.randint(10, size=(64, 20), dtype=torch.int64)\n",
    "summary(Encoder(1000, 100, 20), input_data=dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hiddem_size,\n",
    "                 bidirectional=False,\n",
    "                 dropout=0.2):\n",
    "        super.__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(\n",
    "            hidden_size,\n",
    "            vocab_size\n",
    "        )\n",
    "    def forword(self, X, hidden):\n",
    "        \"\"\"\n",
    "        X: 한 개 토큰 / shape: [batch]\n",
    "        hidden: 이전 처리 hidden state / 첫번째 timestep: Encorder의 context vector\n",
    "                [seq_length: 1, batch, hidden_size]\n",
    "        \"\"\"\n",
    "        embedding_vector = self.embedding(X) # 입력: int64, [batch, seq_length]\n",
    "        # [batch, seq_length, embedding_dim] -> [seq_length(1), batch, embedding_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0)\n",
    "\n",
    "        # [seq_length(1), batch, embedding_dim] -> out, hidden\n",
    "        # out(모든 timestep의 hidden state 모음) : [seq_length(1), batch_size, hidden_size]\n",
    "        # hidden(마지막 timestep의 hidden state): [num_laers]\n",
    "        out, hidden = self.gru(embedding_vector)\n",
    "\n",
    "        # Linear(분류기) 넣어서 다음 단어를 예측\n",
    "        last_out = self.classifier(out[-1])\n",
    "\n",
    "        # last_out: 다음 단어일 확률, [batch, vocab_size]\n",
    "        # hidden: 다음 단어를 예측할 때 넣어줄 context vector(hidden state)\n",
    "        return last_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.ones([64], dtype=torch.int64) # 64: batch\n",
    "dummy_hidden = torch.ones((1, 64, 200), dtype=torch.float32)\n",
    "# hidden shape : [1 - gru layer 개수, 64: batch, 200: hidden_size]\n",
    "# gru layer 개수 : num _layers * 2 if bidirectional else 1\n",
    "\n",
    "dummy_decoder = Decoder(1000, 200, 256, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word, hidden = dummy_decoder(dummy_input, dummy_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d95199",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next_word.shape)\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word.max(dim=-1).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성한다.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법이다.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습할 수있다.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acaa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: 질문. (batch, seq_length)\n",
    "            outputs: 답변(정답). (batch, seq_length) -> teacher forcing 때 사용\n",
    "            teacher_forcing_rate: teacher forcing은 random하게 적용, 적용될 확률\n",
    "        \"\"\"\n",
    "        # 질문과 답변이 1차원일 경우 2차원으로 reshape\n",
    "        # [batch] -> [batch(1), seq_length]\n",
    "        if inputs.dim() == 1:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        if outputs.dim() == 1:\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "\n",
    "        batch_size, output_length = outputs.shape\n",
    "        output_vocab_size = self.encoder.vocab_size\n",
    "\n",
    "        ##############################################\n",
    "        # 생성된 문장을 저장할 tensor를 생성\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        # [나는, 학생, 이다]\n",
    "        # [\n",
    "        #  vocab_size의 각 단어가 \"나는\"일 확률\n",
    "        #  vocab_size의 각 단어가 \"학생\"일 확률\n",
    "        #  vocab_size의 각 단어가 \"이다\"일 확률\n",
    "        # ]\n",
    "        ##############################################\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "\n",
    "\n",
    "        ###################################################################\n",
    "        # 추론\n",
    "        # 1. encoder를 이용해서 context vector 추출(한번에 처리)\n",
    "        # 2. decoder를 이용해서 답변 문장을 생성(개별 토큰별로 생성)\n",
    "        ###################################################################\n",
    "        # encoder를 이용해서 context vector 추출\n",
    "        encoder_out, _ = self.encoder(inputs) # encoder_out: 전체 hidden state 모음 \n",
    "\n",
    "        # context vector == encoder_out[-1] ==> Decoder에 첫번째 timestep의 hidden으로 입력\n",
    "        decoder_hidden = encoder_out[-1].unsqueeze(0)\n",
    "        # decoder에 입력할 첫번째 timestep의 값: <sos> 토큰 id\n",
    "        decoder_input = torch.full([batch_size], fill_value=SOS_TOKEN, device=self.device)\n",
    "\n",
    "        ########################################\n",
    "        # Decoder를 이용해서 한 단어(토큰)씩 생성\n",
    "        ########################################\n",
    "        for t in range(output_length):\n",
    "            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            predicted_outputs[t] = decoder_out # t번째 예측 단어\n",
    "\n",
    "            # 다음 timestep의 input을 생성 (decoder_input값을 생성)\n",
    "            # teacher forcing 적용      -> t번째 정답 토큰\n",
    "            #                 적용 안함 -> Decoder가 생성한 decoder_out의 token id 값\n",
    "\n",
    "            teacher_forcing = techer_forcing_rate > random.random() \n",
    "            techer_forcing_rate *= 0.99 # 반복하면서 teacher focing 적용 확률을 죽여 나간다\n",
    "\n",
    "            top1 = decoder_out.argmax(dim=-1) # 다음 단어일확률아 가장 높은 단어의 토큰 id\n",
    "            decoder_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba84d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce8d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd289e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {},
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8000c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f75708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {},
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d12a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, device, teacher_forcing_rate=0.9):\n",
    "    medel.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X,y in dataloader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        pred = model(X, y, teacher_forcing_rate) # seq2seq\n",
    "        # pred: [batch, seq_length, vocab_size]\n",
    "        # pred: [batch * seq_length, vocab_size]\n",
    "        y_hat = pred.reshape(-1, pred.shape[2]) # loss 계산을 위해서\n",
    "        y = y. reshape(-1) # [batch, seq_length] -> [batch*seq_length]\n",
    "        # CrossEntropyLoss입력: 정답 - [batch,], 추론: [batch, class개수-vocab_size]\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(dataload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09774a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, dataloader, loss_fn , device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    for X,y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {},
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c9109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a276d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b463d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280dca7-029c-4eb6-b079-39963d7b7932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894",
   "metadata": {},
   "source": [
    "- Sampler:\n",
    "    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n",
    "    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6bedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0822c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {},
   "source": [
    "# 학습모델을 이용한 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dea07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313038f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c89f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
