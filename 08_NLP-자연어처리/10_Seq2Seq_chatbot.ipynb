{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ABO2r8RRuMb0",
   "metadata": {
    "id": "ABO2r8RRuMb0"
   },
   "source": [
    "- 런타임 > 런타임 유형변경 : T4 Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4XeBXqBWuc63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1765159859992,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "4XeBXqBWuc63",
    "outputId": "0657f0bf-93e9-48f8-b718-0b77d10f7fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec  8 02:10:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   63C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {
    "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa"
   },
   "source": [
    "# Encoder–Decoder 구조\n",
    "\n",
    "- Encoder–Decoder 구조는 어떤 형태의 입력 시퀀스를 받아 **의미를 해석**한 뒤, 새로운 **출력 시퀀스를 생성**해야 하는 거의 모든 AI 문제를 해결하는 딥러닝 모델 구조다.\n",
    "- 이 구조는 Encoder와 Decoder 두개의 딥러닝 모델을 연결한 구조로 **입력 데이터를 하나의 표현으로 압축한 뒤, 이를 다시 출력 데이터로 변환하는 방식**으로 동작한다.\n",
    "\n",
    "- **Encoder Network**\n",
    "  - 입력 데이터를 해석(이해)하는 역할을 수행한다.\n",
    "  - 입력 시퀀스에 담긴 의미적 정보를 하나의 고정된 벡터 형태로 요약한다.\n",
    "\n",
    "- **Decoder Network**\n",
    "  - Encoder가 생성한 요약 정보를 바탕으로 최종 출력을 생성한다.\n",
    "  - 즉, Encoder의 “이해 결과”를 이용해 새로운 시퀀스를 만들어낸다.\n",
    "\n",
    "## Seq2Seq (Sequence-to-Sequence)\n",
    "\n",
    "Seq2Seq 모델은 **Encoder–Decoder 구조를 RNN(Recurrent Neural Network) 계열에 적용한 대표적인 시퀀스 변환 모델**이다.  \n",
    "입력과 출력이 모두 “시퀀스(sequence)” 형태라는 점에서 *Sequence-to-Sequence*라는 이름이 붙었다.\n",
    "\n",
    "### Encoder의 역할: 입력 시퀀스 이해 및 Context Vector 생성\n",
    "\n",
    "Encoder는 입력으로 들어온 **전체 시퀀스**(sequence)를 순차적으로 처리한 뒤,  그 의미를 **하나의 고정 길이 벡터**(Vector)로 압축하여 출력한다.  \n",
    "이 벡터를 **Context Vector**(컨텍스트 벡터)라고 한다.\n",
    "- **Context Vector란?**  \n",
    "  - 입력 시퀀스 전체의 의미, 문맥, 핵심 정보를 요약해 담고 있는 벡터 표현이다.\n",
    "  - **기계 번역**(Machine Translation)의 경우  \n",
    "    - 번역할 원문 문장에서 **번역 결과를 생성하는 데 필요한 핵심 의미 정보**(feature)\n",
    "  - **챗봇**(Chatbot)의 경우  \n",
    "    - 사용자가 입력한 질문에서 **적절한 답변을 생성하는 데 필요한 의미 정보**(feature)\n",
    "\n",
    "### Decoder의 역할: Context Vector를 바탕으로 출력 시퀀스 생성\n",
    "\n",
    "Decoder는 Encoder가 출력한 **Context Vector를 입력으로 받아**, 이를 바탕으로 **목표 출력 시퀀스**를 한 토큰(token)씩 순차적으로 생성한다.\n",
    "\n",
    "- **기계 번역**(Machine Translation)의 경우  \n",
    "  - 입력 문장의 의미를 반영한 **번역 문장**을 생성한다.\n",
    "- **챗봇**(Chatbot)  \n",
    "  - 질문에 대한 **자연스러운 답변 문장**을 생성한다.\n",
    "\n",
    "Decoder는 매 시점(time step)마다\n",
    "  - 이전에 생성한 단어\n",
    "  - 그리고 Context Vector에 담긴 입력 문맥\n",
    "을 함께 고려하여 다음 단어를 예측한다.\n",
    "\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {
    "id": "9887d108-2ac6-425e-9643-d351e44282c7"
   },
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {
    "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef"
   },
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {
    "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5"
   },
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {
    "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c"
   },
   "source": [
    "## 데이터셋 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876b85c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1765159985120,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "876b85c4"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(\"다운실패:\", res.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395565ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1765160034478,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "395565ac",
    "outputId": "d9240e29-1107-4d44-fceb-27b575f5fa51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/chatbot_data.csv\", encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b640e96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1765160035103,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "0b640e96",
    "outputId": "62ed22ae-ecf0-41af-b33f-af56703c0505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e75bef7",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1765160035895,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "6e75bef7"
   },
   "outputs": [],
   "source": [
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7288146",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1765160039557,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "f7288146",
    "outputId": "6be3200a-9619-4d3a-8519-76adcc18dd4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A\n",
       "0                   12시 땡!          하루가 또 가네요.\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56432716",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1765160042796,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "56432716",
    "outputId": "04586255-9eb4-4465-8ef3-08eb8256554f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n",
       "      <td>사랑하기 힘든 관계인가봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n",
       "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
       "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>후회 없이 사랑하고 싶어</td>\n",
       "      <td>진심으로 다가가 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                                            A\n",
       "11813   회사에 좋아하는 남자가 생겼어 어떡하지?                              사랑하기 힘든 관계인가봐요.\n",
       "11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐.                      눈 마주치는 게 우연인지 잘 살펴 보세요.\n",
       "11815      회식 중이라고 하는데 연락이 안돼.  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.\n",
       "11816        회식하는데 나만 챙겨줘. 썸임?          호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n",
       "11817            후회 없이 사랑하고 싶어                                진심으로 다가가 보세요.\n",
       "11818           훔쳐보는 것도 눈치 보임.                           티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.                                훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                                       설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?                     잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐                           도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf714bef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1765160044942,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "bf714bef",
    "outputId": "aea5e5b2-02d6-4971-e0ad-5986931a470c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {
    "id": "d1aad072-2245-41e8-9863-a0b451262fdd"
   },
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {
    "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7578036",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1765160054994,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "e7578036"
   },
   "outputs": [],
   "source": [
    "# 토큰화를 위해서 문장을 q + a 형식으로 만든다.\n",
    "# 어휘사전을 만들때 Q와 A에 있는 모든 단어들이 다 들어가게 하기 위해.\n",
    "question_texts = df['Q'] # Series (str)\n",
    "answer_texts = df['A'] # Series (str)\n",
    "\n",
    "all_texts = list(question_texts+\" \"+answer_texts)  # series + 문자열 + series  (원소단위 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71395ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1765160056638,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "a71395ea",
    "outputId": "4fa949fd-c364-432b-c397-d901551314cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.',\n",
       " 'SD카드 망가졌어 다시 새로 사는 게 마음 편해요.',\n",
       " 'SD카드 안돼 다시 새로 사는 게 마음 편해요.',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ 잘 모르고 있을 수도 있어요.',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중 시간을 정하고 해보세요.',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨 시간을 정하고 해보세요.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67feeef0",
   "metadata": {
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1765160067267,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "67feeef0"
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    BPE(unk_token=\"<unk>\")\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=10_000, # 최대 어휘수\n",
    "    min_frequency=5,   # 어휘사전에 등록할 단어의 최소 빈도수. (5회 이상은 나와야 등록.)\n",
    "    continuing_subword_prefix='##', # 연결 subword 앞에 붙일 접두어. cowork : co + ##work\n",
    "    special_tokens=[\"<pad>\",\"<unk>\",\"<sos>\"] # <sos> 문장의 시작을 의미하는 특수토큰.\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1990cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1765160070558,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "6d1990cf",
    "outputId": "bb069df8-783d-4580-a0c8-15cd44920049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘수: 7040\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0dd2b1",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1765160072237,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "5b0dd2b1"
   },
   "outputs": [],
   "source": [
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 이런 날씨에 뭘 하면 좋을까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3256c008",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1765160075476,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "3256c008",
    "outputId": "b4d28e76-1471-45d5-9a20-e3b39b7a2caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '날씨가', '너무', '좋습니다', '.', '이런', '날씨', '##에', '뭘', '하면', '좋을까요', '?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81c673c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1765160076522,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "81c673c9",
    "outputId": "559a60d4-a2ca-4eeb-c7b9-80cc1f2572da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2290, 3852, 2258, 5913, 8, 2752, 2841, 1276, 527, 2530, 5532, 20]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00dfc867",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765160077204,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "00dfc867",
    "outputId": "de654c6a-9aa5-465b-c063-20717728fcf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(1500)  # id로 토큰문자열 조회\n",
    "tokenizer.token_to_id(\"하면\")# 토큰 문자열로 id(정수)를 조회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {
    "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc"
   },
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8eea16",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1765160080321,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "4a8eea16"
   },
   "outputs": [],
   "source": [
    "tokenizer.save(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d3e5ae9",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765160086008,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "1d3e5ae9"
   },
   "outputs": [],
   "source": [
    "load_tokenizer = Tokenizer.from_file(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {
    "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774"
   },
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나의 batch로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92338cf3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4782,
     "status": "ok",
     "timestamp": 1765160151574,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "92338cf3",
    "outputId": "52a10d34-b750-480c-a96b-33e56dfb4cf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6418051",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765160173814,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "c6418051"
   },
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question_texts (list[str]): 질문 text 리스트. [\"질문1\", \"질문2\", ..]\n",
    "            answer_texts (list[str]): 답변 text 리스트. [\"답변1\", \"답변2\", ...]\n",
    "            max_length (int): 개별 문장의 최대 토큰 수\n",
    "            tokenizer (Tokenzier)\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        # \"질문\" -> Tensor(토큰 id)\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        token_sequence를 self.max_length 길이에 맞추는 메소드.\n",
    "        max_length보다 적으면 <pad>를 추가, 크면 잘라낸다.\n",
    "        Args:\n",
    "            token_sequence (list[int]): 한 문장의 토큰 id 리스트. [2334, 7100, 257, ..]\n",
    "        Returns:\n",
    "            list[int]: 길이를 max_length에 맞춘 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_length = len(token_sequence)\n",
    "        if seq_length > self.max_length: #잘라내기\n",
    "            result = token_sequence[:self.max_length]\n",
    "        else: # <pad> 추가 (padding 처리)\n",
    "            result = token_sequence + [pad_token] * (self.max_length - seq_length)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한 문장(text-str)을 받아서 token화 한 뒤 max_length에 개수를 맞춰서 반환.\n",
    "        max_length에 맞추는 작업은 __pad_token_sequence() 를 이용\n",
    "        Args:\n",
    "            text (str): 토큰화할 문장\n",
    "        Returns:\n",
    "            torch.Tensor[int64]: 토큰화한 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        encode = self.tokenizer.encode(text)\n",
    "        token_ids = encode.ids # \"나는 학생이다.\" -> [4020, 1003, 3932]\n",
    "        # [4020, 1003, 3932] -> [4020, 1003, 3932, 0, 0, 0 ] 패딩 처리.\n",
    "        return torch.tensor(self.__pad_token_sequence(token_ids), dtype=torch.int64)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        index의 (question, answer) 쌍을 반환.\n",
    "        Args:\n",
    "            index (int) : 몇번 질문-답변 쌍인지 index\n",
    "        Return:\n",
    "            tuple[Tensor(int64), Tensor(int64)]\n",
    "        \"\"\"\n",
    "        q = self.question_texts[index]\n",
    "        a = self.answer_texts[index]\n",
    "        return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f92a451",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1765160176877,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "5f92a451",
    "outputId": "80f2f71d-413b-4104-b24e-dbcd2ec5baa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length. 가장 긴 문장의 토큰 수\n",
    "max([len(tokenizer.encode(sent).ids) for sent in question_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7145b9c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1765160177700,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "7145b9c1",
    "outputId": "d5c7ad3f-d1ca-41a6-a0b6-f1be20a7a953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(sent).ids) for sent in answer_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db4f6435",
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1765160183281,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "db4f6435"
   },
   "outputs": [],
   "source": [
    "max_length = 29\n",
    "dataset = ChatbotDataset(\n",
    "    list(question_texts),\n",
    "    list(answer_texts),\n",
    "    max_length,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d34e55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1765160186486,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "18d34e55",
    "outputId": "33f38b56-f932-4002-cc86-10183368f905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79631e8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1765160194074,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "79631e8b",
    "outputId": "7f255237-cf05-48bb-ec58-444674f94001"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  10, 1526, 1364,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]),\n",
       " tensor([6117,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25b20de1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1765160194867,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "25b20de1",
    "outputId": "1e6b820a-7992-44e2-a780-57e37c012fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {
    "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813"
   },
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 0.95 : 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c0c8fef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765160199318,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "9c0c8fef",
    "outputId": "2b5ffaba-d069-4c42-87fb-6a9179ad28b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.95)\n",
    "test_size = len(dataset) - train_size\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b5d84a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1765160199867,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "0b5d84a9"
   },
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9df50fa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765160200553,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "9df50fa0",
    "outputId": "496cfdde-90b3-4050-de4c-221acdee9131"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.ChatbotDataset, torch.utils.data.dataset.Subset)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset), type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "208d5e7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1765160201977,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "208d5e7b",
    "outputId": "e1f7c1c3-abf2-411c-86c6-21867cdebd78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {
    "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210"
   },
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1ad8cd9",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1765160211070,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "a1ad8cd9"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a596315",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1765160230667,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "0a596315",
    "outputId": "a1b1b8e4-7b29-4704-8462-06db52f7f65f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {
    "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352"
   },
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {
    "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911"
   },
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21002f",
   "metadata": {
    "id": "2b21002f"
   },
   "outputs": [],
   "source": [
    "# a = nn.Embedding(100, 5, padding_idx=2)\n",
    "# a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "477135dd",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765160248767,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "477135dd"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size: int, # 총 어휘수\n",
    "            embedding_dim: int, # Embedding Vector의 차원\n",
    "            hidden_size: int,   # GRU의 HIDDEN 개수\n",
    "            bidirectional: bool = True, # GRU의 양방향 여부\n",
    "            num_layers: int = 1, # GRU의 layer stack 수\n",
    "            dropout: float = 0.2   # dropout 비율\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        # X -> (Embedding Model) -> (GRU) -> Context Vector -> (Decoder)\n",
    "        # Encoder의 목적은 (질문의) Context Vector 를 추출하는 것이 목적.\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim, # (vocab_size x embedding_dim)\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shpae [batch, seq_length]\n",
    "        embedding_vector = self.embedding(X) # [batch, seq_length, emb_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0) # [seq_length, batch, emb_dim]\n",
    "        out, hidden = self.gru(embedding_vector)\n",
    "        # out: 모든 timestep의 hidden state, hidden: 마지막 timestep의 hidden state\n",
    "        return out, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "Rm1MM6Uiv_o7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5597,
     "status": "ok",
     "timestamp": 1765160277313,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "Rm1MM6Uiv_o7",
    "outputId": "6a14d524-5f81-4340-8866-e6440547fa7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c565ebb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1765160318911,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "c565ebb9",
    "outputId": "bba0ef5b-8342-484b-d61d-709aa9e9d67f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [20, 64, 40]              --\n",
       "├─Embedding: 1-1                         [64, 20, 100]             100,000\n",
       "├─GRU: 1-2                               [20, 64, 40]              14,640\n",
       "==========================================================================================\n",
       "Total params: 114,640\n",
       "Trainable params: 114,640\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 25.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.43\n",
       "Params size (MB): 0.46\n",
       "Estimated Total Size (MB): 1.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "dummy_input = torch.randint(10, size=(64, 20), dtype=torch.int64)\n",
    "summary(Encoder(1000, 100, 20), input_data=dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {
    "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6"
   },
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10b3ef35",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765160324509,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "10b3ef35"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size,\n",
    "                 num_layers=1,\n",
    "                 bidirectional=False, # Decoder는 토큰을 하나씩 생성. 뒤에 토큰들을 알지 못하기 때문에 단방향 처리.\n",
    "                 dropout=0.2\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout = dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(\n",
    "            hidden_size,  # 입력 - gru의 마지막 hidden state값.\n",
    "            vocab_size    # 출력 - 다중분류: 어휘사전의 단어들 중 다음 단어 한개를 찾는 다중분류\n",
    "        )\n",
    "\n",
    "    def forward(self, X, hidden):\n",
    "        \"\"\"\n",
    "        X: 한 개 토큰. shape: [batch]\n",
    "        hidden: 이전 처리 hidden state. 첫번째 timestep: Encoder의 context vector\n",
    "                [seq_length: 1, batch, hidden_size]\n",
    "        \"\"\"\n",
    "        # [batch] -> [batch, 1]  1: seq_length\n",
    "        X = X.unsqueeze(1)\n",
    "        embedding_vector = self.embedding(X) # 입력: int64, [batch, seq_length(1)]\n",
    "\n",
    "        # [batch, seq_length(1), embedding_dim] -> [seq_length(1), batch, embedding_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0)\n",
    "\n",
    "        # [seq_length(1), batch, embedding_dim] -> out, hidden\n",
    "        #  out(모든 timestep의 hidden state 모음): [seq_length(1), batch_size, hidden_size]\n",
    "        #  hidden(마지막 timestep의 hidden state): [num_layers, batch_size, hidden_size]\n",
    "        out, hidden = self.gru(embedding_vector, hidden)\n",
    "\n",
    "        # Linear(분류기) 넣어서 다음 단어를 예측\n",
    "        last_out = self.classifier(out[-1])\n",
    "\n",
    "        # last_out: 다음 단어일 확률. [batch, vocab_size]\n",
    "        # hidden: 다음 단어를 예측할 때 넣어줄 context vector(hidden state)\n",
    "        return last_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e27e9182",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1765160446772,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "e27e9182",
    "outputId": "12a64b72-e608-41b9-ed7d-7ccaa9006a7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Decoder                                  [64, 10000]               --\n",
       "├─Embedding: 1-1                         [64, 1, 200]              2,000,000\n",
       "├─GRU: 1-2                               [1, 64, 200]              241,200\n",
       "├─Linear: 1-3                            [64, 10000]               2,010,000\n",
       "==========================================================================================\n",
       "Total params: 4,251,200\n",
       "Trainable params: 4,251,200\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 272.08\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 5.32\n",
       "Params size (MB): 17.00\n",
       "Estimated Total Size (MB): 22.38\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.ones([64], dtype=torch.int64, device=device)  # 64: batch\n",
    "dummy_hidden = torch.ones((1, 64, 200), dtype=torch.float32, device=device)\n",
    "# hidden shape: [1-gru layer 개수, 64: batch, 200: hidden_size]\n",
    "# gru layer 개수: num_layers * 2 if bidirectional else 1\n",
    "\n",
    "dummy_decoder = Decoder(10000, 200, 200, num_layers=1).to(device)\n",
    "summary(dummy_decoder, input_data=(dummy_input, dummy_hidden), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eff7b81d",
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1765160484137,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "eff7b81d"
   },
   "outputs": [],
   "source": [
    "next_word, hidden = dummy_decoder(dummy_input, dummy_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1d95199",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765160484809,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "b1d95199",
    "outputId": "51afe7d0-49df-465c-ecf0-8756c39edfff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10000])\n",
      "torch.Size([1, 64, 200])\n"
     ]
    }
   ],
   "source": [
    "print(next_word.shape)\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1765160485725,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "52cdf137-057b-4e41-95cd-c58219032b67",
    "outputId": "9e5bf241-f499-48d6-c972-8244b5c85b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762,\n",
       "        2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762,\n",
       "        2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762,\n",
       "        2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762,\n",
       "        2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762, 2762,\n",
       "        2762, 2762, 2762, 2762], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word.max(dim=-1).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {
    "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac"
   },
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성한다.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법이다.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습할 수있다.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2580464a",
   "metadata": {
    "id": "2580464a",
    "outputId": "339a3bd5-07b6-4341-994d-2657d1d079c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id(\"<sos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4acaa23d",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1765160500142,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "4acaa23d"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SOS_TOKEN = tokenizer.token_to_id(\"<sos>\")\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: 질문. (batch, seq_length)\n",
    "            outputs: 답변(정답). (batch, seq_length) -> teacher forcing 때 사용.\n",
    "            teacher_forcing_rate: teacher forcing은 random하게 적용. 적용될 확률.\n",
    "        \"\"\"\n",
    "        # 질문과 답변이 1차원일 경우 2차원으로 reshape\n",
    "        # if [seq_length] -> [batch(1), seq_length]\n",
    "        if inputs.dim() == 1:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        if outputs.dim() == 1:\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "\n",
    "        batch_size, output_length = outputs.shape # output_length: output의 max_length. 답변문장의 토큰수를 여기에 맞출것.\n",
    "        output_vocab_size = self.encoder.vocab_size\n",
    "\n",
    "        ######################################\n",
    "        # 생성된 문장을 저장할 tensor를 생성 (모델이 생성한 예측 문장)\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        # [나는, 학생, 이다.]\n",
    "        # [\n",
    "        #   vocab_size의 각 단어가 \"나는\"일 확률\n",
    "        #   vocab_size의 각 단어가 \"학생\"일 확률\n",
    "        #   vocab_size의 각 단어가 \"이다\"일 확률\n",
    "        # ]\n",
    "        ######################################\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "\n",
    "        ##################################################################\n",
    "        # 추론\n",
    "        #  1. encoder를 이용해서 context vector 추출(한번에 처리)\n",
    "        #  2. decoder를 이용해서 답변 문장을 생성(개별 토큰별로 생성.)\n",
    "        ##################################################################\n",
    "        # encoder를 이용해서 context vector 추출\n",
    "        encoder_out, _ = self.encoder(inputs) # encoder_out: 전체 hidden state 모음\n",
    "\n",
    "        # context vector == encoder_out[-1] => Decoder에 첫번째 timestep의 hidden으로 입력\n",
    "        decoder_hidden = encoder_out[-1].unsqueeze(0)\n",
    "        # decoder에 입력할 첫번째 timestep의 값: <sos> 토큰 id\n",
    "        decoder_input = torch.full([batch_size], fill_value=SOS_TOKEN, device=self.device)\n",
    "\n",
    "        ###########################################\n",
    "        # Decoder를 이용해서 한 단어(토큰)씩 생성\n",
    "        ###########################################\n",
    "        for t in range(output_length):\n",
    "            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            predicted_outputs[t] = decoder_out # t번째 예측 단어\n",
    "\n",
    "            # 다음 timestep의 input을 생성 (decoder_input값을 생성)\n",
    "            # teacher forcing 적용     -> t 번째 정답 토큰\n",
    "            #                 적용안함  -> Decoder 가 생성한 decoder_out의 token id값.\n",
    "            # teacher_forcing_rate 비율로 teacher forcing을 적용\n",
    "            teacher_forcing = teacher_forcing_rate > random.random()\n",
    "            teacher_forcing_rate *= 0.99 # 반복하면서 teacher forcing 적용 확률을 줄여나간다.\n",
    "\n",
    "            top1 = decoder_out.argmax(dim=-1) # 다음 단어일 확율이 가장 높은 단어의 토큰ID\n",
    "            decoder_input = outputs[:, t] if teacher_forcing else top1\n",
    "\n",
    "        return predicted_outputs.transpose(1, 0) # [seq_length <-> batch, vocab_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {
    "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb"
   },
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {
    "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7"
   },
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1aba84d5",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765160503710,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "1aba84d5"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 정의\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "encoder_bidirectional = True # 인코더는 양방향.\n",
    "encoder_hidden_size = 200\n",
    "\n",
    "# encoder의 hidden(context vector)과 decoder hidden을 맞춰준다.\n",
    "decoder_hidden_size = encoder_hidden_size * 2 if encoder_bidirectional else encoder_hidden_size\n",
    "\n",
    "embedding_dim = 256\n",
    "teacher_forcing_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bce8d66",
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1765160513169,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "1bce8d66"
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "encoder = Encoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=encoder_hidden_size,\n",
    "    num_layers=1,\n",
    "    bidirectional=encoder_bidirectional\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=decoder_hidden_size,\n",
    "    num_layers=1\n",
    ")\n",
    "seq2seq = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43e09ab6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1765160533006,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "43e09ab6",
    "outputId": "362c97bc-f8ff-4d60-d7b9-459bb3e1d24b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Seq2Seq                                  [64, 30, 7044]            --\n",
       "├─Encoder: 1-1                           [30, 64, 400]             --\n",
       "│    └─Embedding: 2-1                    [64, 30, 256]             1,803,264\n",
       "│    └─GRU: 2-2                          [30, 64, 400]             549,600\n",
       "├─Decoder: 1-2                           [64, 7044]                --\n",
       "│    └─Embedding: 2-3                    [64, 1, 256]              1,803,264\n",
       "│    └─GRU: 2-4                          [1, 64, 400]              789,600\n",
       "│    └─Linear: 2-5                       [64, 7044]                2,824,644\n",
       "├─Decoder: 1-3                           [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-6                    [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-7                          [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-8                       [64, 7044]                (recursive)\n",
       "├─Decoder: 1-4                           [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-9                    [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-10                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-11                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-5                           [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-12                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-13                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-14                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-6                           [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-15                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-16                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-17                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-7                           [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-18                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-19                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-20                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-8                           [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-21                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-22                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-23                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-9                           [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-24                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-25                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-26                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-10                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-27                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-28                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-29                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-11                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-30                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-31                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-32                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-12                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-33                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-34                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-35                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-13                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-36                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-37                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-38                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-14                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-39                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-40                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-41                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-15                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-42                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-43                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-44                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-16                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-45                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-46                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-47                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-17                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-48                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-49                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-50                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-18                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-51                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-52                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-53                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-19                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-54                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-55                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-56                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-20                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-57                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-58                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-59                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-21                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-60                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-61                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-62                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-22                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-63                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-64                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-65                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-23                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-66                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-67                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-68                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-24                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-69                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-70                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-71                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-25                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-72                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-73                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-74                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-26                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-75                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-76                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-77                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-27                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-78                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-79                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-80                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-28                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-81                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-82                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-83                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-29                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-84                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-85                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-86                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-30                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-87                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-88                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-89                      [64, 7044]                (recursive)\n",
       "├─Decoder: 1-31                          [64, 7044]                (recursive)\n",
       "│    └─Embedding: 2-90                   [64, 1, 256]              (recursive)\n",
       "│    └─GRU: 2-91                         [1, 64, 400]              (recursive)\n",
       "│    └─Linear: 2-92                      [64, 7044]                (recursive)\n",
       "==========================================================================================\n",
       "Total params: 7,770,372\n",
       "Trainable params: 7,770,372\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 11.57\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 128.35\n",
       "Params size (MB): 31.08\n",
       "Estimated Total Size (MB): 159.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_input = torch.zeros((64, 30), dtype=torch.int64).to(device)\n",
    "\n",
    "summary(seq2seq, input_data=(d_input, d_input), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {
    "id": "6ba83263-e042-4579-9784-2403eb3c3fa1"
   },
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8000c89",
   "metadata": {
    "executionInfo": {
     "elapsed": 5527,
     "status": "ok",
     "timestamp": 1765160565763,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "e8000c89"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model = seq2seq.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {
    "id": "6a659df1-87a2-4fe0-a095-e031ed130e68"
   },
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8d12a24",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1765160567570,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "c8d12a24"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, device, teacher_forcing_rate=0.9):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X, y, teacher_forcing_rate) # seq2seq\n",
    "        # pred: [batch, seq_length, vocab_size]\n",
    "        # pred: [batch * seq_length, vocab_size]\n",
    "        y_hat = pred.reshape(-1, pred.shape[2]) # loss 계산을 위해서\n",
    "        y = y.reshape(-1)  # [batch, seq_length] -> [batch * seq_length]\n",
    "        # CrossEntropyLoss입력: 정답 - [batch,], 추론: [batch, class개수-vocab_size]\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {
    "id": "8981388d-ad33-4318-844b-29a5a434d2a7"
   },
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab2c9109",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765160570153,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "ab2c9109"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X, y, teacher_forcing_rate=0.0) # tearcher forcing 적용하면 안됨.\n",
    "        y_hat = pred.reshape(-1, pred.shape[-1])\n",
    "        y = y.reshape(-1)\n",
    "        eval_loss += loss_fn(y_hat, y).item()\n",
    "\n",
    "    return eval_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {
    "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b5b463d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331002,
     "status": "ok",
     "timestamp": 1765160913639,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "7b5b463d",
    "outputId": "c1758e3b-ec54-4bf4-e70a-5bc9adcc0347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 에서 저장--------------\n",
      "1 1.8405789920261928 1.581171953678131\n",
      "2 1.3332557630538941 1.7026333212852478\n",
      "3 1.2094926357269287 1.7753680109977723\n",
      "4 1.0700290741239276 1.9077330470085143\n",
      "5 0.9214714384078979 1.9321029424667358\n",
      "6 0.7784584266798836 2.056926953792572\n",
      "7 0.6635004442078727 2.098116946220398\n",
      "8 0.5613568793024336 2.1436828136444093\n",
      "9 0.48911329065050396 2.275307846069336\n",
      "10 0.4019744554587773 2.280193340778351\n",
      "11 0.3385529840844018 2.395860195159912\n",
      "12 0.2909469256230763 2.4719274759292604\n",
      "13 0.26449664294719694 2.5078150987625123\n",
      "14 0.22655549126011984 2.563248109817505\n",
      "15 0.17411650495869774 2.527349758148193\n",
      "16 0.15247284901993616 2.6093538284301756\n",
      "17 0.12158655728612627 2.6760928869247436\n",
      "18 0.0949666325535093 2.7431278944015505\n",
      "19 0.08234336584806443 2.8091658115386964\n",
      "20 0.06426235345857484 2.8667532205581665\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "model_save_path = \"saved_models/chatbot_seq2seq.pth\"\n",
    "# 가장 validation loss 가 좋은 모델을 저장.\n",
    "best_loss = torch.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn,\n",
    "                       device, teacher_forcing_rate)\n",
    "    eval_loss = eval(model, test_loader, loss_fn, device)\n",
    "\n",
    "    if best_loss > eval_loss: # 성능개선\n",
    "        torch.save(model, model_save_path)\n",
    "        print(epoch+1, \"에서 저장--------------\")\n",
    "        best_loss = eval_loss\n",
    "\n",
    "    print(epoch+1, train_loss, eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "L5nC7S24ylQz",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1765161112500,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "L5nC7S24ylQz"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'saved_models/chatbot_seq2seq_last_train.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627557f",
   "metadata": {
    "id": "4627557f"
   },
   "outputs": [],
   "source": [
    "## 저장 모델 Load\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# map_location=device : 다른 device에 학습/저장한 모델을 읽어올 때 현재 device를 지정해서  현재 device에 맞춰 load하도록한다.\n",
    "best_model = torch.load(model_save_path, weights_only=False, map_location=device)\n",
    "best_model.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {
    "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00"
   },
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894",
   "metadata": {
    "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894"
   },
   "source": [
    "- Sampler:\n",
    "    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n",
    "    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4cfa6",
   "metadata": {
    "id": "56c4cfa6"
   },
   "outputs": [],
   "source": [
    "# ds = Dataset(....)\n",
    "\n",
    "# d_loader = DataLoader(ds, 200, shuffle=True)\n",
    "# index = [0 ~ 999]\n",
    "# 1. new_idx = shuffle(index) [920, 1, 87, 237, ..]  0 ~ 199, 200 ~ 399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eff6bedd",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765161164003,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "eff6bedd"
   },
   "outputs": [],
   "source": [
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('##')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 ##는 내 ##꺼 ##야\" ==> \"이 기회는 내꺼야\"\n",
    "\n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열.\n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    tokens = decoded_string.split() # 공백기준으로 토큰화.\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"): # 연결 토큰\n",
    "            if new_tokens: # len(new_tokens) != 0 원소가 하나라도 있으면\n",
    "                # 토큰에서 ##을 제거하고 리스트의 마지막 원소(문자열) 뒤에 붙인다.\n",
    "                new_tokens[-1] += token[2:]\n",
    "            else: # new_tokens가 빈 리스트. 현재 token이 첫번째 단어. ##을 지우고 append\n",
    "                new_tokens.append(token[2:])\n",
    "        else: # 단어의 시작인 토큰. (##이 없는 토큰) -> list에 추가.\n",
    "            new_tokens.append(' '+token)\n",
    "\n",
    "    return \"\".join(new_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0822c18",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1765161168126,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "a0822c18"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "# sampler는 “Dataset에서 어떤 순서로 index를 뽑을지 결정하는 객체”이다. DataLoader는 sampler가 제공하는 index를 이용해 Dataset에서 데이터를 추출한다.\n",
    "## shuffle=True 이면 RandomSampler가 사용된다. False이면 SequentialSampler가 사용된다.\n",
    "\n",
    "\n",
    "#  dataset에서 일부 데이터들을 가지고 확인\n",
    "def random_evaluation(model, dataset, device, n=10):\n",
    "    \"\"\"\n",
    "    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n",
    "    Parameter\n",
    "        model: 학습된 seq2seq 모델\n",
    "        dataset: 질문-답변 쌍울 추출할 dataset\n",
    "        device\n",
    "        n: int - 추출할 질문-답변 쌍 개수 default: 10\n",
    "    \"\"\"\n",
    "    ## 평가할 데이터셋을 만들기\n",
    "    n_samples = len(dataset)       # Dataset의 총 데이터개수\n",
    "    # index = list(range(n_samples)) # Dataset의 index만들기.  [0, 1, 2, ...., dataset_length]\n",
    "    # np.random.shuffle(index)       # 값들을 랜덤하게 섞어준다. [100, 23, 590, 10, ...]\n",
    "    # sample_index = index[ : n]     # 평가할 데이터 개수만큼 index 생성.\n",
    "\n",
    "    sample_index = torch.randint(0, n_samples, size=[n])\n",
    "\n",
    "    # Dataloader 생성\n",
    "    # SubsetRandomSampler: 지정한 index들 안에서 random한 순서로 제공.\n",
    "    # sample_index=[1, 20, 4, 5, 100], dataset에서 [1, 20, 4, 5, 100] index의 값만 추출\n",
    "    sampler = SubsetRandomSampler(sample_index)\n",
    "    sample_loader = DataLoader(dataset, batch_size=n, sampler=sampler)\n",
    "\n",
    "    ## 추론 후 확인\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in sample_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X, y, 0.0) # [batch, seq_len, vocab_size]\n",
    "\n",
    "            # torch.Tensor -> ndarray (tokenizer decode에 넣기 위해.)\n",
    "            ## tensor를 cpu로 이동후 변환가능.\n",
    "            ### tensor가 grad를 가지고 있으면(계산그래프에 포함되 있으면)\n",
    "            ####                               -> tensor.detach().cpu().ndarray()\n",
    "\n",
    "            pred = output.cpu().numpy()  # X.to(\"cpu\") # 모델추정 답변\n",
    "            X = X.cpu().numpy()   # 정답-질문\n",
    "            y = y.cpu().numpy()   # 정답-답변 (batch, seq_len, vocab)\n",
    "\n",
    "            for i in range(n):\n",
    "                q = handle_special_tokens(tokenizer.decode(X[i]))\n",
    "                a = handle_special_tokens(tokenizer.decode(y[i]))\n",
    "                p = handle_special_tokens(tokenizer.decode(pred[i].argmax(-1)))\n",
    "                print(f\"질문: {q}\")\n",
    "                print(f\"정답: {a}\")\n",
    "                print(f\"예측: {p}\")\n",
    "                print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1765161303132,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
    "outputId": "dd6ebcb1-b852-49ff-df68-6a317ec3bd76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:  코골이 어떻게 고쳐 ?\n",
      "정답:  피곤한건 아닌지 살펴보세요 .\n",
      "예측:  피곤한건 아닌지 살펴보세요 .\n",
      "==================================================\n",
      "질문:  남자친구의 입냄새가 고민이야 .\n",
      "정답:  가글 사줘요 .\n",
      "예측:  가글 사줘요 .\n",
      "==================================================\n",
      "질문:  수백번 싸우고 수백번 화해\n",
      "정답:  너무 안맞으면 헤어지는 것이 서로에게 도움이 될지도 몰라요 .\n",
      "예측:  너무 안맞으면 헤어지는 것이 서로에게 도움이 될지도 몰라요 .\n",
      "==================================================\n",
      "질문:  저도 연애하고 결혼할 수 있을까\n",
      "정답:  더 좋은 사람 만나서 알콩달콩 연애하고 행복한 결혼생활 할 수 있을 거예요 .\n",
      "예측:  더 좋은 사람 만나서 알콩달콩 연애하고 행복한 결혼생활 할 수 있을 거예요 .\n",
      "==================================================\n",
      "질문:  심리상담 받았어\n",
      "정답:  잘 다녀오셨어요 .\n",
      "예측:  잘 다녀오셨어요 .\n",
      "==================================================\n",
      "질문:  나혼자 설레발 치는게 짜증나 .\n",
      "정답:  짝사랑이 그런가봐요 .\n",
      "예측:  짝사랑이 그런가봐요 .\n",
      "==================================================\n",
      "질문:  청강하려고\n",
      "정답:  열심히 하네요 .\n",
      "예측:  열심히 하네요 .\n",
      "==================================================\n",
      "질문:  억지로 붙여놓은 깨어진 도자기\n",
      "정답:  언제 깨질지 모르겠어요 .\n",
      "예측:  언제 깨질지 모르겠어요 .\n",
      "==================================================\n",
      "질문:  사진을 보다가\n",
      "정답:  많은 생각이 나겠네요 .\n",
      "예측:  많은 생각이 나겠네요 .\n",
      "==================================================\n",
      "질문:  내 여자친구 아이돌이야\n",
      "정답:  어머어머 궁금하네요 .\n",
      "예측:  어머어머 궁금하네요 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_evaluation(model, train_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "VWWz8B4v0Bps",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1765161364643,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "VWWz8B4v0Bps",
    "outputId": "08935599-8a31-4502-f314-b854e5c5ab69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:  멋지게 나이들고 싶다\n",
      "정답:  지금도 그러고 있어요 .\n",
      "예측:  열심히 하면 할 수 있을 거예요 .\n",
      "==================================================\n",
      "질문:  썸 타다 늙어 죽을 듯\n",
      "정답:  속 타 죽기 전에 표현해보세요 .\n",
      "예측:  주변 사람들에게 부탁해보세요 .\n",
      "==================================================\n",
      "질문:  헤어지는게 편하겠죠 ?\n",
      "정답:  자신을 위해 좋은 걸 하세요 .\n",
      "예측:  노후는 지금부터 준비하는 게 좋죠 .\n",
      "==================================================\n",
      "질문:  아직 아주 많이 사랑하는데 나는 말야\n",
      "정답:  그분도 그랬을거예요 .\n",
      "예측:  질투하지 마세요 .\n",
      "==================================================\n",
      "질문:  4년 반이라는 시간이 이렇게 끝나네 .\n",
      "정답:  사랑은 끝나도 당신의 시간은 여전히 진행 중인 걸 잊지 마세요 .\n",
      "예측:  많은 준비가 필요해보여요 .\n",
      "==================================================\n",
      "질문:  애프터까지 왔는데 연락이 뜸해 .\n",
      "정답:  바쁘거나 감정의 변화가 생겼을지도 모르겠어요 .\n",
      "예측:  먼저 연락해 보는건 어떨까요 ?\n",
      "==================================================\n",
      "질문:  5년간 사귀고 이별\n",
      "정답:  생각을 비워보세요 .\n",
      "예측:  전역해서 더 좋은 사람 만날 수 있을 거예요 .\n",
      "==================================================\n",
      "질문:  내 생각을 하고는 있을까 ?\n",
      "정답:  궁금해하지마세요 .\n",
      "예측:  인내할 수 있는 사람이라면 무엇이든 손에 넣을 수 있을 거예요 .\n",
      "==================================================\n",
      "질문:  메모하는 습관을 기르고 싶어\n",
      "정답:  오늘부터 하기로 해요 .\n",
      "예측:  좋은 곳에서 일하시나봐요 .\n",
      "==================================================\n",
      "질문:  생강차 먹어야겠다\n",
      "정답:  따뜻하게 드세요 .\n",
      "예측:  차가운 음료 너무 많이 마시면 아니 되어요\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_evaluation(model, test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "S3CUea2v0i-M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1765161536157,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "S3CUea2v0i-M",
    "outputId": "a6ed80cc-8651-4176-cd30-c11e34d6d9a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8134)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(torch.tensor(0.06))\n",
    "# tensor(2.8134)\n",
    "# 2.8667532205581665\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {
    "id": "3c4965d1-a305-4465-8f64-f689d55490ac"
   },
   "source": [
    "# 학습모델을 이용한 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f5dea07",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1765161969885,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "8f5dea07"
   },
   "outputs": [],
   "source": [
    "class ChatbotInputDataset(Dataset):\n",
    "    \"\"\"\n",
    "    질문만 받아서 생성하는 Dataset\n",
    "    - 새로운 데이터 추론용.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "\n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "\n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length 크기에 맞춘다.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 질문만 반환.\n",
    "        q = self.question_texts[index]  # List\n",
    "\n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다.\n",
    "        return torch.tensor(q, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5313038f",
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1765162151346,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "5313038f"
   },
   "outputs": [],
   "source": [
    "# 질문:  내 여자친구 아이돌이야\n",
    "# 정답:  어머어머 궁금하네요 .\n",
    "\n",
    "input_data = [\n",
    "    \"난 가족들과 주말에 여행갈 거야.\",\n",
    "    \"와! 내일 주말이다.\",\n",
    "    \"너무 피곤하네요. 좀 쉬었으면 좋겠어요.\",\n",
    "    \"지금 몇시에요.\",\n",
    "    \"여자 친구와 내일 저녁에 만나기로 했어.\",\n",
    "    \"여자친구 아이돌이야\",\n",
    "    \"내 여자친구는 아이돌이야.\"\n",
    "]\n",
    "input_dataset = ChatbotInputDataset(input_data, max_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55c89f81",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765162151810,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "55c89f81"
   },
   "outputs": [],
   "source": [
    "def predict(dataset, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for X in dataset:  # Dataset에서 한 질문씩을 조회\n",
    "            X = X.to(device)\n",
    "            output = model(X.unsqueeze(0), X.unsqueeze(0), 0.0)\n",
    "            pred = output.cpu().numpy()\n",
    "            X = X.cpu().numpy()\n",
    "            q = handle_special_tokens(tokenizer.decode(X))\n",
    "            a = handle_special_tokens(tokenizer.decode(pred[0].argmax(-1)))\n",
    "            print(f\"질문: {q}\")\n",
    "            print(f\"예상답: {a}\")\n",
    "            print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c1150a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1765162152513,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "f5c1150a",
    "outputId": "2a930b56-1050-4876-d896-0e653f37cbc6"
   },
   "outputs": [],
   "source": [
    "predict(input_dataset, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "IyTJLfSC8V3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17215,
     "status": "ok",
     "timestamp": 1765163514251,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "IyTJLfSC8V3e",
    "outputId": "1152d78e-1ea6-42ee-dd3c-dfe64b456b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JUDA_9309DGJ",
   "metadata": {
    "id": "JUDA_9309DGJ"
   },
   "outputs": [],
   "source": [
    "# 저장된 모델, 데이터 디렉토를 구글드라이브로 복사\n",
    "## 구글드라이브 연결\n",
    "## 저장할 구글드라이브 디렉토리의 경로복사\n",
    "## !cp 원본 타겟\n",
    "## 디렉토리채 복사: !cp -r 원본 타겟\n",
    "\n",
    "# 학습데이터셋: 구글드라이브에 저장 후 학습할 때 코랩으로 복사\n",
    "# 모델 저장:    학습 도중 저장할 경우 코랩에 저장하고 끝나면\n",
    "#               구글드라이브로 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0IxVs4pJ9WKV",
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1765163786533,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "0IxVs4pJ9WKV"
   },
   "outputs": [],
   "source": [
    "!cp -r data \"/content/drive/MyDrive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ltjUHK1_9fYJ",
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1765163802136,
     "user": {
      "displayName": "김성환",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "ltjUHK1_9fYJ"
   },
   "outputs": [],
   "source": [
    "!cp -r saved_models \"/content/drive/MyDrive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11e63575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩에서 학습한 모델 load\n",
    "# Encoder, Decoder, Seq2Seq 클래스 정의는 실행해서 메모리에 올린다.\n",
    "import torch\n",
    "\n",
    "load_model = torch.load(\n",
    "    \"saved_models/chatbot_seq2seq_last_train.pth\",\n",
    "    weights_only=False,\n",
    "    map_location=device    \n",
    ")\n",
    "load_model.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:  난 가족들과 주말에 여행갈 거야 .\n",
      "예상답:  충분히 중독엇 해요 .\n",
      "=========================================================\n",
      "질문:  와 ! 내일 주말이다 .\n",
      "예상답:  갖지 공부해서 .\n",
      "=========================================================\n",
      "질문:  너무 피곤하네요 . 좀 쉬었으면 좋겠어요 .\n",
      "예상답:  매키하게 돌아애상 걸릴 쉽지 않은 일부터 .\n",
      "=========================================================\n",
      "질문:  지금 몇시에요 .\n",
      "예상답:  마음이 허지지 .\n",
      "=========================================================\n",
      "질문:  여자 친구와 내일 저녁에 만나기로 했어 .\n",
      "예상답:  당당하게야 생각해요 .\n",
      "=========================================================\n",
      "질문:  여자친구 아이돌이야\n",
      "예상답:  이제 귀엽게 떨쳐 .\n",
      "=========================================================\n",
      "질문:  내 여자친구는 아이돌이야 .\n",
      "예상답:  이제 그녀를 놓아주세요 .\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# ChatbotInputDataset 실행. handle_special_tokens(), predict() 함수 정의 실행.\n",
    "predict(input_dataset, load_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76656f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f013c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda36542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
