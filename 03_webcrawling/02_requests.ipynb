{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# requests 모듈을 이용한 웹 요청\n",
    "- [Requests 홈페이지](https://requests.kennethreitz.org/en/master/)\n",
    "- **HTTP 요청과 응답을 처리하는 파이썬 패키지**\n",
    "- get/post 요청 방식을 모두 지원하며 요청시 설정해야 하는 헤더정보, 쿠키정보 설정등 HTTP요청을 위한 모든 기능을 지원한다.\n",
    "- 설치\n",
    "    - `pip install requests`\n",
    "\n",
    "> HTTP 요청 방식(HTTP Method) \n",
    "> - HTTP 프로토콜은 클라이언트가 서버에 요청하는 목적에 따라 다음과 같은 방식을 정의한다.\n",
    ">     - GET, POST, PUT, PATCH, DELETE, HEADER, OPTIONS, TRACE, CONECT\n",
    ">         - 전통적인 Web은 GET과 POST 방식 지원하는데 Restful 기반 API에서는 GET, POST, PUT, PATCH, DELETE를 이용한다.\n",
    ">     - GET: 기본 요청방식으로 서버가 가진 데이터를 요청한다. (RETRIEVE)\n",
    ">     - POST: 클라이언트의 데이터를 서버에 전송(저장)한다. (CREATE)\n",
    ">     - PUT: 서버가 가진 데이터를 클라이언트가 전송한 데이터로 변경한다. (UPDATE - 전체 변경)\n",
    ">     - PATCH: 서버가 가진 데이터의 일부를 클라이언트가 전송한 데이터로 변경한다. (UPDATE - 부분 변경)\n",
    ">     - DELETE: 서버의 데이터를 삭제한다. (DELETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling을 위한 requests 코딩 패턴\n",
    "1. requests의 get()/post() 함수를 이용해 url을 넣어 서버 요청한다.\n",
    "2. 응답받은 내용(일반적으로 HTML 페이지)을 처리.\n",
    "    - text(HTML)은 BeautifulSoup를 이용해 원하는 내용을 추출한다.\n",
    "    - binary 파일(text를 제외한 모든 파일-이미지, 동영상등)의 경우 파일출력을 이용해 local에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 요청 함수\n",
    "- HTTP 요청 방식에 따라 두개 함수를 사용.\n",
    "- get(): GET방식 요청\n",
    "    - GET 방식(기본방식): 목적 - client가 자원을 요청하는 것 목적(달라는 것.)\n",
    "- post(): POST방식 요청\n",
    "    - POST 방식: 목적 - client가 자기의 자원을 server로 전송하는 것이 목적."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### requests.get(URL)\n",
    "- **GET 방식 요청**\n",
    "- **주요 매개변수**\n",
    "    - params: 요청파라미터를 dictionary로 전달\n",
    "    - headers: HTTP 요청 header를 dictionary로 전달\n",
    "        - 'User-Agent', 'Referer' 등 헤더 설정\n",
    "        - 크롤링을 하기 위해 필요한 header 정보는 웹브라우저의 개발자 도구를 이용해 확인한다. (Network 탭에서 확인)\n",
    "    - cookies: 쿠키정보를 전달\n",
    "- **반환값(Return Value)**\n",
    "    - [Response](#Response객체): 응답결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests.post(URL)\n",
    "- **POST 방식 요청**\n",
    "- **주요 매개변수**\n",
    "    - datas : 요청파라미터를 dictionary로 전달\n",
    "    - files : 업로드할 파일을 dictionary로 전달\n",
    "        - key: 이름, value: 파일과 연결된 InputStream(TextIOWrapper)\n",
    "    - headers: HTTP 요청 header를 dictionary로 전달\n",
    "        - 'User-Agent', 'Referer' 등 헤더 설정\n",
    "    - cookies: 쿠키정보를 전달\n",
    "- **반환값(Return Value)**\n",
    "    - [Response](#Response객체): 응답결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ### 요청파라미터(Request Parameter)\n",
    "> - 요청파라미터란\n",
    ">     - 서버가 일하기 위해 클라이언트로 부터 받아야 하는 값들\n",
    ">     - `name=value` 형식으로 클라이언트가 전달한다. 여러개일 경우 `&`로 연결해서 전송됨 (ex: page=1&keyword=test)\n",
    "> - Get 요청시 queryString 으로 전달\n",
    ">     - querystring: URL 뒤에 붙여서 전송하는 요청파라미터를 말한다.\n",
    ">     - URL 뒤에 ?를 붙이고 그 뒤에 요청파라미터를 붙여 구성한다. (`?`가 url과 요청파라미터를 구분하는 구분자로 사용된다.)\n",
    ">     - ex) https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=python\n",
    ">     - requests.get() 요청시 요청파라미터 전달하는 두가지 방법\n",
    ">         1. url 뒤에 querystring으로 붙여서 전송\n",
    ">         2. dictionary 에 name=value 형태로 만들어 매개변수 params에 전달\n",
    ">     - Post 요청시 요청정보의 body에 넣어 전달\n",
    ">         - requests.post() 요청시에는 dictionary로 구성한 뒤 매개변수 datas에 전달한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### HTTP 요청 헤더(Request Header)\n",
    "> HTTP 요청시 웹브라우저가 client의 여러 부가적인 정보들을 Key-Value 쌍 형식으로 전달한다.\n",
    "> - accept: 클라이언트가 처리가능한 content 타입 (Mime-type 형식으로 전달)\n",
    "> - accept-language: 클라이언트가 지원하는 언어(ex: ko, en-US)\n",
    "> - host: 요청한 host \n",
    "> - user-agent: 웹브라우저 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Response객체 -  응답데이터\n",
    "- get()/post() 의 요청에 대한 서버의 응답 결과를 Response 클래스의 객체에 담아 반환한다.\n",
    "    - Response객체의 속성(attribute)들을 이용해 서버가 응답결과를 조회할 수있다.\n",
    "- **주요 속성(Attribut)**\n",
    "    - **url**\n",
    "        - 응답한 서버의 url\n",
    "    - **status_code**\n",
    "        - HTTP 응답 상태코드\n",
    "    - **headers**\n",
    "        - 응답 header 정보로 dictionary로 반환한다.\n",
    "    - **응답 결과 데이터 조회**\n",
    "        - **text**\n",
    "            - 응답내용(html을 str로 반환)\n",
    "        - **content**\n",
    "            - 응답내용(응답결과가 binary-image, 동영상등-일 경우 사용하며 bytes 타입으로 반환한다.)\n",
    "        - **json()**\n",
    "            - 응답 결과가 JSON 인 경우 dictionary로 변환해서 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### JSON(JavaScript Object Notation)\n",
    "> key-value 형태 또는 배열 형태의 text이며 이 기종간 데이터 교환에 많이 사용된다. 자바스크립트 언어에서 Object와 array를 생성하는 문법을 이용해 만듬. \n",
    "> - [JSON 공식사이트](http://json.org)\n",
    ">\n",
    "> ### Python json 모듈\n",
    ">\n",
    "> JSON 형식 문자열을 다루는 파이썬 표준 모듈\n",
    "> - json.loads(json문자열)\n",
    ">    - JSON 형식 문자열을 dictionary로 변환\n",
    "> - json.dumps(dictionary)\n",
    ">    - dictionary를 JSON 형식 문자열로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### HTTP 응답 상태코드\n",
    "> - 서버의 응답 결과를 나타내는 세 자리 숫자 코드이다. 이 코드를 통해 요청이 성공적으로 처리되었는지, 오류가 발생했는지, 아니면 다른 조치가 필요한지 등을 클라이언트에게 알려준다.\n",
    "> - https://ko.wikipedia.org/wiki/HTTP_상태_코드\n",
    ">     - 2XX(200번대): 성공\n",
    ">         - 200: OK\n",
    ">     - 3XX: 다른 주소로 이동 (이사)\n",
    ">         - 300번대이면 자동으로 이동해 준다. 크롤링시는 사용할 일이이 별로 없다.\n",
    ">     - 4XX: 클라이언트 오류 (사용자가 잘못한 것)\n",
    ">       - 403: 권한 없음. (권한이 없는 사용자가 요청한 경우)\n",
    ">       - 404: 존재하지 않는 주소\n",
    ">       - 405: 잘못된 요청방식으로 요청한 경우.(예를들어 POST 요청을 받는 페이지를 GET방식으로 요청 하면 발생.)\n",
    ">     - 5XX: 서버 오류 (서버에서 문제생긴 것)\n",
    ">       - 500: 서버가 처리방법을 모르는 오류\n",
    ">       - 503: 서버가 다운 등의 문제로 서비스 불가 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 방식 요청 예제\n",
    "\n",
    "#### 네이버 검색 결과 가져오기\n",
    "- naver 검색 요청 url을 이용해 검색을 요청하고 그 결과를 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query={}\"\n",
    "keyword = input(\"keyword:\")\n",
    "url = url.format(keyword)\n",
    "\n",
    "res = requests.get(url)  # 요청 - 응답: 반환: 응답데이터\n",
    "\n",
    "print(res.status_code)\n",
    "if res.status_code == 200:\n",
    "    print(type(res))\n",
    "    print(type(res.text), len(res.text)) \n",
    "    print(res.text[:1000])\n",
    "else:\n",
    "    print(\"응답을 받지 못함.\", res.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### War and Peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "\n",
    "res = requests.get(url, headers={\"user-agent\":user_agent})\n",
    "\n",
    "if res.status_code == 200:\n",
    "\n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "    green_list = soup.select(\"span.green\")\n",
    "    search_names = []\n",
    "    for tag in green_list:\n",
    "        search_names.append(tag.text.replace(\"\\n\", ' '))\n",
    "else:\n",
    "    print(\"실패:\", res.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "search_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binary date 를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.kia.com/content/dam/kwp/kr/ko/main-kv-contents/202311/kv_the_new_carnival_pc.jpg\"\n",
    "\n",
    "res = requests.get(url, headers={\"user-agent\":user_agent})\n",
    "\n",
    "if res.status_code == 200:\n",
    "    file = res.content  # binary 데이터를 bytes 타입으로 반환.\n",
    "    print(type(file))\n",
    "    with open(\"image.jpg\", \"wb\") as fo:\n",
    "        fo.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daum New 목록 조회\n",
    "- https://news.daum.net 의 뉴스기사 목록에서 제목, 상세뉴스 url을 수집해서 csv 파일에 저장\n",
    "- 크롤링시 확인할 내용\n",
    "    - 요청 url을 파악한다.\n",
    "    - 페이지에서 수집할 내용을 찾는 방법을 웹브라우저 **개발자 도구를 이용해 찾는다.**\n",
    "    - 요청시 전달할 **요청정보들(header, cookie 등 정보) 를 개발자 도구를 이용해 찾는다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### CSV 형식 파일\n",
    "> - Comma Separate Value\n",
    "> - 정형(표형태) 데이터를 text 파일에 저장하는 방식(형식)\n",
    "> - 한행에 한개의 데이터를 저장\n",
    "> - 데이터를 구성하는 속성들은 \",\" 를 구분자로 나눠서 작성한다.\n",
    "> - 예\n",
    "> ```csv\n",
    "> 이름,나이,주소\n",
    "> 홍길동,20,인천\n",
    "> 이순신,15,서울\n",
    "> 강감찬,30,부산\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://news.daum.net\"\n",
    "# 뉴스제목: <a>의 content, 링크주소: <a>의 href 속성값\n",
    "a_selector = r\"#\\35 8d84141-b8dd-413c-9500-447b39ec29b9 > ul > li > a\"\n",
    "# user-agent: 1.개발자도구>콘솔: navigator.userAgent, 2. google검색: my user agent 검색\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "\n",
    "def get_daum_news_list():\n",
    "    \"\"\"\n",
    "    다음 뉴스 기사 목록을 크롤링하는 함수.\n",
    "    news.daum.net의 기사 목록에서 \"제목\", \"링크\" 들을 수집.\n",
    "\n",
    "    aguments\n",
    "    return\n",
    "        DataFrame: 조회결과들을 담은 DataFrame(표)\n",
    "    raise\n",
    "        Exception: 처리 실패시 발생\n",
    "    \"\"\"\n",
    "    # 1. 요청\n",
    "    res = requests.get(url, headers={\"user-agent\":user_agent})\n",
    "    # 한글 처리\n",
    "    res.encoding = \"utf-8\"\n",
    "    \n",
    "    # 2. 응답 페이지에서 필요한 정보 추출\n",
    "    if res.status_code == 200:\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "        a_list = soup.select(a_selector)\n",
    "        result_list = []\n",
    "        for a_tag in a_list:\n",
    "            # title = a_tag.get_text()\n",
    "            strong_tag = a_tag.select_one(\"strong.tit_txt\") # Tag.select() -> Tag 하위 태그에서 찾는다.\n",
    "            title = strong_tag.text\n",
    "            link = a_tag.get(\"href\")\n",
    "            result_list.append([title.strip(), link])\n",
    "        \n",
    "        return result_list\n",
    "    else:\n",
    "        raise Exception(f\"요청 실패. 응답코드: {res.status_code}\")      \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = get_daum_news_list()\n",
    "    # print(result)\n",
    "    \n",
    "    # 저장할 디렉토리를 생성\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    save_dir = \"daum_news_list\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # dir 생성\n",
    "    \n",
    "    # # 저장할 파일명 - 특정 기간마다 크롤링 수행할 경우 실행 날짜/시간을 이용해서 만들어 준다.\n",
    "    d = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    # print(d)\n",
    "    file_path = f\"{save_dir}/{d}.csv\"\n",
    "    # # DataFrame 생성\n",
    "    result_df = pd.DataFrame(result, columns=['제목', \"링크주소\"])\n",
    "    # # csv 파일로 저장.\n",
    "    result_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open API 를 이용\n",
    "\n",
    "Open API는 말 그대로 공개된 프로그래밍 인터페이스로, 외부 개발자나 사용자가 특정 서비스나 애플리케이션에 접근하여 서비스를 받을 수 있도록 공개된 API이다.\n",
    "\n",
    "## 정의\n",
    "\n",
    "Open API는 애플리케이션 개발자가 공개된 API를 사용해 다른 서비스와 애플리케이션을 연동할 수 있도록 만든 인터페이스이다. \n",
    "일반적으로 RESTful API 형식으로 서비스 한다.\n",
    "\n",
    "## 특징\n",
    "\n",
    "- 공개성: 누구나 접근할 수 있으며, 문서화가 잘 되어 있어 사용자가 쉽게 활용할 수 있음.\n",
    "- 표준화: 대부분 표준화된 HTTP 프로토콜과 JSON, XML 형식을 사용.\n",
    "- 보안성: API 키나 OAuth 같은 인증 방식으로 보안을 유지.\n",
    "\n",
    "## 사용 사례\n",
    "다양한 기업, 공공기관에서 다양한 서비스를 오픈 api로 제공한다. \n",
    "- 공공데이터 포털: 행정안전부에서 서비스하는 정부, 공공기관, 지자체 등이 보유한 데이터를 개방하고 제공하는 플랫폼.\n",
    "- 구글 맵 API: 외부 애플리케이션에서 구글 맵을 활용할 수 있게 해주는 대표적인 Open API.\n",
    "- 트위터 API: 트위터(X) 데이터를 외부에서 가져오거나 포스팅할 수 있도록 제공.\n",
    "- 네이버 개발자 오픈 API: 네이버의 다양한 서비스를 제공. (검색, 검색어 트랜드 조회, 캘린더 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공공데이터 포털 데이터 조회\n",
    "- 서비스를 받기위한 API 키를 신청한다.\n",
    "- 가이드에 따라 요청방식, 요청 URL, 전달 값을 맞춰 요청한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### JSON 형식 파일\n",
    "> - 데이터를 text파일에 저장하는 형식으로 Javascript 객체 표기법을 이용한다.\n",
    "> - 파이썬의 dictionary 표기법과 동일다.\n",
    "> - 파이썬은 json 표준 모듈을 이용해 처리한다.\n",
    ">     - json.dump(): dictionary를 json 형식 문자열로 변환\n",
    ">     - json.load(): json 파일을 읽어 dictionary로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "url = 'http://apis.data.go.kr/1613000/BUSINESS_CAR/T_OD_BUSINESS_CAR_BRN_INFO'\n",
    "with open('api_key.json', 'rt') as fr:\n",
    "    key_dict = json.load(fr)  # json 텍스트 -> dictionary: load()\n",
    "\n",
    "key = key_dict['apikey']\n",
    "params ={'serviceKey' : key,\n",
    "         'pageNo' : '1', \n",
    "         'numOfRows':'3',\n",
    "         'resultType':'json',\n",
    "         'crtr_yr': '2023',\n",
    "         'mtrpl_lcgv_nm': '서울'\n",
    "        }\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    # result = response.text\n",
    "    print(type(result))\n",
    "    from pprint import pprint\n",
    "    print(len(result['response']['body']['items']['item']))\n",
    "    pprint(result['response']['body']['items']['item'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
