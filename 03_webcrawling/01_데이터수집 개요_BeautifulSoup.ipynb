{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집에 도움이 되는 사이트\n",
    "\n",
    "- **국가 통계포털**\n",
    "    - https://kosis.kr\n",
    "    - 통계청에서 관리하는 공공데이터 포털로 다양한 카테고리의 국가 통계데이터를 제공한다.\n",
    "- **공공데이터 포털**\n",
    "    - https://www.data.go.kr\n",
    "    - 행정 안전부에서 제공하는 정부 데이터 포털\n",
    "- **Kaggle**\n",
    "    - https://kaggle.com\n",
    "    - 데이터과학 관련 경진대회 플랫폼\n",
    "    - 다양한 데이터들을 제공한다.\n",
    "- **구글 데이터셋 서치**\n",
    "    - https://datasetsearch.research.google.com\n",
    "    - 구글에서 제공하는 데이터셋 검색 사이트\n",
    "    - 키워드를 이용해 다양한 데이터셋을 검색하고 다운로드 받을 수 있다.\n",
    "- **AI Hub**\n",
    "    - https://aihub.or.kr\n",
    "    - 국내외 기관/기업에서 추진한 지능정보산업 인프라 조성사업에서 공개한 AI 학습용 데이터셋들을 제공한다.\n",
    "- **Roboflow Universe**\n",
    "    - https://universe.roboflow.com/\n",
    "    - Roboflow 라는 인공지능 회사에서 운영하는 데이터 저장소 사이트로 컴퓨터비전 관련 데이터셋을 주로 제공한다.\n",
    "- 기타\n",
    "    - **지자체**: 서울시 열린 데이터광장, 경기 데이터 드림\n",
    "    - **금융관련**: 한국거래소, 금융통계정보시스템등\n",
    "    - **영화관련**: 영화진흥위원회\n",
    "    - **대중교통**: 국가교통데이터베이스, 교통카드 빅데이터 통합정보시스템등    \n",
    "    - **관광관련**: 한국 관광 데이터랩등\n",
    "    - **날씨정보**: 기상청 기상자료 개방포털, 네이버 날씨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [크롬개발자 도구](https://developers.google.com/web/tools/chrome-devtools/)\n",
    "\n",
    "- 크롬 개발자 도구는 웹 개발 및 디버깅을 위한 강력한 도구로 크롬 웹브라우저에 내장되어 있다.\n",
    "    - `F12` 나 팝업 메뉴에서 `검사`를 선택한다.\n",
    "    - 엣지 브라우저도 같은 개발자 도구를 제공한다.\n",
    "- 웹 페이지의 HTML, CSS, JavaScript 코드를 검사하고 수정할 수 있으며, 네트워크 요청 응답 내용 분석, 성능 분석, 콘솔 로그 등 다양한 기능을 제공한다.\n",
    "- 주요 기능\n",
    "    - **요소 검사:** 웹 페이지의 특정 요소를 선택하여 HTML 구조, CSS 스타일, selector 등을 확인한다.\n",
    "    - **콘솔:** JavaScript 코드를 실행할 수 있고 Javascript 실행시 발생한 오류 메시지 등을 확인할 수 있다.\n",
    "    - **소스:** 웹 페이지의 JavaScript 코드를 확인할 수있고 디버깅을 위한 중단점(break point)를 설정하고 디버깅할 수 있다.\n",
    "    - **네트워크:** 웹 페이지를 요청할 때 발생하는 요청 및 응답 데이터를 분석하고 성능을 측정할 수 있다.\n",
    "    - **성능:** 웹 페이지의 로딩 시간, 렌더링 성능에 걸린 시간등을 분석할 수 있다.\n",
    "    - **애플리케이션:** 쿠키, 로컬 스토리지, 세션 스토리지 등 클라이언트 저장 데이터 확인 할 수 있다.\n",
    "- 개발자 도구는 크롤링 시 필수적인 도구이며, 수집할 페이지를 분석하는데 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "- Markup 언어 parsing 라이브러리\n",
    "    - HTML이나 XML 문서 내에서 원하는 정보를 가져오기 위한 파이썬 라이브러리.\n",
    "- https://www.crummy.com/software/BeautifulSoup/\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- 설치\n",
    "    - beautifulsoup4 설치\n",
    "        - pip install beautifulsoup4\n",
    "    - lxml 설치(html/xml parser)\n",
    "        - pip install lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install  beautifulsoup4  lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 코딩 패턴\n",
    "1. 조회할 HTML내용을 전달하여 BeautifulSoup 객체 생성 \n",
    "1. BeautifulSoup객체의 메소드들을 이용해 문서내에서 필요한 정보 조회\n",
    "    - 태그이름과 태그 속성으로 조회\n",
    "    - css selector를 이용해 조회\n",
    "    - . 표기법을 이용한 탐색(Tree 구조 순서대로 탐색)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup 객체 생성\n",
    "- BeautifulSoup(html str [, 파서])\n",
    "    - 매개변수\n",
    "        1. 정보를 조회할 html을 string으로 전달\n",
    "        2. 파서\n",
    "            - html.parser(기본파서)\n",
    "            - lxml : 매우 빠르다. html, xml 파싱 가능(xml 파싱은 lxml만 가능)\n",
    "                - 사용시 install 필요 \n",
    "                - `pip install lxml`\n",
    "                - install 후 커널 restart 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"example.html\", \"rt\", encoding='utf-8') as fr:\n",
    "    html_doc = fr.read()\n",
    "    \n",
    "print(html_doc[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정보를 추출할 웹문서의 내용을 str으로 전달.\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서내에서 원하는 정보 검색\n",
    "\n",
    "### Tag 객체\n",
    "- 하나의 태그(element)에 대한 정보를 다루는 객체.\n",
    "    - BeautifulSoup 조회 메소드들의 **조회결과의 반환타입.**\n",
    "    - 조회 함수들이 찾은 Element가 하나일 경우 **Tag 객체를, 여러개일 경우 Tag 객체들을 담은 List(ResultSet)**를 반환한다.\n",
    "    - Tag 객체는 찾은 정보를 제공하는 메소드와 Attribute를 가지고 있다. 또 찾은 Tag가 하위 element를 가질 경우 찾을 수 있는 조회 메소드를 제공한다.\n",
    "- 주요 속성/메소드\n",
    "    - **태그의 속성값 조회**\n",
    "        - `Tag객체.get('속성명')`\n",
    "        - `Tag객체['속성명']`\n",
    "        - ex) `tag.get('href')` 또는 `tag['href']`\n",
    "    - **태그내 text값 조회**\n",
    "        - `Tag객체.get_text()`\n",
    "        - `Tag객체.text`\n",
    "        - ex) tag.get_text() 또는 tag.text\n",
    "    - **contents 속성**\n",
    "        - 조회한 태그의 모든 자식 요소들을 리스트로 반환\n",
    "        - ex) `child_list = tag.contents`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 조회 함수\n",
    "- **태그의 이름으로 조회**\n",
    "    - `find_all()`\n",
    "    - `find()`\n",
    "- **css selector를 이용해 조회**\n",
    "    - `select(), select_one()`\n",
    "- **`.` 표기법(dot notation)**\n",
    "    - dom tree 구조의 계층 순서대로 조회\n",
    "    - 위의 두방식으로 찾은 tag를 기준으로 그 주위의 element 들을 찾을 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 태그의 이름으로 조회\n",
    "- **find_all**(name=태그명, attrs={속성명:속성값, ..})\n",
    "   - 이름의 모든 태그 element들을 리스트에 담아 반환.\n",
    "   - 여러 이름의 태그를 조회할 경우 List에 태그명들을 묶어서 전달한다.\n",
    "   - 태그의 attribute 조건으로만 조회할 경우 name을 생략한다. \n",
    "- **find**(name=태그명, attrs={속성명:속성값})\n",
    "    - 이름의 태그중 첫번째 태그 element를 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"example.html\", \"rt\", encoding=\"utf-8\") as fr:\n",
    "    html_doc = fr.read()\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(result))  # 조회 결과 개수\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag1 = result[0]\n",
    "print(\"content:\", tag1.text, tag1.get_text())\n",
    "print(\"class속성값:\", tag1.get(\"class\"), tag1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find(\"div\")  # 조회결과 1개만(첫번째 것) 반환.\n",
    "print(type(result))\n",
    "print(\"-\"*50)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그의 content와 attribute 조회\n",
    "\n",
    "print(\"content text:\", result.text)\n",
    "print(\"content text:\", result.get_text())\n",
    "print(\"attribue의 value:\", result.get(\"class\"))\n",
    "print(\"attribue의 value:\", result[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그의 모든 자식 요소들 조회\n",
    "result.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result = soup.find_all(\"a\")  # 태그 이름\n",
    "# result = soup.find_all([\"a\", \"span\"])  #한번에 여러이름의 태그드을 조회.\n",
    "# result = soup.find_all(\"div\", attrs={\"class\":\"name\"}) # 태그이름 + 속성\n",
    "# result = soup.find_all(\"div\", attrs={\"class\":\"animal_info\", \"id\":\"animal1\"}) # 속성 조건이 여러개\n",
    "# result = soup.find_all(\"a\", attrs={\"href\":\"https://www.coexaqua.com\"})\n",
    "\n",
    "# import re\n",
    "# result = soup.find_all(\"a\", attrs={\"href\":re.compile(r\"\\.html$\")}) # 정규표현식-.com으로 끝나는.\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = soup.find_all(\"a\")\n",
    "\n",
    "result_list = []\n",
    "for tag in result:\n",
    "    print(tag.text, tag['href'])\n",
    "    result_list.append([tag.text, tag['href']]) # list[text, href]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS Selector를 이용해 조회\n",
    "- **select(selector='css셀렉터')**\n",
    "    - css 셀렉터와 일치하는 tag들을 반환한다.\n",
    "- **select_one(selector='css셀렉터')**\n",
    "    - css 셀렉터와 일치하는 tag를 반환한다.\n",
    "    - 일치하는 것이 여러개일 경우 첫번째 것 하나만 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"example.html\", \"rt\", encoding=\"utf-8\") as fr:\n",
    "    html_doc = fr.read()\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# css selector를 이용한 조회\n",
    "\n",
    "result = soup.select(\"a\")         #  태그이름(a)  \n",
    "# result = soup.select(\"a, span, img\") # 태그이름(여러개)\n",
    "# result = soup.select(\"ul a\")    # ul의 자손인 a태그 찾는다.\n",
    "# result = soup.select(\"ul > a\")  # ul의 자식인 a태그 찾기.\n",
    "\n",
    "# result = soup.select_one(\"#animal1\")       # *#animal1   # 모든 태그중 id=animal1\n",
    "# result = soup.select_one(\"a#animal1\")      # a#animal1   # a태그 중에서 id=animal1\n",
    "\n",
    "# result = soup.select(\"ul + div\")                 # ul의 다음 형제 태그중 div\n",
    "# result = soup.select(\"body > div:nth-child(3)\")  # body의 3번째 자식 div\n",
    "\n",
    "# result = soup.select(\"a[href]\")                        # href 속성이 있는 a 태그들\n",
    "# result = soup.select(\"a[href='http://www.naver.com']\") # href='http://www.naver.com' 속성을 가진 a 그그\n",
    "# result = soup.select('a[href$=\".do\"]')                 # $=  href 속성값이 .do로 끝나는 a태그들\n",
    "# result = soup.select('a[href^=\"https\"]')               # =^  href 속성값이 https로 시작하는 a태그\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in result:\n",
    "    if tag.name == \"a\":\n",
    "        print(tag.text, tag['href'], tag.name)  # tag객체.name : 태그 이름."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
