{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습된 모델 저장\n",
    "\n",
    "- 학습이 완료된 모델을 파일로 저장하여, 이후 추가 학습이나 예측 서비스에 사용할 수 있도록 한다.\n",
    "- 파이토치(PyTorch)는 **모델의 파라미터만 저장**하는 방법과 **모델의 구조와 파라미터를 모두 저장**하는 두 가지 방식을 제공한다.\n",
    "- 저장 함수\n",
    "  - `torch.save(저장할 객체, 저장 경로)`\n",
    "- 보통 저장 파일의 확장자는 `.pt`나 `.pth`를 사용한다.\n",
    "\n",
    "## 모델 전체 저장 및 불러오기\n",
    "\n",
    "- 저장하기\n",
    "  - `torch.save(model, 저장 경로)`\n",
    "- 불러오기\n",
    "  - `load_model = torch.load(저장 경로, weights_only=False)`\n",
    "- 모델 저장 시 **피클(pickle)**을 사용해 직렬화되므로, 모델을 불러오는 실행 환경에도 저장할 때 사용한 클래스 정의가 필요하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 파라미터만 저장\n",
    "\n",
    "-   모델을 구성하는 파라미터만 저장한다.\n",
    "-   모델의 구조는 저장하지 않기 때문에 불러올 때 **모델을 먼저 생성하고 생성한 모델에 불러온 파라미터를 덮어씌운다.**\n",
    "-   모델의 파라미터는 **state_dict** 형식으로 저장한다.\n",
    "\n",
    "### state_dict\n",
    "\n",
    "-   모델의 파라미터 Tensor들을 레이어 단위별로 나누어 저장한 Ordered Dictionary (OrderedDict)\n",
    "-   `모델객체.state_dict()` 메소드를 이용해 조회한다.\n",
    "-   모델의 state_dict을 조회 후 저장한다.\n",
    "    -   `torch.save(model.state_dict(), \"저장경로\")`\n",
    "-   생성된 모델에 읽어온 state_dict를 덮어씌운다.\n",
    "    -   `new_model.load_state_dict(torch.load(\"state_dict저장경로\"))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 저장 및 불러오기\n",
    "\n",
    "- 학습이 끝나지 않은 모델을 저장하고, 나중에 이어서 학습시키려면 모델의 구조와 파라미터뿐만 아니라 optimizer, loss 함수 등 학습에 필요한 객체들도 함께 저장해야 한다.\n",
    "- 딕셔너리(Dictionary)에 저장하려는 값들을 key-value 쌍으로 구성하여 `torch.save()`를 이용해 저장한다.\n",
    "\n",
    "```python\n",
    "# 저장\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': train_loss\n",
    "}, \"저장경로\")\n",
    "\n",
    "# 불러오기\n",
    "model = MyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 불러온 checkpoint를 이용해 이전 학습 상태 복원\n",
    "checkpoint = torch.load(\"저장경로\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 모델 정의\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(3, 4) # 3 X 4 + 4 \n",
    "        self.lr2 = nn.Linear(4, 2)\n",
    "        self.relu = nn.ReLU() # activation함수->파라미터가 없는 단순 계산함수. relu(X) = max(X, 0)\n",
    "    def forward(self, X):\n",
    "        X = self.lr1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.lr2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (lr1): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (lr2): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성성\n",
    "model = MyModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=4, bias=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "#  모델에 Layer들을 조회. 모델.instance변수명\n",
    "################################################\n",
    "lr_layer = model.lr1\n",
    "lr_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#  Layer의 파라미터(weight/bias) 조회\n",
    "################################################\n",
    "lr1_weight = lr_layer.weight\n",
    "lr1_bias = lr_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0990, -0.2017,  0.3291],\n",
       "        [ 0.3617,  0.4953,  0.0188],\n",
       "        [ 0.1496, -0.5085,  0.0211],\n",
       "        [-0.3762,  0.0578, -0.0185]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr1_weight.size())\n",
    "lr1_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2466,  0.1807, -0.4694, -0.3903], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"saved_models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#  모델을 저장\n",
    "################################################\n",
    "torch.save(model, \"saved_models/my_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "#  저장된 모델 Load\n",
    "################################################\n",
    "load_model = torch.load(\"saved_models/my_model.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (lr1): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (lr2): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0990, -0.2017,  0.3291],\n",
       "        [ 0.3617,  0.4953,  0.0188],\n",
       "        [ 0.1496, -0.5085,  0.0211],\n",
       "        [-0.3762,  0.0578, -0.0185]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.lr1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0990, -0.2017,  0.3291],\n",
       "        [ 0.3617,  0.4953,  0.0188],\n",
       "        [ 0.1496, -0.5085,  0.0211],\n",
       "        [-0.3762,  0.0578, -0.0185]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight',\n",
       "              tensor([[-0.0990, -0.2017,  0.3291],\n",
       "                      [ 0.3617,  0.4953,  0.0188],\n",
       "                      [ 0.1496, -0.5085,  0.0211],\n",
       "                      [-0.3762,  0.0578, -0.0185]])),\n",
       "             ('lr1.bias', tensor([ 0.2466,  0.1807, -0.4694, -0.3903])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.1697, -0.2790,  0.1483,  0.3806],\n",
       "                      [ 0.0087, -0.2120, -0.2670, -0.0226]])),\n",
       "             ('lr2.bias', tensor([-0.2744,  0.2594]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################\n",
    "# 모델의 파라미터들(weight들, bias들)만 저장/불러오기\n",
    "######################################################\n",
    "state_dict = model.state_dict()\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr1.weight', 'lr1.bias', 'lr2.weight', 'lr2.bias'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# state_dict 저장\n",
    "################### \n",
    "torch.save(state_dict, \"saved_models/my_model_parameter.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight',\n",
       "              tensor([[-0.0990, -0.2017,  0.3291],\n",
       "                      [ 0.3617,  0.4953,  0.0188],\n",
       "                      [ 0.1496, -0.5085,  0.0211],\n",
       "                      [-0.3762,  0.0578, -0.0185]])),\n",
       "             ('lr1.bias', tensor([ 0.2466,  0.1807, -0.4694, -0.3903])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.1697, -0.2790,  0.1483,  0.3806],\n",
       "                      [ 0.0087, -0.2120, -0.2670, -0.0226]])),\n",
       "             ('lr2.bias', tensor([-0.2744,  0.2594]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# state_dict load\n",
    "#####################\n",
    "sd = torch.load(\"saved_models/my_model_parameter.pt\")  #weight_only=True (default)\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load한 state_dict를 모델 파라미터에 적용(덮어 씌운다.)\n",
    "new_model = MyModel()\n",
    "# new_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight',\n",
       "              tensor([[-0.0990, -0.2017,  0.3291],\n",
       "                      [ 0.3617,  0.4953,  0.0188],\n",
       "                      [ 0.1496, -0.5085,  0.0211],\n",
       "                      [-0.3762,  0.0578, -0.0185]])),\n",
       "             ('lr1.bias', tensor([ 0.2466,  0.1807, -0.4694, -0.3903])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.1697, -0.2790,  0.1483,  0.3806],\n",
       "                      [ 0.0087, -0.2120, -0.2670, -0.0226]])),\n",
       "             ('lr2.bias', tensor([-0.2744,  0.2594]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (lr1): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (lr2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 48ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 30ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchinfo\u001b[0m\u001b[2m==1.8.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# torchinfo 패키지 설치: 파이토치 모델 구조를 조사해주는 패키지.\n",
    "!uv pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MyModel                                  --\n",
       "├─Linear: 1-1                            16\n",
       "├─Linear: 1-2                            10\n",
       "├─ReLU: 1-3                              --\n",
       "=================================================================\n",
       "Total params: 26\n",
       "Trainable params: 26\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [100, 2]                  --\n",
       "├─Linear: 1-1                            [100, 4]                  16\n",
       "├─ReLU: 1-2                              [100, 4]                  --\n",
       "├─Linear: 1-3                            [100, 2]                  10\n",
       "==========================================================================================\n",
       "Total params: 26\n",
       "Trainable params: 26\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input data 의 shape을 지정하면 각 Layer의 output shape을 출력한다.\n",
    "summary(model, (100, 3))  # input_data=입력Tensor객체, input_data=torch.randn(100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 문제 유형별 MLP 네트워크\n",
    "- 해결하려는 문제 유형에 따라 출력 Layer의 구조가 바뀐다.\n",
    "- 딥러닝 구조에서 **Feature를 추출하는 Layer 들을 Backbone** 이라고 하고 **추론하는 Layer들을 Head** 라고 한다. \n",
    "\n",
    "\n",
    "> - MLP(Multi Layer Perceptron), DNN(Deep Neural Network), ANN(Artificial Neural Network)\n",
    ">     -   Fully Connected Layer(nn.Linear)로 구성된 딥러닝 모델\n",
    ">     -   input feature들 모두에 대응하는 weight들(가중치)을 사용한다.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Boston Housing Dataset - **Regression(회귀) 문제**\n",
    "\n",
    "보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제.\n",
    "\n",
    "-   CRIM: 범죄율\n",
    "-   ZN: 25,000 평방피트당 주거지역 비율\n",
    "-   INDUS: 비소매 상업지구 비율\n",
    "-   CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n",
    "-   NOX: 일산화질소 농도(단위: 0.1ppm)\n",
    "-   RM: 주택당 방의 수\n",
    "-   AGE: 1940년 이전에 건설된 주택의 비율\n",
    "-   DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n",
    "-   RAD: 고속도로 접근성\n",
    "-   TAX: 재산세율\n",
    "-   PTRATIO: 학생/교사 비율\n",
    "-   B: 흑인 비율\n",
    "-   LSTAT: 하위 계층 비율\n",
    "    <br><br>\n",
    "-   **Target**\n",
    "    -   MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/boston_housing.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506, 1))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='MEDV').values\n",
    "y = df['MEDV'].values.reshape(-1, 1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 102)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Test Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "trainset = TensorDataset(\n",
    "    torch.tensor(X_train_scaled, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "testset = TensorDataset(\n",
    "    torch.tensor(X_test_scaled, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "batch_size = 200\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 모델 정의\n",
    "##########################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class BostonModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(13, 32) # 첫번째 연산\n",
    "        self.lr2 = nn.Linear(32, 16)\n",
    "        self.lr3 = nn.Linear(16, 1)   \n",
    "        # 추론 결과를 출력 : 회귀 - 예측할 값의 개수.(집값: 1, 아파트,단독,연립: 3), y.shape: (N, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Linear -> ReLU -> Linear -> ReLU -> Liear -> 출력\n",
    "        out = self.lr1(X)\n",
    "        out = self.relu(out)        \n",
    "        out = self.lr2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.lr3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 0.001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "# 모델 생성\n",
    "boston_model = ().to(device)\n",
    "# Loss 함수BostonModel\n",
    "loss_fn = nn.MSELoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.RMSprop(boston_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BostonModel                              [200, 1]                  --\n",
       "├─Linear: 1-1                            [200, 32]                 448\n",
       "├─ReLU: 1-2                              [200, 32]                 --\n",
       "├─Linear: 1-3                            [200, 16]                 528\n",
       "├─ReLU: 1-4                              [200, 16]                 --\n",
       "├─Linear: 1-5                            [200, 1]                  17\n",
       "==========================================================================================\n",
       "Total params: 993\n",
       "Trainable params: 993\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.20\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.08\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(boston_model, (200, 13), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] train loss: 594.42477, validation loss: 515.35468\n",
      "[101/1000] train loss: 23.58760, validation loss: 23.97379\n",
      "[201/1000] train loss: 14.93035, validation loss: 16.34781\n",
      "[301/1000] train loss: 10.74346, validation loss: 12.26301\n",
      "[401/1000] train loss: 8.04014, validation loss: 10.85579\n",
      "[501/1000] train loss: 6.96515, validation loss: 10.33121\n",
      "[601/1000] train loss: 6.27835, validation loss: 10.23465\n",
      "[701/1000] train loss: 5.61462, validation loss: 9.93723\n",
      "[801/1000] train loss: 5.18579, validation loss: 9.94390\n",
      "[901/1000] train loss: 4.64167, validation loss: 9.82463\n",
      "[1000/1000] train loss: 4.28705, validation loss: 9.83201\n"
     ]
    }
   ],
   "source": [
    "# Train -> Train / Validataion 두 단계\n",
    "for epoch in range(epochs):\n",
    "    #####################################\n",
    "    # 학습(train)\n",
    "    #####################################\n",
    "    boston_model.train()\n",
    "    train_loss = 0.0 # 현 에폭의 loss을 저장할 변수.\n",
    "    for X_train, y_train in train_loader:  # 1 배치 학습\n",
    "        # 1. X, y를 device로 이동. (model 과 같은 device로 이동)\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        # 2. 추론\n",
    "        pred_train = boston_model(X_train)\n",
    "        # 3. Loss 계산\n",
    "        loss = loss_fn(pred_train, y_train)\n",
    "        # 4. 역전파로 gradient 계산\n",
    "        loss.backward()\n",
    "        # 5. 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # 6. gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 7. 현재 batch에대한 loss 계산\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    #####################################\n",
    "    # 검증(valiation) - 1 에폭 학습한 것에 대한 검증\n",
    "    #####################################\n",
    "    boston_model.eval() # 추론만 할 때.\n",
    "\n",
    "    valid_loss = 0.0 # 현재 epoch에 대한 검증 loss값을 저장할 변수\n",
    "    with torch.no_grad():\n",
    "        for X_valid, y_valid in test_loader:\n",
    "            # 1. X, y를 model의 device로 이동\n",
    "            X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "            \n",
    "            # 2. 추론\n",
    "            pred_valid = boston_model(X_valid)\n",
    "\n",
    "            # 3. 평가 - MSE\n",
    "            valid_loss  += loss_fn(pred_valid, y_valid).item()\n",
    "        valid_loss = valid_loss / len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "    # 로그 출력 - train/valid loss를 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1}/{epochs}] train loss: {train_loss:.5f}, validation loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boston_model_path = \"saved_models/boston_model.pth\"\n",
    "torch.save(boston_model, save_boston_model_path) # 모델 전체 저장\n",
    "torch.save(boston_model.state_dict(), \"saved_models/bost_model_parameter.pth\") # 모델 파라미터만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26.8538],\n",
      "        [35.7528],\n",
      "        [15.9317],\n",
      "        [24.0498],\n",
      "        [16.7013],\n",
      "        [19.5364],\n",
      "        [17.8356],\n",
      "        [15.4498],\n",
      "        [26.5210],\n",
      "        [18.9611]])\n"
     ]
    }
   ],
   "source": [
    "load_model = torch.load(save_boston_model_path, weights_only=False)\n",
    "load_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(load_model(X_valid)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26.8538],\n",
      "        [35.7528],\n",
      "        [15.9317],\n",
      "        [24.0498],\n",
      "        [16.7013],\n",
      "        [19.5364],\n",
      "        [17.8356],\n",
      "        [15.4498],\n",
      "        [26.5210],\n",
      "        [18.9611]])\n"
     ]
    }
   ],
   "source": [
    "load_state_dict = torch.load(\"saved_models/bost_model_parameter.pth\", weights_only=True)\n",
    "new_model = BostonModel()\n",
    "new_model.load_state_dict(load_state_dict)\n",
    "new_model.eval()\n",
    "with torch.no_grad():\n",
    "    result = new_model(X_valid)[:10]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 분류 (Classification)\n",
    "\n",
    "### Fashion MNIST Dataset - **다중분류(Multi-Class Classification) 문제**\n",
    "\n",
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋.\n",
    "이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 의류 품목을 나타낸다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>그림</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Feature**이미지는 28x28 크기이며 Gray scale이다.\n",
    "- **Target**은 총 10개의 class로 구성되어 있으며 각 class의 class 이름은 다음과 같다.\n",
    "\n",
    "| 레이블 | 클래스       |\n",
    "|--------|--------------|\n",
    "| 0      | T-shirt/top |\n",
    "| 1      | Trousers    |\n",
    "| 2      | Pullover    |\n",
    "| 3      | Dress       |\n",
    "| 4      | Coat        |\n",
    "| 5      | Sandal      |\n",
    "| 6      | Shirt       |\n",
    "| 7      | Sneaker     |\n",
    "| 8      | Bag         |\n",
    "| 9      | Ankle boot  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 학습 도중 모델 저장\n",
    ">\n",
    "> - 학습 도중 가장 좋은 성능을 보이는 모델이 나올 수 있다.\n",
    "> - 학습 도중 모델을 저장하는 방법\n",
    ">   1. 각 에폭이 끝날 때 마다 모델을 저장한다.\n",
    ">   2. 한 에폭 학습 후 성능 개선이 있으면 모델을 저장하여 가장 성능 좋은 모델만 저장되도록 한다.\n",
    ">      - 최고 성능 점수(best score)와 현재 에폭의 성능을 비교하여, 성능이 개선되었을 경우 모델을 저장(덮어쓰기)한다.\n",
    ">\n",
    "> #### 조기 종료(Early Stopping)\n",
    ">\n",
    "> - 학습 도중 성능 개선이 나타나지 않으면, 중간에 학습을 종료하도록 구현한다.\n",
    "> - 에폭 수를 충분히 길게 설정한 뒤, 특정 횟수 동안 성능 개선이 없으면 학습을 조기 종료하도록 구현한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"mps\" if torch.backend.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000, 10000, 195, 40)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset \n",
    "batch_size = 256\n",
    "dataset_path = \"datasets/fashion_mnist\"\n",
    "f_trainset = FashionMNIST(dataset_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "f_testset = FashionMNIST(dataset_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "f_trainset, f_validset = random_split(f_trainset, [50000, 10000])\n",
    "\n",
    "f_train_loader = DataLoader(f_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "f_valid_loader = DataLoader(f_validset, batch_size=batch_size)\n",
    "f_test_loader = DataLoader(f_testset, batch_size=batch_size)\n",
    "\n",
    "len(f_trainset), len(f_testset), len(f_validset), len(f_train_loader), len(f_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_testset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_testset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([1, 28, 28])\n",
      "tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(f_trainset[0][0].dtype)\n",
    "print(f_trainset[0][0].size())\n",
    "print(f_trainset[0][0].min(), f_trainset[0][0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# 모델 정의\n",
    "##################################\n",
    "class FashionMNISTModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(784, 2048)\n",
    "        self.lr2 = nn.Linear(2048, 1024)\n",
    "        self.lr3 = nn.Linear(1024, 512)\n",
    "        self.lr4 = nn.Linear(512, 256)\n",
    "        self.lr5 = nn.Linear(256, 128)\n",
    "        self.lr6 = nn.Linear(128, 64)\n",
    "        self.lr7 = nn.Linear(64, 10)\n",
    "        # 출력 Layer out_features 개수: 다중분류문제의 경우 정답 클래스 개수.\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X shape: (batch, 1, 28, 28) -> (batch, 784) torch.flatten(start_dim=1)함수\n",
    "        out = nn.Flatten()(X) # 0축은 그대로 두고 그 이후 축을 flatten 한다.\n",
    "        out = self.lr1(out)  # self.relu(self.lr1(out))\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr2(out) \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr3(out) \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr4(out) \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr5(out) \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr6(out) \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr7(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FashionMNISTModel                        [100, 10]                 --\n",
       "├─Linear: 1-1                            [100, 2048]               1,607,680\n",
       "├─ReLU: 1-2                              [100, 2048]               --\n",
       "├─Linear: 1-3                            [100, 1024]               2,098,176\n",
       "├─ReLU: 1-4                              [100, 1024]               --\n",
       "├─Linear: 1-5                            [100, 512]                524,800\n",
       "├─ReLU: 1-6                              [100, 512]                --\n",
       "├─Linear: 1-7                            [100, 256]                131,328\n",
       "├─ReLU: 1-8                              [100, 256]                --\n",
       "├─Linear: 1-9                            [100, 128]                32,896\n",
       "├─ReLU: 1-10                             [100, 128]                --\n",
       "├─Linear: 1-11                           [100, 64]                 8,256\n",
       "├─ReLU: 1-12                             [100, 64]                 --\n",
       "├─Linear: 1-13                           [100, 10]                 650\n",
       "==========================================================================================\n",
       "Total params: 4,403,786\n",
       "Trainable params: 4,403,786\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 440.38\n",
       "==========================================================================================\n",
       "Input size (MB): 0.31\n",
       "Forward/backward pass size (MB): 3.23\n",
       "Params size (MB): 17.62\n",
       "Estimated Total Size (MB): 21.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(FashionMNISTModel(), (100, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model = FashionMNISTModel().to(device)\n",
    "optimizer = torch.optim.Adam(f_model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "# 다중분류의 loss: CrossEntropyLoss()\n",
    "# CrossEntrpyLoss()입력: 정답-class index로 구성 [[3],[8],[0]..], 모델 추정결과: Softmax를 적용하기 전값 - logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train loss: 1.16591, valid loss: 0.74194, valid acc: 0.71790\n",
      ">>>>>> 모델 저장: 1 epoch - 이전 score: inf, 개선된 score: 0.7419377461075782\n",
      "[2/100] train loss: 0.64029, valid loss: 0.59728, valid acc: 0.79420\n",
      ">>>>>> 모델 저장: 2 epoch - 이전 score: 0.7419377461075782, 개선된 score: 0.5972842842340469\n",
      "[3/100] train loss: 0.55904, valid loss: 0.54403, valid acc: 0.80960\n",
      ">>>>>> 모델 저장: 3 epoch - 이전 score: 0.5972842842340469, 개선된 score: 0.5440327368676663\n",
      "[4/100] train loss: 0.50130, valid loss: 0.50173, valid acc: 0.82490\n",
      ">>>>>> 모델 저장: 4 epoch - 이전 score: 0.5440327368676663, 개선된 score: 0.501725647598505\n",
      "[5/100] train loss: 0.46540, valid loss: 0.49677, valid acc: 0.82600\n",
      ">>>>>> 모델 저장: 5 epoch - 이전 score: 0.501725647598505, 개선된 score: 0.49676945582032206\n",
      "[6/100] train loss: 0.43954, valid loss: 0.44215, valid acc: 0.85070\n",
      ">>>>>> 모델 저장: 6 epoch - 이전 score: 0.49676945582032206, 개선된 score: 0.4421533174812794\n",
      "[7/100] train loss: 0.41327, valid loss: 0.43157, valid acc: 0.85060\n",
      ">>>>>> 모델 저장: 7 epoch - 이전 score: 0.4421533174812794, 개선된 score: 0.4315674677491188\n",
      "[8/100] train loss: 0.39029, valid loss: 0.40568, valid acc: 0.86000\n",
      ">>>>>> 모델 저장: 8 epoch - 이전 score: 0.4315674677491188, 개선된 score: 0.4056809425354004\n",
      "[9/100] train loss: 0.37821, valid loss: 0.39195, valid acc: 0.86720\n",
      ">>>>>> 모델 저장: 9 epoch - 이전 score: 0.4056809425354004, 개선된 score: 0.39195446148514745\n",
      "[10/100] train loss: 0.36161, valid loss: 0.39541, valid acc: 0.86410\n",
      "[11/100] train loss: 0.34615, valid loss: 0.37637, valid acc: 0.87210\n",
      ">>>>>> 모델 저장: 11 epoch - 이전 score: 0.39195446148514745, 개선된 score: 0.376373690366745\n",
      "[12/100] train loss: 0.33481, valid loss: 0.36530, valid acc: 0.87360\n",
      ">>>>>> 모델 저장: 12 epoch - 이전 score: 0.376373690366745, 개선된 score: 0.36530091762542727\n",
      "[13/100] train loss: 0.32674, valid loss: 0.37452, valid acc: 0.86610\n",
      "[14/100] train loss: 0.31669, valid loss: 0.35077, valid acc: 0.87850\n",
      ">>>>>> 모델 저장: 14 epoch - 이전 score: 0.36530091762542727, 개선된 score: 0.35076653212308884\n",
      "[15/100] train loss: 0.30417, valid loss: 0.35364, valid acc: 0.87580\n",
      "[16/100] train loss: 0.29693, valid loss: 0.33847, valid acc: 0.88100\n",
      ">>>>>> 모델 저장: 16 epoch - 이전 score: 0.35076653212308884, 개선된 score: 0.3384663790464401\n",
      "[17/100] train loss: 0.28858, valid loss: 0.33582, valid acc: 0.88380\n",
      ">>>>>> 모델 저장: 17 epoch - 이전 score: 0.3384663790464401, 개선된 score: 0.3358179278671741\n",
      "[18/100] train loss: 0.28128, valid loss: 0.33515, valid acc: 0.88040\n",
      ">>>>>> 모델 저장: 18 epoch - 이전 score: 0.3358179278671741, 개선된 score: 0.3351533427834511\n",
      "[19/100] train loss: 0.27447, valid loss: 0.33228, valid acc: 0.88470\n",
      ">>>>>> 모델 저장: 19 epoch - 이전 score: 0.3351533427834511, 개선된 score: 0.3322793338447809\n",
      "[20/100] train loss: 0.26315, valid loss: 0.33943, valid acc: 0.87930\n",
      "[21/100] train loss: 0.25764, valid loss: 0.35533, valid acc: 0.87570\n",
      "[22/100] train loss: 0.25628, valid loss: 0.35666, valid acc: 0.87360\n",
      "[23/100] train loss: 0.24916, valid loss: 0.32585, valid acc: 0.88440\n",
      ">>>>>> 모델 저장: 23 epoch - 이전 score: 0.3322793338447809, 개선된 score: 0.32585195302963255\n",
      "[24/100] train loss: 0.23734, valid loss: 0.31861, valid acc: 0.88630\n",
      ">>>>>> 모델 저장: 24 epoch - 이전 score: 0.32585195302963255, 개선된 score: 0.3186128489673138\n",
      "[25/100] train loss: 0.23170, valid loss: 0.32109, valid acc: 0.88940\n",
      "[26/100] train loss: 0.22874, valid loss: 0.30726, valid acc: 0.89100\n",
      ">>>>>> 모델 저장: 26 epoch - 이전 score: 0.3186128489673138, 개선된 score: 0.30725546181201935\n",
      "[27/100] train loss: 0.22118, valid loss: 0.29714, valid acc: 0.89470\n",
      ">>>>>> 모델 저장: 27 epoch - 이전 score: 0.30725546181201935, 개선된 score: 0.2971425123512745\n",
      "[28/100] train loss: 0.21539, valid loss: 0.33876, valid acc: 0.88310\n",
      "[29/100] train loss: 0.21107, valid loss: 0.32184, valid acc: 0.89070\n",
      "[30/100] train loss: 0.20476, valid loss: 0.31290, valid acc: 0.89320\n",
      "[31/100] train loss: 0.19931, valid loss: 0.30936, valid acc: 0.89380\n",
      "[32/100] train loss: 0.19326, valid loss: 0.31408, valid acc: 0.89510\n",
      "[33/100] train loss: 0.18623, valid loss: 0.32475, valid acc: 0.89010\n",
      "[34/100] train loss: 0.18051, valid loss: 0.31404, valid acc: 0.89900\n",
      "[35/100] train loss: 0.17327, valid loss: 0.34546, valid acc: 0.88920\n",
      "[36/100] train loss: 0.16972, valid loss: 0.31450, valid acc: 0.89710\n",
      "[37/100] train loss: 0.15735, valid loss: 0.31649, valid acc: 0.90200\n",
      ">>>>>>>>>>>>> 조기종료: valid loss가 0.2971425123512745 보다 개선되지 않음.\n",
      "학습에 걸린시간: 433.8394899368286 초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "##################################################################\n",
    "# 1. 성능(valid_loss)이 개선될 때 마다 모델을 저장.\n",
    "#    최종적으로 가장 성능이 좋은 epoch의 모델이 저장되도록한다.\n",
    "# 2. 일정 epoch동안 성능개선이 안되면 학습을 중단.\n",
    "# 이것과 관련된 변수들 정의.\n",
    "##################################################################\n",
    "best_score = torch.inf  # 가장 좋은 valid_loss 값을 저장. valid_loss < best_score 성능개선 -> 저장.\n",
    "# 저장\n",
    "save_model_path = \"saved_models/fashion_mnist_model.pth\"\n",
    "# 조기종료\n",
    "patience = 10  # 성능이 개선되는지 10 에폭 동안 기다려본다. valid_loss >= best_score 성능개선이 안됨. \n",
    "stop_count = 0 # 학습하는 도중 몇 번동안 성능개선이 안되었는지 저장할변수. stop_count == patience 이면 종료.\n",
    "\n",
    "epochs = 100\n",
    "s = time.time()\n",
    "for epoch in range(epochs):\n",
    "    # 학습\n",
    "    f_model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for X_train, y_train in f_train_loader:\n",
    "        # 1. X, y를 device로 이동\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        # 2. 모델 추론\n",
    "        pred_train = f_model(X_train)\n",
    "        # 3. loss 계산\n",
    "        loss = loss_fn(pred_train, y_train)\n",
    "        # 4. gradient 계산  (역전파)\n",
    "        loss.backward()\n",
    "        # 5. 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # 6. 파라미터 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 7. 현재 에폭에서의 train loss 누적\n",
    "        train_loss = train_loss + loss.item()\n",
    "\n",
    "    # train_loss 평균계산\n",
    "    train_loss = train_loss / len(f_train_loader)\n",
    "    train_loss_list.append(train_loss) \n",
    "\n",
    "    ## 검증\n",
    "    f_model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_valid, y_valid in f_valid_loader:\n",
    "            # 1. device로 이동\n",
    "            X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "            \n",
    "            # 2. 모델 추정\n",
    "            pred_valid = f_model(X_valid) # 10개 class에대한 logit값(확률).\n",
    "            pred_label = pred_valid.argmax(dim=-1)# 가장 확률높은 class\n",
    "            # 3. 평가 - loss와 정확도\n",
    "            valid_loss = valid_loss + loss_fn(pred_valid, y_valid).item() # 현 step에서의 loss\n",
    "            valid_acc = valid_acc + torch.sum(pred_label == y_valid).item() # 현 step에서 맞은것 개수.\n",
    "\n",
    "        valid_loss = valid_loss / len(f_valid_loader)\n",
    "        valid_acc = valid_acc / len(f_validset)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        #로그출력 - train_loss, valid_loss, valid_acc\n",
    "        print(f\"[{epoch+1}/{epochs}] train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, valid acc: {valid_acc:.5f}\")\n",
    "\n",
    "        ################################\n",
    "        # 모델 저장, 조기종료\n",
    "        ################################\n",
    "        if valid_loss < best_score: # 이번 epoch 학습에서 성능(valid_loss)이 개선되었다.\n",
    "            # 모델 저장\n",
    "            torch.save(f_model, save_model_path)\n",
    "            print(f\">>>>>> 모델 저장: {epoch+1} epoch - 이전 score: {best_score}, 개선된 score: {valid_loss}\")\n",
    "            best_score = valid_loss\n",
    "            # 조기종료 (stop_count 를 초기)\n",
    "            stop_count = 0\n",
    "        else: # 성능개선이 안됨. -> 조기종료관련 처리.\n",
    "            stop_count += 1\n",
    "            if stop_count == patience:\n",
    "                print(f\">>>>>>>>>>>>> 조기종료: valid loss가 {best_score} 보다 개선되지 않음.\")\n",
    "                break\n",
    "\n",
    "\n",
    "e = time.time()\n",
    "print('학습에 걸린시간:', (e-s), \"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "result_dict = {\n",
    "    \"train_loss\": train_loss_list,\n",
    "    \"valid_acc\": valid_acc_list,\n",
    "    \"valid_loss\": valid_loss_list\n",
    "}\n",
    "\n",
    "with open(\"f_mnist_train_result.pkl\", 'wb') as fo:\n",
    "    pickle.dump(result_dict, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"f_mnist_train_result.pkl\", 'rb') as fi:\n",
    "    load_result = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.165911</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.741938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640290</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>0.597284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559044</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.544033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501304</td>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.501726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465405</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.496769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.439535</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.442153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.413268</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.431567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.390290</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.405681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.378214</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.391954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.361607</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>0.395411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.346150</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.376374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.334808</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.365301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.326742</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>0.374519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.316689</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.350767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.304174</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.353639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.296928</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.338466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.288584</td>\n",
       "      <td>0.8838</td>\n",
       "      <td>0.335818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.281278</td>\n",
       "      <td>0.8804</td>\n",
       "      <td>0.335153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.274471</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.332279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.263148</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.339429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.257639</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>0.355327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.256280</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.356665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.249156</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.325852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.237338</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.318613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.231702</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.321090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.228743</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.307255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.221180</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.297143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.215386</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>0.338760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.211067</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.321838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.204761</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>0.312897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.199310</td>\n",
       "      <td>0.8938</td>\n",
       "      <td>0.309360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.193263</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.314075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.186231</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.324754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.180507</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.314039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.173268</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.345463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.169717</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>0.314503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.157350</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.316495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_acc  valid_loss\n",
       "0     1.165911     0.7179    0.741938\n",
       "1     0.640290     0.7942    0.597284\n",
       "2     0.559044     0.8096    0.544033\n",
       "3     0.501304     0.8249    0.501726\n",
       "4     0.465405     0.8260    0.496769\n",
       "5     0.439535     0.8507    0.442153\n",
       "6     0.413268     0.8506    0.431567\n",
       "7     0.390290     0.8600    0.405681\n",
       "8     0.378214     0.8672    0.391954\n",
       "9     0.361607     0.8641    0.395411\n",
       "10    0.346150     0.8721    0.376374\n",
       "11    0.334808     0.8736    0.365301\n",
       "12    0.326742     0.8661    0.374519\n",
       "13    0.316689     0.8785    0.350767\n",
       "14    0.304174     0.8758    0.353639\n",
       "15    0.296928     0.8810    0.338466\n",
       "16    0.288584     0.8838    0.335818\n",
       "17    0.281278     0.8804    0.335153\n",
       "18    0.274471     0.8847    0.332279\n",
       "19    0.263148     0.8793    0.339429\n",
       "20    0.257639     0.8757    0.355327\n",
       "21    0.256280     0.8736    0.356665\n",
       "22    0.249156     0.8844    0.325852\n",
       "23    0.237338     0.8863    0.318613\n",
       "24    0.231702     0.8894    0.321090\n",
       "25    0.228743     0.8910    0.307255\n",
       "26    0.221180     0.8947    0.297143\n",
       "27    0.215386     0.8831    0.338760\n",
       "28    0.211067     0.8907    0.321838\n",
       "29    0.204761     0.8932    0.312897\n",
       "30    0.199310     0.8938    0.309360\n",
       "31    0.193263     0.8951    0.314075\n",
       "32    0.186231     0.8901    0.324754\n",
       "33    0.180507     0.8990    0.314039\n",
       "34    0.173268     0.8892    0.345463\n",
       "35    0.169717     0.8971    0.314503\n",
       "36    0.157350     0.9020    0.316495"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result_df = pd.DataFrame(load_result)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df[[\"train_loss\", \"valid_loss\"]].plot(xlabel=\"epoch\", ylabel=\"loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df['valid_acc'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_loss    0.157350\n",
       "valid_loss    0.297143\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[[\"train_loss\", \"valid_loss\"]].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.902)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['valid_acc'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModel(\n",
       "  (lr1): Linear(in_features=784, out_features=2048, bias=True)\n",
       "  (lr2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (lr3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (lr4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (lr5): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lr6): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (lr7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델 load\n",
    "save_model_path = \"saved_models/fashion_mnist_model.pth\"\n",
    "load_model = torch.load(save_model_path, weights_only=False)\n",
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3335733566433191\n",
      "accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "### Testset으로 최종 평가\n",
    "load_model = load_model.to(device)\n",
    "load_model.eval()\n",
    "loss = 0.0\n",
    "acc = 0.0\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():\n",
    "    for X, y in f_test_loader:\n",
    "        X, y = X.to(device), y.to(device) # 1. device로 옮기기\n",
    "        pred = load_model(X) # 2. 모델 추론\n",
    "        pred_label = pred.argmax(dim=-1)\n",
    "        # 평가\n",
    "        loss += loss_fn(pred, y).item()\n",
    "        acc += torch.sum(y == pred_label).item()\n",
    "    loss /= len(f_test_loader)\n",
    "    acc /= len(f_testset)\n",
    "\n",
    "print(\"loss:\", loss)\n",
    "print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = nn.Softmax(dim=-1)(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1520,  1.5371, -0.2541,  8.2770,  0.4474, -7.0903,  3.3835, -6.8558,\n",
       "         -2.6592, -8.8808],\n",
       "        [ 3.2736, -0.3634,  3.5475,  0.5031,  0.2289, -2.9125,  2.2069, -3.2826,\n",
       "         -2.2528, -1.5481]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5763e-02, 1.1534e-03, 1.9236e-04, 9.7518e-01, 3.8792e-04, 2.0662e-07,\n",
       "         7.3093e-03, 2.6122e-07, 1.7361e-05, 3.4479e-08],\n",
       "        [3.5570e-01, 9.3663e-03, 4.6779e-01, 2.2279e-02, 1.6935e-02, 7.3203e-04,\n",
       "         1.2241e-01, 5.0555e-04, 1.4158e-03, 2.8645e-03]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:2]# .sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 위스콘신 유방암 데이터셋 - **이진분류(Binary Classification) 문제**\n",
    "\n",
    "-   **이진 분류 문제 처리 모델의 두가지 방법**\n",
    "    1. positive(1)일 확률을 출력하도록 구현\n",
    "        - output layer: units=1, activation='sigmoid'\n",
    "        - loss: binary_crossentropy\n",
    "    2. negative(0)일 확률과 positive(1)일 확률을 출력하도록 구현 => 다중분류 처리 방식으로 해결\n",
    "        - output layer: units=2, activation='softmax', y(정답)은 one hot encoding 처리\n",
    "        - loss: categorical_crossentropy\n",
    "-   위스콘신 대학교에서 제공한 종양의 악성/양성여부 분류를 위한 데이터셋\n",
    "-   Feature\n",
    "    -   종양에 대한 다양한 측정값들\n",
    "-   Target의 class\n",
    "    -   0 - malignant(악성종양)\n",
    "    -   1 - benign(양성종양)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "## 모델의 weight, bias -> float32. X, y는 weight, bias와 계산을 하게 되기 때문에 타입을 맞춰준다.\n",
    "trainset = TensorDataset(\n",
    "    torch.tensor(X_train_scaled, dtype=torch.float32),  \n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "testset = TensorDataset(\n",
    "    torch.tensor(X_test_scaled, dtype=torch.float32), \n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class name <-> class index\n",
    "classes = np.array([\"악성종양\", \"양성종양\"])\n",
    "class_to_idx = {\"악성종양\":0, \"양성종양\":1}\n",
    "\n",
    "trainset.classes = classes\n",
    "trainset.class_to_idx = class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['악성종양', '양성종양', '양성종양', '악성종양', '양성종양', '양성종양', '악성종양', '양성종양',\n",
       "       '양성종양'], dtype='<U4')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.classes[[0, 1, 1, 0, 1,  1, 0, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 143)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(trainset, batch_size=200, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 모델 정의\n",
    "class BCModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(30, 16)\n",
    "        self.lr2 = nn.Linear(16, 8)\n",
    "        self.lr3 = nn.Linear(8, 1)  # out_features: 1 - positive일 확률\n",
    "        self.relu = nn.ReLU() # hidden layer의 활성함수\n",
    "        self.sigmoid = nn.Sigmoid()  # Linear 출력값을 0 ~ 1 확률로 만들어주는 Sigmoid(Logistic)함수.\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.relu(self.lr1(X))\n",
    "        out = self.relu(self.lr2(out))\n",
    "\n",
    "        out = self.lr3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BCModel                                  --\n",
       "├─Linear: 1-1                            496\n",
       "├─Linear: 1-2                            136\n",
       "├─Linear: 1-3                            9\n",
       "├─ReLU: 1-4                              --\n",
       "├─Sigmoid: 1-5                           --\n",
       "=================================================================\n",
       "Total params: 641\n",
       "Trainable params: 641\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "m = BCModel()\n",
    "summary(m)\n",
    "# p = m(torch.randn(10, 30))\n",
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 학습\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "model = BCModel().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 조기종료, best 모델 저장\n",
    "best_score = torch.inf  # valid loss 기준\n",
    "save_model_path = \"saved_models/bc_model.pth\"\n",
    "patience = 10\n",
    "stop_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] train loss: 0.64756, valid loss0.59831, valid acc: 0.68531\n",
      ">>>>>>>> 1 Epoch에서 모델을 저장합니다. inf에서 0.5983078181743622로 개선됨\n",
      "[2/1000] train loss: 0.59126, valid loss0.53053, valid acc: 0.88112\n",
      ">>>>>>>> 2 Epoch에서 모델을 저장합니다. 0.5983078181743622에서 0.5305299460887909로 개선됨\n",
      "[3/1000] train loss: 0.51114, valid loss0.45639, valid acc: 0.92308\n",
      ">>>>>>>> 3 Epoch에서 모델을 저장합니다. 0.5305299460887909에서 0.4563935697078705로 개선됨\n",
      "[4/1000] train loss: 0.43413, valid loss0.39584, valid acc: 0.90909\n",
      ">>>>>>>> 4 Epoch에서 모델을 저장합니다. 0.4563935697078705에서 0.3958374559879303로 개선됨\n",
      "[5/1000] train loss: 0.36936, valid loss0.35343, valid acc: 0.90909\n",
      ">>>>>>>> 5 Epoch에서 모델을 저장합니다. 0.3958374559879303에서 0.35342937707901로 개선됨\n",
      "[6/1000] train loss: 0.31789, valid loss0.31951, valid acc: 0.90909\n",
      ">>>>>>>> 6 Epoch에서 모델을 저장합니다. 0.35342937707901에서 0.3195130079984665로 개선됨\n",
      "[7/1000] train loss: 0.28655, valid loss0.28657, valid acc: 0.91608\n",
      ">>>>>>>> 7 Epoch에서 모델을 저장합니다. 0.3195130079984665에서 0.28656579554080963로 개선됨\n",
      "[8/1000] train loss: 0.24075, valid loss0.25394, valid acc: 0.91608\n",
      ">>>>>>>> 8 Epoch에서 모델을 저장합니다. 0.28656579554080963에서 0.25394223630428314로 개선됨\n",
      "[9/1000] train loss: 0.20830, valid loss0.22353, valid acc: 0.93706\n",
      ">>>>>>>> 9 Epoch에서 모델을 저장합니다. 0.25394223630428314에서 0.2235262393951416로 개선됨\n",
      "[10/1000] train loss: 0.16350, valid loss0.19579, valid acc: 0.93706\n",
      ">>>>>>>> 10 Epoch에서 모델을 저장합니다. 0.2235262393951416에서 0.19579191505908966로 개선됨\n",
      "[11/1000] train loss: 0.13752, valid loss0.17219, valid acc: 0.93706\n",
      ">>>>>>>> 11 Epoch에서 모델을 저장합니다. 0.19579191505908966에서 0.17219041287899017로 개선됨\n",
      "[12/1000] train loss: 0.10515, valid loss0.15467, valid acc: 0.95105\n",
      ">>>>>>>> 12 Epoch에서 모델을 저장합니다. 0.17219041287899017에서 0.1546678990125656로 개선됨\n",
      "[13/1000] train loss: 0.08872, valid loss0.14359, valid acc: 0.95105\n",
      ">>>>>>>> 13 Epoch에서 모델을 저장합니다. 0.1546678990125656에서 0.14359048753976822로 개선됨\n",
      "[14/1000] train loss: 0.07415, valid loss0.13900, valid acc: 0.95804\n",
      ">>>>>>>> 14 Epoch에서 모델을 저장합니다. 0.14359048753976822에서 0.1390014886856079로 개선됨\n",
      "[15/1000] train loss: 0.05945, valid loss0.14079, valid acc: 0.95804\n",
      "[16/1000] train loss: 0.05724, valid loss0.14494, valid acc: 0.95105\n",
      "[17/1000] train loss: 0.05090, valid loss0.14794, valid acc: 0.95105\n",
      "[18/1000] train loss: 0.05079, valid loss0.14900, valid acc: 0.95804\n",
      "[19/1000] train loss: 0.03342, valid loss0.15049, valid acc: 0.95804\n",
      "[20/1000] train loss: 0.04747, valid loss0.14852, valid acc: 0.95804\n",
      "[21/1000] train loss: 0.04265, valid loss0.14580, valid acc: 0.95804\n",
      "[22/1000] train loss: 0.03832, valid loss0.14433, valid acc: 0.95804\n",
      "[23/1000] train loss: 0.04419, valid loss0.14331, valid acc: 0.95804\n",
      "[24/1000] train loss: 0.03601, valid loss0.14562, valid acc: 0.95804\n",
      "24에서 조기종료 합니다. 0.1390014886856079에서 개선이 안됨.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # 학습\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_train, y_train in train_loader:\n",
    "        # 1. device로 이동\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        # 2. 추론\n",
    "        pred_train = model(X_train)\n",
    "        # 3. loss\n",
    "        loss = loss_fn(pred_train, y_train)\n",
    "        # 4. gradient계산\n",
    "        loss.backward()\n",
    "        # 5. 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # 6. 파라미터 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # loss 누적\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # train loss 평균\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "        \n",
    "    # 검증\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for X_valid, y_valid in test_loader:\n",
    "            # 1. device 이동\n",
    "            X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "            # 2. 추론\n",
    "            pred_valid = model(X_valid) # (batch, 1) 1축: positive일 확률\n",
    "            pred_label = (pred_valid > 0.5).type(torch.int32) # label\n",
    "            # 3. 평가 - loss, acc\n",
    "            valid_loss += loss_fn(pred_valid, y_valid).item()\n",
    "            valid_acc += torch.sum(pred_label == y_valid).item()\n",
    "        \n",
    "        valid_loss /= len(test_loader)\n",
    "        valid_acc /= len(testset)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        print(f\"[{epoch+1}/{epochs}] train loss: {train_loss:.5f}, valid loss{valid_loss:.5f}, valid acc: {valid_acc:.5f}\")\n",
    "\n",
    "        # 성능 개선시 모델 저장 + 조기종료\n",
    "        if valid_loss < best_score: # 개선됨.\n",
    "            # 모델 저장 + stop_count 초기화\n",
    "            print(f\">>>>>>>> {epoch+1} Epoch에서 모델을 저장합니다. {best_score}에서 {valid_loss}로 개선됨\")        \n",
    "            torch.save(model, save_model_path)\n",
    "            best_score = valid_loss\n",
    "            stop_count = 0\n",
    "        else: # 개선안됨\n",
    "            stop_count += 1\n",
    "            if patience == stop_count:\n",
    "                print(f\"{epoch+1}에서 조기종료 합니다. {best_score}에서 개선이 안됨.\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCModel(\n",
       "  (lr1): Linear(in_features=30, out_features=16, bias=True)\n",
       "  (lr2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (lr3): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### 저장된 모델 로드\n",
    "load_bc_model = torch.load(save_model_path, weights_only=False)\n",
    "load_bc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 추론 함수 #######\n",
    "def predict_bc(model, X, device=\"cpu\"):\n",
    "    # model로 X를 추론한 결과를 반환\n",
    "    # label, 확률\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        pred_proba = model(X) # POS 확률\n",
    "        pred_class = (pred_proba > 0.5).type(torch.int32)\n",
    "        for class_index, proba in zip(pred_class, pred_proba):\n",
    "            # print(class_index, proba if class_index.item() == 1 else 1-proba)\n",
    "            result.append((class_index.item(), proba.item() if class_index.item() == 1 else 1-proba.item()))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def predict_bc(model, X, device=\"cpu\"):\n",
    "    # model로 X를 추론한 결과를 반환\n",
    "    # label, 확률\n",
    "    result = []\n",
    "    \n",
    "    pred_proba = model(X) # POS 확률\n",
    "    pred_class = (pred_proba > 0.5).type(torch.int32)\n",
    "    for class_index, proba in zip(pred_class, pred_proba):\n",
    "        # print(class_index, proba if class_index.item() == 1 else 1-proba)\n",
    "        result.append((class_index.item(), proba.item() if class_index.item() == 1 else 1-proba.item()))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = torch.tensor(X_test_scaled[:5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.9759008884429932),\n",
       " (0, 0.9999994845734363),\n",
       " (0, 0.9999653625418432),\n",
       " (1, 0.993977427482605),\n",
       " (0, 0.9997869370126864)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predict_bc(load_bc_model, new_data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BCModel().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/1000] - Train loss: 0.16901 Train Accucracy: 0.88498 || Validation Loss: 0.21779 Validation Accuracy: 0.90909\n",
      "====================================================================================================\n",
      "저장: 1 - 이전 : inf, 현재: 0.21779108047485352\n",
      "Epoch[2/1000] - Train loss: 0.08153 Train Accucracy: 0.92254 || Validation Loss: 0.16598 Validation Accuracy: 0.94406\n",
      "====================================================================================================\n",
      "저장: 2 - 이전 : 0.21779108047485352, 현재: 0.1659836433827877\n",
      "Epoch[3/1000] - Train loss: 0.11448 Train Accucracy: 0.91080 || Validation Loss: 0.34324 Validation Accuracy: 0.92308\n",
      "====================================================================================================\n",
      "Epoch[4/1000] - Train loss: 0.07925 Train Accucracy: 0.92723 || Validation Loss: 0.34212 Validation Accuracy: 0.95105\n",
      "====================================================================================================\n",
      "Epoch[5/1000] - Train loss: 0.07638 Train Accucracy: 0.92723 || Validation Loss: 0.28102 Validation Accuracy: 0.94406\n",
      "====================================================================================================\n",
      "Epoch[6/1000] - Train loss: 0.06307 Train Accucracy: 0.92723 || Validation Loss: 0.28663 Validation Accuracy: 0.95105\n",
      "====================================================================================================\n",
      "Epoch[7/1000] - Train loss: 0.04774 Train Accucracy: 0.92254 || Validation Loss: 0.24003 Validation Accuracy: 0.95105\n",
      "====================================================================================================\n",
      "Epoch[8/1000] - Train loss: 0.03414 Train Accucracy: 0.92723 || Validation Loss: 0.17665 Validation Accuracy: 0.95105\n",
      "====================================================================================================\n",
      "Epoch[9/1000] - Train loss: 0.03609 Train Accucracy: 0.92958 || Validation Loss: 0.13003 Validation Accuracy: 0.95804\n",
      "====================================================================================================\n",
      "저장: 9 - 이전 : 0.1659836433827877, 현재: 0.1300286054611206\n",
      "Epoch[10/1000] - Train loss: 0.02708 Train Accucracy: 0.92958 || Validation Loss: 0.10768 Validation Accuracy: 0.96503\n",
      "====================================================================================================\n",
      "저장: 10 - 이전 : 0.1300286054611206, 현재: 0.10767815262079239\n",
      "Epoch[11/1000] - Train loss: 0.03100 Train Accucracy: 0.92723 || Validation Loss: 0.10981 Validation Accuracy: 0.96503\n",
      "====================================================================================================\n",
      "Epoch[12/1000] - Train loss: 0.02218 Train Accucracy: 0.92958 || Validation Loss: 0.10841 Validation Accuracy: 0.97203\n",
      "====================================================================================================\n",
      "Epoch[13/1000] - Train loss: 0.02643 Train Accucracy: 0.93192 || Validation Loss: 0.13361 Validation Accuracy: 0.96503\n",
      "====================================================================================================\n",
      "Epoch[14/1000] - Train loss: 0.02007 Train Accucracy: 0.93427 || Validation Loss: 0.14091 Validation Accuracy: 0.95804\n",
      "====================================================================================================\n",
      "Epoch[15/1000] - Train loss: 0.02164 Train Accucracy: 0.93192 || Validation Loss: 0.14535 Validation Accuracy: 0.95105\n",
      "====================================================================================================\n",
      "Epoch[16/1000] - Train loss: 0.01405 Train Accucracy: 0.93427 || Validation Loss: 0.14224 Validation Accuracy: 0.95105\n",
      "====================================================================================================\n",
      "Epoch[17/1000] - Train loss: 0.01038 Train Accucracy: 0.93897 || Validation Loss: 0.13389 Validation Accuracy: 0.95804\n",
      "====================================================================================================\n",
      "Epoch[18/1000] - Train loss: 0.00809 Train Accucracy: 0.93897 || Validation Loss: 0.12973 Validation Accuracy: 0.95105\n",
      "====================================================================================================\n",
      "Epoch[19/1000] - Train loss: 0.00552 Train Accucracy: 0.93897 || Validation Loss: 0.13063 Validation Accuracy: 0.96503\n",
      "====================================================================================================\n",
      "Epoch[20/1000] - Train loss: 0.00621 Train Accucracy: 0.93662 || Validation Loss: 0.13939 Validation Accuracy: 0.97203\n",
      "====================================================================================================\n",
      "Early stopping: Epoch - 19\n",
      "0.12969350814819336 초\n"
     ]
    }
   ],
   "source": [
    "from module.train import fit\n",
    "\n",
    "result = fit(\n",
    "    train_loader, test_loader, model, loss_fn, optimizer, \n",
    "    epochs=1000, save_best_model=True, save_model_path=\"saved_models/bc_model2.pth\", \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 유형별 구현 정리\n",
    "\n",
    "## 공통\n",
    "\n",
    "-   Input layer(첫번째 Layer)의 in_features\n",
    "    -   입력데이터의 feature(속성) 개수에 맞춰준다.\n",
    "-   Hidden layer 수\n",
    "    -   경험적(art)으로 정한다.\n",
    "    -   Hidden layer에 Linear를 사용하는 경우 보통 feature 수를 줄여 나간다. (핵심 특성들을 추출해나가는 과정의 개념.)\n",
    "\n",
    "## 회귀 모델\n",
    "\n",
    "-   output layer의 출력 unit개수(out_features)\n",
    "    -   정답의 개수\n",
    "    -   ex\n",
    "        -   집값: 1\n",
    "        -   아파트가격, 단독가격, 빌라가격: 3 => y의 개수에 맞춘다.\n",
    "-   출력 Layer에 적용하는 activation 함수\n",
    "    -   일반적으로 **None**\n",
    "    -   값의 범위가 설정되 있고 그 범위의 값을 출력하는 함수가 있을 경우\n",
    "        -   ex) 0 ~ 1: logistic(Sigmoid), -1 ~ 1: hyperbolic tangent(Tanh)\n",
    "-   loss함수\n",
    "    -   MSELoss\n",
    "-   평가지표\n",
    "    -   MSE, RMSE, R square($R^2$)\n",
    "\n",
    "## 다중분류 모델\n",
    "\n",
    "-   output layer의 unit 개수\n",
    "    -   정답 class(고유값)의 개수\n",
    "-   출력 Layer에 적용하는 activation 함수\n",
    "    -   Softmax: 클래스별 확률을 출력\n",
    "-   loss함수\n",
    "    -   **categrocial crossentropy**\n",
    "    -   파이토치 함수\n",
    "        -   **CrossEntropyLoss** = NLLLoss(정답) + LogSoftmax(모델 예측값)\n",
    "        -   **NLLLoss**\n",
    "            -   정답을 OneHot Encoding 처리 후 Loss를 계산한다.\n",
    "            -   입력으로 LogSoftmax 처리한 모델 예측값과 onehot encoding 안 된 정답을 받는다.\n",
    "        -   **LogSoftmax**\n",
    "            -   입력값에 Softmax 계산후 그 Log를 계산한다.\n",
    "                -   NLLLoss의 모델 예측값 입력값으로 처리할 때 사용한다.\n",
    "\n",
    "```python\n",
    "pred = model(input)\n",
    "loss1 = nn.NLLLoss(nn.LogSoftmax(dim=-1)(pred), y)\n",
    "# or\n",
    "loss2 = nn.CrossEntropyLoss()(pred, y)\n",
    "```\n",
    "\n",
    "## 이진분류 모델\n",
    "\n",
    "-   output layer의 unit 개수\n",
    "    -   1개 (positive일 확률)\n",
    "-   출력 Layer에 적용하는 activation 함수\n",
    "    -   Sigmoid(Logistic)\n",
    "-   loss 함수\n",
    "    -   **Binary crossentropy**\n",
    "    -   파이토치 함수: **BCELoss**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
