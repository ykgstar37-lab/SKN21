{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1-HdRR266M6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d 생성\n",
    "## 입력 shape: (Batch, Channel, Height, Width)  (100, 10, 100, 200)\n",
    "layer = nn.Conv2d(\n",
    "    in_channels=10,  # 입력 channel 수\n",
    "    out_channels=5, # Filter(Kernel)의 개수/Feature map의 개수\n",
    "    kernel_size=3,  # Filter크기 (3, 3). H/W 크기가 동일하면 정수.\n",
    "    stride=1,       # 이동 보폭(default: 1)\n",
    "    padding=1 #\"same\",      # 패딩 수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 10, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.ones(1, 10, 10, 10)\n",
    "output = layer(input_data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.shape\n",
    "# [5, 10, 3, 3]  # [filter 개수:5, 입력channel수: 10, filter-height: 3, fiter-width: 3] \n",
    "# (out_channels, in_channels, kernel_size, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias.shape # 필터별로 1개씩."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = nn.MaxPool2d(\n",
    "    kernel_size=2, # pool 영역 크기 (2, 2)\n",
    "    stride=2,      # 이동 크기. kernel size와 동일\n",
    "    padding=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 10, 10])\n",
      "torch.Size([1, 10, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)\n",
    "pool_output = pool_layer(input_data)\n",
    "print(pool_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn(1, 1, 5, 5)\n",
    "\n",
    "print(input_data.shape)\n",
    "pool_output = pool_layer(input_data)\n",
    "print(pool_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6957, -0.6342,  0.4635,  1.9956, -1.1246],\n",
       "          [-2.8484, -0.1004,  0.4432, -0.3017,  1.0525],\n",
       "          [ 0.6118, -1.3783,  1.1444,  1.0403, -0.2005],\n",
       "          [-1.3915,  0.3039,  0.4850,  0.6450,  0.3047],\n",
       "          [-1.8958, -0.3284,  0.0737, -2.0000, -0.3655]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6957,  0.4635,  1.9956],\n",
       "          [ 0.6118,  1.1444,  1.0525],\n",
       "          [-1.3915,  0.4850,  0.6450]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from module.data import load_mnist_dataset, load_fashion_mnist_dataset\n",
    "from module.train import fit\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 지정\n",
    "EPOCH = 1 # 10\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DATA_ROOT_DIR = \"datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_mnist_dataset(DATA_ROOT_DIR, BATCH_SIZE, True)\n",
    "test_loader = load_mnist_dataset(DATA_ROOT_DIR, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN - layer block\n",
    "# ConvolutionLayer -> Activation -> Pooling Layer\n",
    "# ConvolutionLayer -> Activation -> ConvolutionLayer -> Activation-> Pooling Layer\n",
    "\n",
    "# ConvolutionLayer -> BatchNormalization -> Activation -> Dropout -> Pooling Layer\n",
    "\n",
    "## 구조: filter 개수는 늘려주고(channel-depth) feature map의 size는 줄이는 방식으로 구성.\n",
    "# depth: Conv2d,  size: MaxPool2d\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, \n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"                                  \n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2, \n",
    "                stride=2\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, \n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "        # 추론기(분류기) - Fully Conntected Layer(nn.Liear)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=4*4*128, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.b1(X)\n",
    "        output = self.b2(output)\n",
    "        output = self.b3(output)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNModel                                 [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 28, 28]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-4                    [1, 32, 14, 14]           --\n",
       "├─Sequential: 1-2                        [1, 64, 7, 7]             --\n",
       "│    └─Conv2d: 2-5                       [1, 64, 14, 14]           18,496\n",
       "│    └─BatchNorm2d: 2-6                  [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-7                         [1, 64, 14, 14]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-3                        [1, 128, 4, 4]            --\n",
       "│    └─Conv2d: 2-9                       [1, 128, 7, 7]            73,856\n",
       "│    └─BatchNorm2d: 2-10                 [1, 128, 7, 7]            256\n",
       "│    └─ReLU: 2-11                        [1, 128, 7, 7]            --\n",
       "│    └─MaxPool2d: 2-12                   [1, 128, 4, 4]            --\n",
       "├─Sequential: 1-4                        [1, 10]                   --\n",
       "│    └─Flatten: 2-13                     [1, 2048]                 --\n",
       "│    └─Linear: 2-14                      [1, 10]                   20,490\n",
       "==========================================================================================\n",
       "Total params: 113,610\n",
       "Trainable params: 113,610\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 7.52\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.70\n",
       "Params size (MB): 0.45\n",
       "Estimated Total Size (MB): 1.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(CNNModel(dropout_rate=0.5), (1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "# loss 함수\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/1] - Train loss: 0.04362 Train Accucracy: 0.98653 || Validation Loss: 0.04200 Validation Accuracy: 0.98690\n",
      "====================================================================================================\n",
      "저장: 1 - 이전 : inf, 현재: 0.04200267249252647\n",
      "39.9455361366272 초\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "save_path = \"saved_models/mnist_cnn_model.pt\"\n",
    "result = fit(\n",
    "    train_loader, test_loader, model, loss_fn, optimizer, EPOCH,\n",
    "    save_model_path=save_path,\n",
    "    device=device, \n",
    "    mode=\"multi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 평가\n",
    "from module.train import test_multi_classification\n",
    "loss, acc = test_multi_classification(\n",
    "    test_loader, model, loss_fn, device\n",
    ")\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정성적 평가 - 실제 image 파일로 확인\n",
    "from PIL import Image\n",
    "img = Image.open(\"test_img/num/eight.png\")\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "@torch.no_grad\n",
    "def predict(path, model):\n",
    "    img = Image.open(path)\n",
    "\n",
    "    # color -> grayscale\n",
    "    img = img.convert('L') # 'L': grayscale, \"RGB\": color\n",
    "\n",
    "    # resize\n",
    "    input_tensor = transforms.Resize((28, 28))(img)\n",
    "\n",
    "    # PIL.Image -> torch.Tensor  변환, 정규화 (0 ~ 1)\n",
    "    input_tensor = transforms.ToTensor()(input_tensor)\n",
    "\n",
    "    # batch 축(dummy 축)을 추가.\n",
    "    input_tensor = input_tensor.unsqueeze(dim=0)\n",
    "\n",
    "    # device로 이동\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    result = model(input_tensor)\n",
    "    sm = nn.Softmax(dim=-1)\n",
    "    result_proba = sm(result)\n",
    "    final_result = result_proba.max(dim=-1)\n",
    "    return {\"class\":final_result.indices[0], \n",
    "            \"확률\":final_result.values[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "img_path_list = glob(\"test_img/num/*.png\")\n",
    "for img_path in img_path_list:\n",
    "    result = predict(img_path, model)\n",
    "    print(f\"{img_path}, 추론class: {result['class']}, 확률: {result['확률']}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2ARCyjDW66NR",
    "6bAN1wPG66NS",
    "shNUg6al66NV",
    "7xgQxAU666NZ"
   ],
   "name": "07_CNN_MNIST분류, 모델저장.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
